{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "__file__ = os.getcwd()\n",
    "path = os.path.join(os.path.realpath(__file__).rsplit('/', 1)[0], 'raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train_activity = os.path.join(path, 'train_activity.csv')\n",
    "path_train_combat = os.path.join(path, 'train_combat.csv')\n",
    "path_train_pledge = os.path.join(path, 'train_pledge.csv')\n",
    "path_train_payment = os.path.join(path, 'train_payment.csv')\n",
    "path_train_trade = os.path.join(path, 'train_trade.csv')\n",
    "path_train_label = os.path.join(path, 'train_label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = pd.read_csv(path_train_activity, engine = 'python')\n",
    "train2 = pd.read_csv(path_train_combat, engine = 'python')\n",
    "train3 = pd.read_csv(path_train_pledge, engine = 'python')\n",
    "train4 = pd.read_csv(path_train_payment, engine = 'python')\n",
    "train5 = pd.read_csv(path_train_trade, engine = 'python')\n",
    "y_train = pd.read_csv(path_train_label, engine = 'python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user3/anaconda3/bigcontest/preprocess:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# 잔존 고객 0, 이탈 고객 1\n",
    "y_train['leave'] = 0\n",
    "y_train['leave'][y_train.survival_time < 64] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user3/anaconda3/bigcontest/preprocess:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# 결제 기록이 없으면 0, 결제 기록이 있으면 1\n",
    "y_train['amount'] = 0\n",
    "y_train['amount'][y_train.amount_spent > 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits = 1, test_size = 0.25, random_state = 42)\n",
    "for train_index, test_index in split.split(y_train, y_train['leave']):\n",
    "    strat_y_train = y_train.loc[train_index]\n",
    "    strat_y_test = y_train.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 10000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(strat_y_train), len(strat_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4501, 0.4501)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strat_y_train['leave'].mean(), strat_y_test['leave'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = strat_y_train.sort_values(['acc_id'], ascending = True)\n",
    "y_test = strat_y_test.sort_values(['acc_id'], ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id = y_train['acc_id'].values\n",
    "test_id = y_test['acc_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     2,      5,      8, ..., 130468, 130469, 130470])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_id.sort()\n",
    "train_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    20,     62,     81, ..., 130434, 130445, 130473])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_id.sort()\n",
    "test_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전처리에 필요한 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def divide_by_week(data, variable):\n",
    "    '''\n",
    "    데이터와 변수를 넣으면 각 유저 아이디에 대한 주차별 변수의 합을 구함\n",
    "    '''\n",
    "    \n",
    "    data_sub = data.groupby(['acc_id', 'day'])[variable].sum().unstack('day').fillna(0)\n",
    "    week_1 = data_sub.iloc[:, 0:7].sum(axis = 1).values\n",
    "    week_2 = data_sub.iloc[:, 7:14].sum(axis = 1).values\n",
    "    week_3 = data_sub.iloc[:, 14:21].sum(axis = 1).values\n",
    "    week_4 = data_sub.iloc[:, 21:28].sum(axis = 1).values\n",
    "    print(variable, 'done')\n",
    "        \n",
    "    return week_1, week_2, week_3, week_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pledge_divide_by_week(data, variable):\n",
    "    '''\n",
    "    데이터와 변수를 넣으면 각 혈맹 아이디에 대한 주차별 변수의 평균을 구함\n",
    "    '''\n",
    "    \n",
    "    data_sub = data.groupby(['pledge_id', 'day'])[variable].mean().unstack('day').fillna(0)\n",
    "    week_1 = data_sub.iloc[:, 0:7].mean(axis = 1).values\n",
    "    week_2 = data_sub.iloc[:, 7:14].mean(axis = 1).values\n",
    "    week_3 = data_sub.iloc[:, 14:21].mean(axis = 1).values\n",
    "    week_4 = data_sub.iloc[:, 21:28].mean(axis = 1).values\n",
    "    print(variable, 'done')\n",
    "        \n",
    "    return week_1, week_2, week_3, week_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_divide_by_week(data, variable):\n",
    "    '''\n",
    "    데이터와 변수를 넣으면 각 캐릭터 아이디의 유저에 대한 주차별 변수의 평균을 구함\n",
    "    '''\n",
    "    \n",
    "    data_sub = data.groupby(['acc_id', 'day'])[variable].mean().unstack('day').fillna(0)\n",
    "    week_1 = data_sub.iloc[:, 0:7].mean(axis = 1).values\n",
    "    week_2 = data_sub.iloc[:, 7:14].mean(axis = 1).values\n",
    "    week_3 = data_sub.iloc[:, 14:21].mean(axis = 1).values\n",
    "    week_4 = data_sub.iloc[:, 21:28].mean(axis = 1).values\n",
    "    print(variable, 'done')\n",
    "        \n",
    "    return week_1, week_2, week_3, week_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data1, data2, data3, data4, data5, user_id, train = True):\n",
    "    '''\n",
    "    유저와 케릭터에 대한 28일 동안의 모든 활동 데이터를 각 유저에 대한 정보로 전처리\n",
    "    data1 : 기본 활동 데이터(DataFrame)\n",
    "    data2 : 전투 데이터(DataFrame)\n",
    "    data3 : 혈맹 데이터(DataFrame)\n",
    "    data4 : 결제 데이터(DataFrame)\n",
    "    data5 : 거래 데이터(DataFrame)\n",
    "    user_id(=acc_id) : 유저별 id(np.array)\n",
    "    train : default = True, train data set에 대해서만 이상치 대체\n",
    "    '''\n",
    "    \n",
    "    # user_id에 해당하는 행만 subset\n",
    "    index_list = []\n",
    "    for i in range(0, len(data1)):\n",
    "        if(data1['acc_id'][i] in user_id):\n",
    "            index_list.append(i)            \n",
    "    data1_sub = data1.loc[index_list]\n",
    "    \n",
    "    index_list = []\n",
    "    for i in range(0, len(data2)):\n",
    "        if(data2['acc_id'][i] in user_id):\n",
    "            index_list.append(i)            \n",
    "    data2_sub = data2.loc[index_list]\n",
    "    \n",
    "    index_list = []\n",
    "    for i in range(0, len(data3)):\n",
    "        if(data3['acc_id'][i] in user_id):\n",
    "            index_list.append(i)            \n",
    "    data3_sub = data3.loc[index_list]\n",
    "    \n",
    "    index_list = []\n",
    "    for i in range(0, len(data4)):\n",
    "        if(data4['acc_id'][i] in user_id):\n",
    "            index_list.append(i)            \n",
    "    data4_sub = data4.loc[index_list]\n",
    "    \n",
    "    index_list = []\n",
    "    for i in range(0, len(data5)):\n",
    "        if(data5['source_acc_id'][i] in user_id):\n",
    "            index_list.append(i)      \n",
    "    source_data = data5.loc[index_list]\n",
    "    \n",
    "    index_list = []\n",
    "    for i in range(0, len(data5)):\n",
    "        if(data5['target_acc_id'][i] in user_id):\n",
    "            index_list.append(i)      \n",
    "    target_data = data5.loc[index_list]\n",
    "    \n",
    "    \n",
    "    # 연속형 변수명만 추출\n",
    "    data1_col = data1.columns[4:]\n",
    "    data2_col = data2.columns[6:]\n",
    "    data3_col = data3.columns[5:-1]\n",
    "    \n",
    "    \n",
    "    # 각 유저에 대한 연속형 변수를 주차별 합으로 새로운 변수 만듦\n",
    "    dic = {}  # 새 변수를 담기 위한 빈 dictionary\n",
    "\n",
    "    for var_name in data1_col:\n",
    "        week_1, week_2, week_3, week_4 = divide_by_week(data = data1_sub, variable = var_name)\n",
    "        key_1 = var_name + '_1'\n",
    "        key_2 = var_name + '_2'\n",
    "        key_3 = var_name + '_3'\n",
    "        key_4 = var_name + '_4'\n",
    "        dic[key_1] = week_1\n",
    "        dic[key_2] = week_2\n",
    "        dic[key_3] = week_3\n",
    "        dic[key_4] = week_4\n",
    "        \n",
    "    for var_name in data2_col:\n",
    "        week_1, week_2, week_3, week_4 = divide_by_week(data = data2_sub, variable = var_name)\n",
    "        key_1 = 'combat_' + var_name + '_1'\n",
    "        key_2 = 'combat_' + var_name + '_2'\n",
    "        key_3 = 'combat_' + var_name + '_3'\n",
    "        key_4 = 'combat_' + var_name + '_4'\n",
    "        dic[key_1] = week_1\n",
    "        dic[key_2] = week_2\n",
    "        dic[key_3] = week_3\n",
    "        dic[key_4] = week_4\n",
    "    \n",
    "    \n",
    "    # user_id와 연속형 변수들을 concatenate 하여 data_array로 저장\n",
    "    user_id_clone = user_id.copy()\n",
    "    data_array = user_id_clone.reshape(-1, 1)\n",
    "\n",
    "    for key in dic.keys():\n",
    "        data_array = np.concatenate([data_array, dic[key].reshape(-1, 1)], axis = 1)\n",
    "        \n",
    "        \n",
    "    # data_array를 데이터프레임 형태로 바꿔주고 컬럼명 지정\n",
    "    colnames = ['acc_id']\n",
    "    colnames.extend(list(dic.keys())[0:])\n",
    "\n",
    "    data = pd.DataFrame(data_array)\n",
    "    data.columns = colnames\n",
    "    \n",
    "    \n",
    "    # 혈맹 데이터를 이용해 혈맹 군집화\n",
    "    dic = {}\n",
    "    char_list = []\n",
    "    char_matrix = data3_sub.groupby(['acc_id', 'char_id']).count()['day']\n",
    "    data3_id = data3_sub['acc_id'].unique()\n",
    "    data3_id.sort()\n",
    "    for i in data3_id:\n",
    "        char_list.append(np.argmax(char_matrix[i]))\n",
    "    char_id = np.array(char_list)\n",
    "\n",
    "    index_list = []\n",
    "    for i in range(0, len(data3_sub)):\n",
    "        if(data3_sub['char_id'].iloc[i] in char_id):\n",
    "            index_list.append(i)            \n",
    "    data3_sub_2 = data3_sub.iloc[index_list]\n",
    "\n",
    "    for var_name in data3_col:\n",
    "        week_1, week_2, week_3, week_4 = char_divide_by_week(data = data3_sub_2, variable = var_name)\n",
    "        key_1 = var_name + '_1'\n",
    "        key_2 = var_name + '_2'\n",
    "        key_3 = var_name + '_3'\n",
    "        key_4 = var_name + '_4'\n",
    "        dic[key_1] = week_1\n",
    "        dic[key_2] = week_2\n",
    "        dic[key_3] = week_3\n",
    "        dic[key_4] = week_4\n",
    "\n",
    "    data3_id_clone = data3_id.copy()\n",
    "    char_data_array = np.concatenate([data3_id_clone.reshape(-1, 1), char_id.reshape(-1, 1)], axis = 1)\n",
    "\n",
    "    for key in dic.keys():\n",
    "        char_data_array = np.concatenate([char_data_array, dic[key].reshape(-1, 1)], axis = 1)\n",
    "\n",
    "    colnames = ['acc_id', 'char_id']\n",
    "    colnames.extend(list(dic.keys())[0:])\n",
    "\n",
    "    char_data = pd.DataFrame(char_data_array)\n",
    "    char_data.columns = colnames\n",
    "    char_data = char_data.fillna(0)\n",
    "    \n",
    "    if(train == True):\n",
    "        # random_attacker_cnt\n",
    "        data3_sub_day_1 = data3_sub[(data3_sub['day'] == 1) | (data3_sub['day'] == 8)]\n",
    "        data3_sub_day_2 = data3_sub[(data3_sub['day'] == 2) | (data3_sub['day'] == 9)]\n",
    "        data3_sub_day_3 = data3_sub[(data3_sub['day'] == 3) | (data3_sub['day'] == 10)]\n",
    "        data3_sub_day_4 = data3_sub[(data3_sub['day'] == 4) | (data3_sub['day'] == 11)]\n",
    "        data3_sub_day_5 = data3_sub[(data3_sub['day'] == 5) | (data3_sub['day'] == 12)]\n",
    "        data3_sub_day_6 = data3_sub[(data3_sub['day'] == 6) | (data3_sub['day'] == 13)]\n",
    "        data3_sub_day_7 = data3_sub[(data3_sub['day'] == 7) | (data3_sub['day'] == 14)]\n",
    "\n",
    "        data3_sub_day_6_mean = data3_sub_day_6.groupby('char_id')['random_attacker_cnt'].mean()\n",
    "        data3_sub_day_6_mean = pd.DataFrame(data3_sub_day_6_mean)\n",
    "        data3_sub_day_6_mean.columns = ['random_attacker_cnt_new']\n",
    "        val6 = pd.merge(data3_sub[data3_sub['day'] == 20], data3_sub_day_6_mean, how = 'left', on = 'char_id')\n",
    "        val6 = val6.fillna(0)\n",
    "\n",
    "        data3_sub_day_7_mean = data3_sub_day_7.groupby('char_id')['random_attacker_cnt'].mean()\n",
    "        data3_sub_day_7_mean = pd.DataFrame(data3_sub_day_7_mean)\n",
    "        data3_sub_day_7_mean.columns = ['random_attacker_cnt_new']\n",
    "        val7 = pd.merge(data3_sub[data3_sub['day'] == 21], data3_sub_day_7_mean, how = 'left', on = 'char_id')\n",
    "        val7 = val7.fillna(0)\n",
    "\n",
    "        val1 = data3_sub[data3_sub['day'] == 15]\n",
    "        val2 = data3_sub[data3_sub['day'] == 16]\n",
    "        val3 = data3_sub[data3_sub['day'] == 17]\n",
    "        val4 = data3_sub[data3_sub['day'] == 18]\n",
    "        val5 = data3_sub[data3_sub['day'] == 19]\n",
    "        val = pd.concat([val1, val2, val3, val4, val5, val6, val7], axis = 0, ignore_index = True)\n",
    "\n",
    "        val['random_attacker_cnt_new'][val['random_attacker_cnt_new'].isna()] = val['random_attacker_cnt'][val['random_attacker_cnt_new'].isna()]\n",
    "        random_attacker_cnt_3_new = val.groupby('char_id')['random_attacker_cnt_new'].mean()\n",
    "        char_data = pd.merge(char_data, random_attacker_cnt_3_new, how = 'left', on = 'char_id')\n",
    "        char_data['random_attacker_cnt_3'][~char_data['random_attacker_cnt_new'].isna()] = char_data['random_attacker_cnt_new'][~char_data['random_attacker_cnt_new'].isna()]\n",
    "        char_data = char_data.drop('random_attacker_cnt_new', axis = 1)\n",
    "\n",
    "\n",
    "        data3_sub_day_1_mean = data3_sub_day_1.groupby('char_id')['random_attacker_cnt'].mean()\n",
    "        data3_sub_day_1_mean = pd.DataFrame(data3_sub_day_1_mean)\n",
    "        data3_sub_day_1_mean.columns = ['random_attacker_cnt_new']\n",
    "        val1 = pd.merge(data3_sub[data3_sub['day'] == 22], data3_sub_day_1_mean, how = 'left', on = 'char_id')\n",
    "        val1 = val1.fillna(0)\n",
    "\n",
    "        val2 = data3_sub[data3_sub['day'] == 23]\n",
    "        val3 = data3_sub[data3_sub['day'] == 24]\n",
    "        val4 = data3_sub[data3_sub['day'] == 25]\n",
    "        val5 = data3_sub[data3_sub['day'] == 26]\n",
    "        val6 = data3_sub[data3_sub['day'] == 27]\n",
    "        val7 = data3_sub[data3_sub['day'] == 28]\n",
    "        val = pd.concat([val1, val2, val3, val4, val5, val6, val7], axis = 0, ignore_index = True)\n",
    "\n",
    "        val['random_attacker_cnt_new'][val['random_attacker_cnt_new'].isna()] = val['random_attacker_cnt'][val['random_attacker_cnt_new'].isna()]\n",
    "        random_attacker_cnt_4_new = val.groupby('char_id')['random_attacker_cnt_new'].mean()\n",
    "        char_data = pd.merge(char_data, random_attacker_cnt_4_new, how = 'left', on = 'char_id')\n",
    "        char_data['random_attacker_cnt_4'][~char_data['random_attacker_cnt_new'].isna()] = char_data['random_attacker_cnt_new'][~char_data['random_attacker_cnt_new'].isna()]\n",
    "        char_data = char_data.drop('random_attacker_cnt_new', axis = 1)\n",
    "\n",
    "        # same_pledge_cnt\n",
    "        char_data['same_pledge_cnt_1'] = (char_data['same_pledge_cnt_2'] + char_data['same_pledge_cnt_3'] + char_data['same_pledge_cnt_4']) / 3\n",
    "\n",
    "        # temp_cnt\n",
    "        data3_sub_day_1 = data3_sub[(data3_sub['day'] == 1) | (data3_sub['day'] == 8) | (data3_sub['day'] == 15)]\n",
    "        data3_sub_day_2 = data3_sub[(data3_sub['day'] == 2) | (data3_sub['day'] == 9) | (data3_sub['day'] == 16)]\n",
    "        data3_sub_day_3 = data3_sub[(data3_sub['day'] == 3) | (data3_sub['day'] == 10) | (data3_sub['day'] == 17)]\n",
    "        data3_sub_day_4 = data3_sub[(data3_sub['day'] == 4) | (data3_sub['day'] == 11) | (data3_sub['day'] == 18)]\n",
    "        data3_sub_day_5 = data3_sub[(data3_sub['day'] == 5) | (data3_sub['day'] == 12) | (data3_sub['day'] == 19)]\n",
    "        data3_sub_day_6 = data3_sub[(data3_sub['day'] == 6) | (data3_sub['day'] == 13) | (data3_sub['day'] == 20)]\n",
    "        data3_sub_day_7 = data3_sub[(data3_sub['day'] == 7) | (data3_sub['day'] == 14) | (data3_sub['day'] == 21)]\n",
    "\n",
    "        data3_sub_day_2_mean = data3_sub_day_2.groupby('char_id')['temp_cnt'].mean()\n",
    "        data3_sub_day_2_mean = pd.DataFrame(data3_sub_day_2_mean)\n",
    "        data3_sub_day_2_mean.columns = ['temp_cnt_new']\n",
    "        val2 = pd.merge(data3_sub[data3_sub['day'] == 23], data3_sub_day_2_mean, how = 'left', on = 'char_id')\n",
    "        val2 = val2.fillna(0)\n",
    "\n",
    "        data3_sub_day_3_mean = data3_sub_day_3.groupby('char_id')['temp_cnt'].mean()\n",
    "        data3_sub_day_3_mean = pd.DataFrame(data3_sub_day_3_mean)\n",
    "        data3_sub_day_3_mean.columns = ['temp_cnt_new']\n",
    "        val3 = pd.merge(data3_sub[data3_sub['day'] == 24], data3_sub_day_3_mean, how = 'left', on = 'char_id')\n",
    "        val3 = val3.fillna(0)\n",
    "\n",
    "        data3_sub_day_4_mean = data3_sub_day_4.groupby('char_id')['temp_cnt'].mean()\n",
    "        data3_sub_day_4_mean = pd.DataFrame(data3_sub_day_4_mean)\n",
    "        data3_sub_day_4_mean.columns = ['temp_cnt_new']\n",
    "        val4 = pd.merge(data3_sub[data3_sub['day'] == 25], data3_sub_day_4_mean, how = 'left', on = 'char_id')\n",
    "        val4 = val4.fillna(0)\n",
    "\n",
    "        data3_sub_day_5_mean = data3_sub_day_5.groupby('char_id')['temp_cnt'].mean()\n",
    "        data3_sub_day_5_mean = pd.DataFrame(data3_sub_day_5_mean)\n",
    "        data3_sub_day_5_mean.columns = ['temp_cnt_new']\n",
    "        val5 = pd.merge(data3_sub[data3_sub['day'] == 26], data3_sub_day_5_mean, how = 'left', on = 'char_id')\n",
    "        val5 = val5.fillna(0)\n",
    "\n",
    "        data3_sub_day_6_mean = data3_sub_day_6.groupby('char_id')['temp_cnt'].mean()\n",
    "        data3_sub_day_6_mean = pd.DataFrame(data3_sub_day_6_mean)\n",
    "        data3_sub_day_6_mean.columns = ['temp_cnt_new']\n",
    "        val6 = pd.merge(data3_sub[data3_sub['day'] == 27], data3_sub_day_6_mean, how = 'left', on = 'char_id')\n",
    "        val6 = val6.fillna(0)\n",
    "\n",
    "        data3_sub_day_7_mean = data3_sub_day_7.groupby('char_id')['temp_cnt'].mean()\n",
    "        data3_sub_day_7_mean = pd.DataFrame(data3_sub_day_7_mean)\n",
    "        data3_sub_day_7_mean.columns = ['temp_cnt_new']\n",
    "        val7 = pd.merge(data3_sub[data3_sub['day'] == 28], data3_sub_day_7_mean, how = 'left', on = 'char_id')\n",
    "        val7 = val7.fillna(0)\n",
    "\n",
    "        val1 = data3_sub[data3_sub['day'] == 22]\n",
    "        val = pd.concat([val1, val2, val3, val4, val5, val6, val7], axis = 0, ignore_index = True)\n",
    "\n",
    "        val['temp_cnt_new'][val['temp_cnt_new'].isna()] = val['temp_cnt'][val['temp_cnt_new'].isna()]\n",
    "        temp_cnt_4_new = val.groupby('char_id')['temp_cnt_new'].mean()\n",
    "        char_data = pd.merge(char_data, temp_cnt_4_new, how = 'left', on = 'char_id')\n",
    "        char_data['temp_cnt_4'][~char_data['temp_cnt_new'].isna()] = char_data['temp_cnt_new'][~char_data['temp_cnt_new'].isna()]\n",
    "        char_data = char_data.drop('temp_cnt_new', axis = 1)\n",
    "    \n",
    "    \n",
    "    char_data['pledge_group'] = kmean.predict(char_data.iloc[:, 2:]) + 1\n",
    "    data = pd.merge(data, char_data.loc[:, ['acc_id', 'pledge_group']], how = 'left', on = 'acc_id')\n",
    "    data = data.fillna(0)\n",
    "    data['pledge_group'] = data['pledge_group'].astype('int32')\n",
    "    \n",
    "    \n",
    "    # 결제 데이터에서 28일 동안 결제 횟수, 1회 결제시 결제 금액 추출    \n",
    "    amount_cnt = data4_sub.groupby('acc_id')['amount_spent'].count()\n",
    "    amount_mean = data4_sub.groupby('acc_id')['amount_spent'].sum() / data4_sub.groupby('acc_id')['amount_spent'].count()\n",
    "    acc_id_sorted = np.sort(data4_sub['acc_id'].unique())\n",
    "    \n",
    "    amount_array = np.concatenate([acc_id_sorted.reshape(-1, 1), amount_cnt.values.reshape(-1, 1),\n",
    "                                  amount_mean.values.reshape(-1, 1)], axis = 1)\n",
    "    amount_data = pd.DataFrame(amount_array)\n",
    "    amount_data.columns = ['acc_id', 'amount_cnt', 'amount_mean']\n",
    "    \n",
    "    data = pd.merge(data, amount_data, how = 'left', on = 'acc_id')\n",
    "    data = data.fillna(0)  # 결제 기록이 없어 nan인 값을 모두 0으로 대체\n",
    "    \n",
    "    \n",
    "    # 기본 활동 데이터의 서버를 가장 플레이 시간이 많은 케릭터 기준으로 추출\n",
    "    char_list = []\n",
    "    char_matrix = data1_sub.groupby(['acc_id', 'char_id'])['playtime'].sum()\n",
    "    for i in user_id:\n",
    "        char_list.append(np.argmax(char_matrix[i]))\n",
    "        \n",
    "    server_list = []\n",
    "    for i in char_list:\n",
    "        user_char = data1_sub[data1_sub['char_id'] == i]\n",
    "        char_server = user_char['server'].values[-1]\n",
    "        server_list.append(char_server)\n",
    "    \n",
    "    server_array = np.concatenate([np.array(user_id).reshape(-1, 1), np.array(server_list).reshape(-1, 1)], axis = 1)\n",
    "    server_data = pd.DataFrame(server_array)\n",
    "    server_data.columns = ['acc_id', 'server']\n",
    "    server_data['acc_id'] = server_data['acc_id'].astype('float64')\n",
    "    data = pd.merge(data, server_data, how = 'left', on = 'acc_id')\n",
    "    \n",
    "    # 0은 특수 서버, 1은 일반 서버, 2는 non pvp 서버\n",
    "    data['server_group'] = 0\n",
    "    data['server_group'][(data['server'] == 'aa') | (data['server'] == 'ab') | (data['server'] == 'ac') |\n",
    "                         (data['server'] == 'ad') | (data['server'] == 'ae') | (data['server'] == 'af') |\n",
    "                         (data['server'] == 'ag') | (data['server'] == 'ah') | (data['server'] == 'ai') |\n",
    "                         (data['server'] == 'aj') | (data['server'] == 'ak') | (data['server'] == 'al') |\n",
    "                         (data['server'] == 'am') | (data['server'] == 'an') | (data['server'] == 'ao') |\n",
    "                         (data['server'] == 'ap') | (data['server'] == 'aq') | (data['server'] == 'ar') |\n",
    "                         (data['server'] == 'as') | (data['server'] == 'at') | (data['server'] == 'au') |\n",
    "                         (data['server'] == 'av') | (data['server'] == 'aw') | (data['server'] == 'ax') |\n",
    "                         (data['server'] == 'ay') | (data['server'] == 'az') | (data['server'] == 'ba') |\n",
    "                         (data['server'] == 'bb') | (data['server'] == 'bc') | (data['server'] == 'bd')] = 1\n",
    "    data['server_group'][(data['server'] == 'bi') | (data['server'] == 'bs') | (data['server'] == 'bg')] = 2\n",
    "    data = data.drop('server', axis = 1)\n",
    "    \n",
    "    \n",
    "    # 전투 데이터의 직업, 레벨 변수를 가장 접속일 수가 많은 케릭터 기준으로 추출    \n",
    "    char_list = []\n",
    "    char_matrix = data2_sub.groupby(['acc_id', 'char_id']).count()['day']\n",
    "    for i in user_id:\n",
    "        char_list.append(np.argmax(char_matrix[i]))\n",
    "        \n",
    "    class_list = []\n",
    "    level_list = []\n",
    "    for i in char_list:\n",
    "        user_char = data2_sub[data2_sub['char_id'] == i]\n",
    "        char_class = user_char['class'].values[-1]\n",
    "        char_level = user_char['level'].values[-1]\n",
    "        class_list.append(char_class)\n",
    "        level_list.append(char_level)\n",
    "    \n",
    "    char_array = np.concatenate([np.array(user_id).reshape(-1, 1), np.array(class_list).reshape(-1, 1),\n",
    "                                 np.array(level_list).reshape(-1, 1)], axis = 1)\n",
    "    char_data = pd.DataFrame(char_array)\n",
    "    char_data.columns = ['acc_id', 'class', 'level']\n",
    "    char_data['acc_id'] = char_data['acc_id'].astype('float64')\n",
    "    data = pd.merge(char_data, data, how = 'left', on = 'acc_id')\n",
    "    \n",
    "    \n",
    "    # 범주형 변수 one-hot encoding\n",
    "    server_group_dummies = pd.get_dummies(data['server_group']).rename(columns = lambda x : 'server_group_' + str(x))\n",
    "    class_dummies = pd.get_dummies(data['class']).rename(columns = lambda x : 'class_' + str(x))\n",
    "    pledge_group_dummies = pd.get_dummies(data['pledge_group']).rename(columns = lambda x : 'pledge_group_' + str(x))\n",
    "\n",
    "    data = pd.concat([data, server_group_dummies, class_dummies, pledge_group_dummies], axis = 1)\n",
    "    data.drop(['server_group', 'class', 'pledge_group'], axis = 1, inplace = True)\n",
    "    \n",
    "    \n",
    "    # 거래 데이터를 user_id에 대하여 판매, 구매로 구분\n",
    "    trade_data = pd.DataFrame(user_id)\n",
    "    trade_data.columns = ['acc_id']\n",
    "    \n",
    "    for i in range(1, 5):\n",
    "        source_data_week = source_data[(source_data['day'] >= (7 * i - 6)) & (source_data['day'] <= (7 * i))]\n",
    "        source_data_week_sum = source_data_week.groupby(['source_acc_id', 'item_type'])['item_price'].sum().unstack('item_type')\n",
    "        source_data_week_sum = source_data_week_sum.fillna(0)\n",
    "        source_data_week_sum = source_data_week_sum.reset_index(level = 'source_acc_id')\n",
    "        source_data_week_sum = source_data_week_sum.rename(columns = {'source_acc_id' : 'acc_id'})\n",
    "        col = 'source_price_'+ source_data_week_sum.columns[1:] + '_' + str(i)\n",
    "        source_data_week_sum.columns = source_data_week_sum.columns[0:1].append(col)\n",
    "        trade_data = pd.merge(trade_data, source_data_week_sum, how = 'left', on = 'acc_id')\n",
    "        \n",
    "    for i in range(1, 5):\n",
    "        source_data_week = source_data[(source_data['day'] >= (7 * i - 6)) & (source_data['day'] <= (7 * i))]\n",
    "        source_data_week_sum = source_data_week.groupby(['source_acc_id', 'item_type'])['item_amount'].sum().unstack('item_type')\n",
    "        source_data_week_sum = source_data_week_sum.fillna(0)\n",
    "        source_data_week_sum = source_data_week_sum.reset_index(level = 'source_acc_id')\n",
    "        source_data_week_sum = source_data_week_sum.rename(columns = {'source_acc_id' : 'acc_id'})\n",
    "        col = 'source_amount_'+ source_data_week_sum.columns[1:] + '_' + str(i)\n",
    "        source_data_week_sum.columns = source_data_week_sum.columns[0:1].append(col)\n",
    "        trade_data = pd.merge(trade_data, source_data_week_sum, how = 'left', on = 'acc_id')\n",
    "    \n",
    "    for i in range(1, 5):\n",
    "        target_data_week = target_data[(target_data['day'] >= (7 * i - 6)) & (target_data['day'] <= (7 * i))]\n",
    "        target_data_week_sum = target_data_week.groupby(['target_acc_id', 'item_type'])['item_price'].sum().unstack('item_type')\n",
    "        target_data_week_sum = target_data_week_sum.fillna(0)\n",
    "        target_data_week_sum = target_data_week_sum.reset_index(level = 'target_acc_id')\n",
    "        target_data_week_sum = target_data_week_sum.rename(columns = {'target_acc_id' : 'acc_id'})\n",
    "        col = 'target_price_'+ target_data_week_sum.columns[1:] + '_' + str(i)\n",
    "        target_data_week_sum.columns = target_data_week_sum.columns[0:1].append(col)\n",
    "        trade_data = pd.merge(trade_data, target_data_week_sum, how = 'left', on = 'acc_id')\n",
    "        \n",
    "    for i in range(1, 5):\n",
    "        target_data_week = target_data[(target_data['day'] >= (7 * i - 6)) & (target_data['day'] <= (7 * i))]\n",
    "        target_data_week_sum = target_data_week.groupby(['target_acc_id', 'item_type'])['item_amount'].sum().unstack('item_type')\n",
    "        target_data_week_sum = target_data_week_sum.fillna(0)\n",
    "        target_data_week_sum = target_data_week_sum.reset_index(level = 'target_acc_id')\n",
    "        target_data_week_sum = target_data_week_sum.rename(columns = {'target_acc_id' : 'acc_id'})\n",
    "        col = 'target_amount_'+ target_data_week_sum.columns[1:] + '_' + str(i)\n",
    "        target_data_week_sum.columns = target_data_week_sum.columns[0:1].append(col)\n",
    "        trade_data = pd.merge(trade_data, target_data_week_sum, how = 'left', on = 'acc_id')\n",
    "        \n",
    "    trade_data = trade_data.fillna(0)\n",
    "    \n",
    "    \n",
    "    # 주요 거래 아이템(아데나, 기타) 외 아이템은 28일 총합\n",
    "    main_item = ['adena', 'etc']\n",
    "    item_list = []\n",
    "    for item in main_item:\n",
    "        for i in range(0, len(trade_data.columns)):\n",
    "            if(item in trade_data.columns[i]):\n",
    "                item_list.append(i)                \n",
    "    trade_data_sub = trade_data.iloc[:, item_list]\n",
    "    \n",
    "    sub_item = ['weapon', 'armor', 'accessory', 'spell', 'enchant_scroll']\n",
    "    for item in sub_item:\n",
    "        item_list = []\n",
    "        for i in range(0, len(trade_data.columns)):\n",
    "            if(item in trade_data.columns[i]):\n",
    "                item_list.append(i) \n",
    "        colname1 = 'source_price_' + item\n",
    "        colname2 = 'source_amount_' + item\n",
    "        colname3 = 'target_price_' + item\n",
    "        colname4 = 'target_amount_' + item\n",
    "        trade_data_sub[colname1] = trade_data.iloc[:, item_list].iloc[:, :4].sum(axis = 1)\n",
    "        trade_data_sub[colname2] = trade_data.iloc[:, item_list].iloc[:, 4:8].sum(axis = 1)\n",
    "        trade_data_sub[colname3] = trade_data.iloc[:, item_list].iloc[:, 8:12].sum(axis = 1)\n",
    "        trade_data_sub[colname4] = trade_data.iloc[:, item_list].iloc[:, 12:].sum(axis = 1)\n",
    "    \n",
    "    \n",
    "    trade_data_sub['acc_id'] = trade_data['acc_id']\n",
    "    \n",
    "    data = pd.merge(data, trade_data_sub, how = 'left', on = 'acc_id')\n",
    "        \n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 혈맹에 대한 군집 형성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = []\n",
    "for i in range(0, len(train3)):\n",
    "    if(train3['acc_id'][i] in train_id):\n",
    "        index_list.append(i)            \n",
    "train3_sub = train3.loc[index_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "play_char_cnt done\n",
      "combat_char_cnt done\n",
      "pledge_combat_cnt done\n",
      "random_attacker_cnt done\n",
      "random_defender_cnt done\n",
      "same_pledge_cnt done\n",
      "temp_cnt done\n",
      "etc_cnt done\n",
      "combat_play_time done\n"
     ]
    }
   ],
   "source": [
    "dic = {}\n",
    "train3_col = train3_sub.columns[5:-1]\n",
    "\n",
    "for var_name in train3_col:\n",
    "    week_1, week_2, week_3, week_4 = pledge_divide_by_week(data = train3_sub, variable = var_name)\n",
    "    key_1 = var_name + '_1'\n",
    "    key_2 = var_name + '_2'\n",
    "    key_3 = var_name + '_3'\n",
    "    key_4 = var_name + '_4'\n",
    "    dic[key_1] = week_1\n",
    "    dic[key_2] = week_2\n",
    "    dic[key_3] = week_3\n",
    "    dic[key_4] = week_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pledge_id = train3_sub['pledge_id'].unique()\n",
    "pledge_id.sort()\n",
    "pledge_id_clone = pledge_id.copy()\n",
    "pledge_data_array = pledge_id_clone.reshape(-1, 1)\n",
    "\n",
    "for key in dic.keys():\n",
    "    pledge_data_array = np.concatenate([pledge_data_array, dic[key].reshape(-1, 1)], axis = 1)\n",
    "        \n",
    "colnames = ['pledge_id']\n",
    "colnames.extend(list(dic.keys())[0:])\n",
    "\n",
    "pledge_data = pd.DataFrame(pledge_data_array)\n",
    "pledge_data.columns = colnames\n",
    "pledge_data = pledge_data.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이상치 대체"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 혈맹 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### random_attacker_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train3_sub_day_1 = train3_sub[(train3_sub['day'] == 1) | (train3_sub['day'] == 8)]\n",
    "train3_sub_day_2 = train3_sub[(train3_sub['day'] == 2) | (train3_sub['day'] == 9)]\n",
    "train3_sub_day_3 = train3_sub[(train3_sub['day'] == 3) | (train3_sub['day'] == 10)]\n",
    "train3_sub_day_4 = train3_sub[(train3_sub['day'] == 4) | (train3_sub['day'] == 11)]\n",
    "train3_sub_day_5 = train3_sub[(train3_sub['day'] == 5) | (train3_sub['day'] == 12)]\n",
    "train3_sub_day_6 = train3_sub[(train3_sub['day'] == 6) | (train3_sub['day'] == 13)]\n",
    "train3_sub_day_7 = train3_sub[(train3_sub['day'] == 7) | (train3_sub['day'] == 14)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user3/anaconda3/bigcontest/preprocess:18: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/home/user3/anaconda3/bigcontest/preprocess:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "train3_sub_day_6_mean = train3_sub_day_6.groupby('pledge_id')['random_attacker_cnt'].mean()\n",
    "train3_sub_day_6_mean = pd.DataFrame(train3_sub_day_6_mean)\n",
    "train3_sub_day_6_mean.columns = ['random_attacker_cnt_new']\n",
    "val6 = pd.merge(train3_sub[train3_sub['day'] == 20], train3_sub_day_6_mean, how = 'left', on = 'pledge_id')\n",
    "val6 = val6.fillna(0)\n",
    "\n",
    "train3_sub_day_7_mean = train3_sub_day_7.groupby('pledge_id')['random_attacker_cnt'].mean()\n",
    "train3_sub_day_7_mean = pd.DataFrame(train3_sub_day_7_mean)\n",
    "train3_sub_day_7_mean.columns = ['random_attacker_cnt_new']\n",
    "val7 = pd.merge(train3_sub[train3_sub['day'] == 21], train3_sub_day_7_mean, how = 'left', on = 'pledge_id')\n",
    "val7 = val7.fillna(0)\n",
    "\n",
    "val1 = train3_sub[train3_sub['day'] == 15]\n",
    "val2 = train3_sub[train3_sub['day'] == 16]\n",
    "val3 = train3_sub[train3_sub['day'] == 17]\n",
    "val4 = train3_sub[train3_sub['day'] == 18]\n",
    "val5 = train3_sub[train3_sub['day'] == 19]\n",
    "val = pd.concat([val1, val2, val3, val4, val5, val6, val7], axis = 0, ignore_index = True)\n",
    "\n",
    "val['random_attacker_cnt_new'][val['random_attacker_cnt_new'].isna()] = val['random_attacker_cnt'][val['random_attacker_cnt_new'].isna()]\n",
    "random_attacker_cnt_3_new = val.groupby('pledge_id')['random_attacker_cnt_new'].mean()\n",
    "pledge_data = pd.merge(pledge_data, random_attacker_cnt_3_new, how = 'left', on = 'pledge_id')\n",
    "pledge_data['random_attacker_cnt_3'][~pledge_data['random_attacker_cnt_new'].isna()] = pledge_data['random_attacker_cnt_new'][~pledge_data['random_attacker_cnt_new'].isna()]\n",
    "pledge_data = pledge_data.drop('random_attacker_cnt_new', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user3/anaconda3/bigcontest/preprocess:13: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/home/user3/anaconda3/bigcontest/preprocess:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "train3_sub_day_1_mean = train3_sub_day_1.groupby('pledge_id')['random_attacker_cnt'].mean()\n",
    "train3_sub_day_1_mean = pd.DataFrame(train3_sub_day_1_mean)\n",
    "train3_sub_day_1_mean.columns = ['random_attacker_cnt_new']\n",
    "val1 = pd.merge(train3_sub[train3_sub['day'] == 22], train3_sub_day_1_mean, how = 'left', on = 'pledge_id')\n",
    "val1 = val1.fillna(0)\n",
    "\n",
    "val2 = train3_sub[train3_sub['day'] == 23]\n",
    "val3 = train3_sub[train3_sub['day'] == 24]\n",
    "val4 = train3_sub[train3_sub['day'] == 25]\n",
    "val5 = train3_sub[train3_sub['day'] == 26]\n",
    "val6 = train3_sub[train3_sub['day'] == 27]\n",
    "val7 = train3_sub[train3_sub['day'] == 28]\n",
    "val = pd.concat([val1, val2, val3, val4, val5, val6, val7], axis = 0, ignore_index = True)\n",
    "\n",
    "val['random_attacker_cnt_new'][val['random_attacker_cnt_new'].isna()] = val['random_attacker_cnt'][val['random_attacker_cnt_new'].isna()]\n",
    "random_attacker_cnt_4_new = val.groupby('pledge_id')['random_attacker_cnt_new'].mean()\n",
    "pledge_data = pd.merge(pledge_data, random_attacker_cnt_4_new, how = 'left', on = 'pledge_id')\n",
    "pledge_data['random_attacker_cnt_4'][~pledge_data['random_attacker_cnt_new'].isna()] = pledge_data['random_attacker_cnt_new'][~pledge_data['random_attacker_cnt_new'].isna()]\n",
    "pledge_data = pledge_data.drop('random_attacker_cnt_new', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### same_pledge_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pledge_data['same_pledge_cnt_1'] = (pledge_data['same_pledge_cnt_2'] + pledge_data['same_pledge_cnt_3'] + pledge_data['same_pledge_cnt_4']) / 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### temp_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train3_sub_day_1 = train3_sub[(train3_sub['day'] == 1) | (train3_sub['day'] == 8) | (train3_sub['day'] == 15)]\n",
    "train3_sub_day_2 = train3_sub[(train3_sub['day'] == 2) | (train3_sub['day'] == 9) | (train3_sub['day'] == 16)]\n",
    "train3_sub_day_3 = train3_sub[(train3_sub['day'] == 3) | (train3_sub['day'] == 10) | (train3_sub['day'] == 17)]\n",
    "train3_sub_day_4 = train3_sub[(train3_sub['day'] == 4) | (train3_sub['day'] == 11) | (train3_sub['day'] == 18)]\n",
    "train3_sub_day_5 = train3_sub[(train3_sub['day'] == 5) | (train3_sub['day'] == 12) | (train3_sub['day'] == 19)]\n",
    "train3_sub_day_6 = train3_sub[(train3_sub['day'] == 6) | (train3_sub['day'] == 13) | (train3_sub['day'] == 20)]\n",
    "train3_sub_day_7 = train3_sub[(train3_sub['day'] == 7) | (train3_sub['day'] == 14) | (train3_sub['day'] == 21)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user3/anaconda3/bigcontest/preprocess:38: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/home/user3/anaconda3/bigcontest/preprocess:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "train3_sub_day_2_mean = train3_sub_day_2.groupby('pledge_id')['temp_cnt'].mean()\n",
    "train3_sub_day_2_mean = pd.DataFrame(train3_sub_day_2_mean)\n",
    "train3_sub_day_2_mean.columns = ['temp_cnt_new']\n",
    "val2 = pd.merge(train3_sub[train3_sub['day'] == 23], train3_sub_day_2_mean, how = 'left', on = 'pledge_id')\n",
    "val2 = val2.fillna(0)\n",
    "\n",
    "train3_sub_day_3_mean = train3_sub_day_3.groupby('pledge_id')['temp_cnt'].mean()\n",
    "train3_sub_day_3_mean = pd.DataFrame(train3_sub_day_3_mean)\n",
    "train3_sub_day_3_mean.columns = ['temp_cnt_new']\n",
    "val3 = pd.merge(train3_sub[train3_sub['day'] == 24], train3_sub_day_3_mean, how = 'left', on = 'pledge_id')\n",
    "val3 = val3.fillna(0)\n",
    "\n",
    "train3_sub_day_4_mean = train3_sub_day_4.groupby('pledge_id')['temp_cnt'].mean()\n",
    "train3_sub_day_4_mean = pd.DataFrame(train3_sub_day_4_mean)\n",
    "train3_sub_day_4_mean.columns = ['temp_cnt_new']\n",
    "val4 = pd.merge(train3_sub[train3_sub['day'] == 25], train3_sub_day_4_mean, how = 'left', on = 'pledge_id')\n",
    "val4 = val4.fillna(0)\n",
    "\n",
    "train3_sub_day_5_mean = train3_sub_day_5.groupby('pledge_id')['temp_cnt'].mean()\n",
    "train3_sub_day_5_mean = pd.DataFrame(train3_sub_day_5_mean)\n",
    "train3_sub_day_5_mean.columns = ['temp_cnt_new']\n",
    "val5 = pd.merge(train3_sub[train3_sub['day'] == 26], train3_sub_day_5_mean, how = 'left', on = 'pledge_id')\n",
    "val5 = val5.fillna(0)\n",
    "\n",
    "train3_sub_day_6_mean = train3_sub_day_6.groupby('pledge_id')['temp_cnt'].mean()\n",
    "train3_sub_day_6_mean = pd.DataFrame(train3_sub_day_6_mean)\n",
    "train3_sub_day_6_mean.columns = ['temp_cnt_new']\n",
    "val6 = pd.merge(train3_sub[train3_sub['day'] == 27], train3_sub_day_6_mean, how = 'left', on = 'pledge_id')\n",
    "val6 = val6.fillna(0)\n",
    "\n",
    "train3_sub_day_7_mean = train3_sub_day_7.groupby('pledge_id')['temp_cnt'].mean()\n",
    "train3_sub_day_7_mean = pd.DataFrame(train3_sub_day_7_mean)\n",
    "train3_sub_day_7_mean.columns = ['temp_cnt_new']\n",
    "val7 = pd.merge(train3_sub[train3_sub['day'] == 28], train3_sub_day_7_mean, how = 'left', on = 'pledge_id')\n",
    "val7 = val7.fillna(0)\n",
    "\n",
    "val1 = train3_sub[train3_sub['day'] == 22]\n",
    "val = pd.concat([val1, val2, val3, val4, val5, val6, val7], axis = 0, ignore_index = True)\n",
    "\n",
    "val['temp_cnt_new'][val['temp_cnt_new'].isna()] = val['temp_cnt'][val['temp_cnt_new'].isna()]\n",
    "temp_cnt_4_new = val.groupby('pledge_id')['temp_cnt_new'].mean()\n",
    "pledge_data = pd.merge(pledge_data, temp_cnt_4_new, how = 'left', on = 'pledge_id')\n",
    "pledge_data['temp_cnt_4'][~pledge_data['temp_cnt_new'].isna()] = pledge_data['temp_cnt_new'][~pledge_data['temp_cnt_new'].isna()]\n",
    "pledge_data = pledge_data.drop('temp_cnt_new', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "       n_clusters=3, n_init=10, n_jobs=-1, precompute_distances='auto',\n",
       "       random_state=42, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "X = pledge_data.iloc[:, 1:]\n",
    "kmean = KMeans(n_clusters = 3, random_state = 42, n_jobs = -1)\n",
    "kmean.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## raw data -> 전처리 데이터 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 자체 train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "playtime done\n",
      "npc_kill done\n",
      "solo_exp done\n",
      "party_exp done\n",
      "quest_exp done\n",
      "rich_monster done\n",
      "death done\n",
      "revive done\n",
      "exp_recovery done\n",
      "fishing done\n",
      "private_shop done\n",
      "game_money_change done\n",
      "enchant_count done\n",
      "pledge_cnt done\n",
      "random_attacker_cnt done\n",
      "random_defender_cnt done\n",
      "temp_cnt done\n",
      "same_pledge_cnt done\n",
      "etc_cnt done\n",
      "num_opponent done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user3/anaconda3/envs/hun/lib/python3.6/site-packages/numpy/core/fromnumeric.py:56: FutureWarning: \n",
      "The current behaviour of 'Series.argmax' is deprecated, use 'idxmax'\n",
      "instead.\n",
      "The behavior of 'argmax' will be corrected to return the positional\n",
      "maximum in the future. For now, use 'series.values.argmax' or\n",
      "'np.argmax(np.array(values))' to get the position of the maximum\n",
      "row.\n",
      "  return getattr(obj, method)(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "play_char_cnt done\n",
      "combat_char_cnt done\n",
      "pledge_combat_cnt done\n",
      "random_attacker_cnt done\n",
      "random_defender_cnt done\n",
      "same_pledge_cnt done\n",
      "temp_cnt done\n",
      "etc_cnt done\n",
      "combat_play_time done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user3/anaconda3/bigcontest/preprocess:166: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/home/user3/anaconda3/bigcontest/preprocess:168: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/user3/anaconda3/bigcontest/preprocess:187: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/home/user3/anaconda3/bigcontest/preprocess:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/user3/anaconda3/bigcontest/preprocess:244: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/home/user3/anaconda3/bigcontest/preprocess:246: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/user3/anaconda3/envs/hun/lib/python3.6/site-packages/numpy/core/fromnumeric.py:56: FutureWarning: \n",
      "The current behaviour of 'Series.argmax' is deprecated, use 'idxmax'\n",
      "instead.\n",
      "The behavior of 'argmax' will be corrected to return the positional\n",
      "maximum in the future. For now, use 'series.values.argmax' or\n",
      "'np.argmax(np.array(values))' to get the position of the maximum\n",
      "row.\n",
      "  return getattr(obj, method)(*args, **kwds)\n",
      "/home/user3/anaconda3/bigcontest/preprocess:302: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/user3/anaconda3/bigcontest/preprocess:303: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/user3/anaconda3/bigcontest/preprocess:405: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/user3/anaconda3/bigcontest/preprocess:406: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/user3/anaconda3/bigcontest/preprocess:407: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/user3/anaconda3/bigcontest/preprocess:408: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/user3/anaconda3/bigcontest/preprocess:411: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "X_train = preprocess(train1, train2, train3, train4, train5, train_id, train = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_id</th>\n",
       "      <th>level</th>\n",
       "      <th>playtime_1</th>\n",
       "      <th>playtime_2</th>\n",
       "      <th>playtime_3</th>\n",
       "      <th>playtime_4</th>\n",
       "      <th>npc_kill_1</th>\n",
       "      <th>npc_kill_2</th>\n",
       "      <th>npc_kill_3</th>\n",
       "      <th>npc_kill_4</th>\n",
       "      <th>...</th>\n",
       "      <th>target_price_accessory</th>\n",
       "      <th>target_amount_accessory</th>\n",
       "      <th>source_price_spell</th>\n",
       "      <th>source_amount_spell</th>\n",
       "      <th>target_price_spell</th>\n",
       "      <th>target_amount_spell</th>\n",
       "      <th>source_price_enchant_scroll</th>\n",
       "      <th>source_amount_enchant_scroll</th>\n",
       "      <th>target_price_enchant_scroll</th>\n",
       "      <th>target_amount_enchant_scroll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>22.919696</td>\n",
       "      <td>22.980553</td>\n",
       "      <td>22.659883</td>\n",
       "      <td>22.973531</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.589845</td>\n",
       "      <td>0.213000</td>\n",
       "      <td>5.313287</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.310229</td>\n",
       "      <td>0.162887</td>\n",
       "      <td>2.763336</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>16</td>\n",
       "      <td>4.987936</td>\n",
       "      <td>4.889629</td>\n",
       "      <td>4.653223</td>\n",
       "      <td>4.267014</td>\n",
       "      <td>26.808113</td>\n",
       "      <td>1.325063</td>\n",
       "      <td>1.444694</td>\n",
       "      <td>1.594739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.793968e-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.0</td>\n",
       "      <td>16</td>\n",
       "      <td>5.406914</td>\n",
       "      <td>9.048973</td>\n",
       "      <td>7.831832</td>\n",
       "      <td>6.176989</td>\n",
       "      <td>25.931158</td>\n",
       "      <td>1.328780</td>\n",
       "      <td>1.362575</td>\n",
       "      <td>1.834339</td>\n",
       "      <td>...</td>\n",
       "      <td>1.099013</td>\n",
       "      <td>4.793968e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.019241</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.314571e-07</td>\n",
       "      <td>0.014515</td>\n",
       "      <td>1.174522e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21.0</td>\n",
       "      <td>16</td>\n",
       "      <td>6.048253</td>\n",
       "      <td>7.363701</td>\n",
       "      <td>4.966870</td>\n",
       "      <td>3.452466</td>\n",
       "      <td>4.379366</td>\n",
       "      <td>4.602406</td>\n",
       "      <td>0.654252</td>\n",
       "      <td>1.135141</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062655</td>\n",
       "      <td>2.396984e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.369100</td>\n",
       "      <td>6.471857e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 151 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   acc_id  level  playtime_1  playtime_2  playtime_3  playtime_4  npc_kill_1  \\\n",
       "0     2.0      0   22.919696   22.980553   22.659883   22.973531    0.000000   \n",
       "1     5.0     15    0.000000    0.589845    0.213000    5.313287    0.000000   \n",
       "2     8.0     16    4.987936    4.889629    4.653223    4.267014   26.808113   \n",
       "3    17.0     16    5.406914    9.048973    7.831832    6.176989   25.931158   \n",
       "4    21.0     16    6.048253    7.363701    4.966870    3.452466    4.379366   \n",
       "\n",
       "   npc_kill_2  npc_kill_3  npc_kill_4  ...  target_price_accessory  \\\n",
       "0    0.000000    0.000000    0.000000  ...                0.000000   \n",
       "1    0.310229    0.162887    2.763336  ...                0.000000   \n",
       "2    1.325063    1.444694    1.594739  ...                0.000000   \n",
       "3    1.328780    1.362575    1.834339  ...                1.099013   \n",
       "4    4.602406    0.654252    1.135141  ...                0.062655   \n",
       "\n",
       "   target_amount_accessory  source_price_spell  source_amount_spell  \\\n",
       "0             0.000000e+00                 0.0         0.000000e+00   \n",
       "1             0.000000e+00                 0.0         0.000000e+00   \n",
       "2             0.000000e+00                 0.0         4.793968e-08   \n",
       "3             4.793968e-08                 0.0         0.000000e+00   \n",
       "4             2.396984e-08                 0.0         0.000000e+00   \n",
       "\n",
       "   target_price_spell  target_amount_spell  source_price_enchant_scroll  \\\n",
       "0            0.000000             0.000000                          0.0   \n",
       "1            0.000000             0.000000                          0.0   \n",
       "2            0.000000             0.000000                          0.0   \n",
       "3            0.019241             0.000002                          0.0   \n",
       "4            0.000000             0.000000                          0.0   \n",
       "\n",
       "   source_amount_enchant_scroll  target_price_enchant_scroll  \\\n",
       "0                  0.000000e+00                     0.000000   \n",
       "1                  0.000000e+00                     0.000000   \n",
       "2                  0.000000e+00                     0.000000   \n",
       "3                  4.314571e-07                     0.014515   \n",
       "4                  0.000000e+00                     0.369100   \n",
       "\n",
       "   target_amount_enchant_scroll  \n",
       "0                  0.000000e+00  \n",
       "1                  0.000000e+00  \n",
       "2                  0.000000e+00  \n",
       "3                  1.174522e-06  \n",
       "4                  6.471857e-07  \n",
       "\n",
       "[5 rows x 151 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['acc_id', 'level', 'playtime_1', 'playtime_2', 'playtime_3',\n",
       "       'playtime_4', 'npc_kill_1', 'npc_kill_2', 'npc_kill_3',\n",
       "       'npc_kill_4', 'solo_exp_1', 'solo_exp_2', 'solo_exp_3',\n",
       "       'solo_exp_4', 'party_exp_1', 'party_exp_2', 'party_exp_3',\n",
       "       'party_exp_4', 'quest_exp_1', 'quest_exp_2', 'quest_exp_3',\n",
       "       'quest_exp_4', 'rich_monster_1', 'rich_monster_2',\n",
       "       'rich_monster_3', 'rich_monster_4', 'death_1', 'death_2',\n",
       "       'death_3', 'death_4', 'revive_1', 'revive_2', 'revive_3',\n",
       "       'revive_4', 'exp_recovery_1', 'exp_recovery_2', 'exp_recovery_3',\n",
       "       'exp_recovery_4', 'fishing_1', 'fishing_2', 'fishing_3',\n",
       "       'fishing_4', 'private_shop_1', 'private_shop_2', 'private_shop_3',\n",
       "       'private_shop_4', 'game_money_change_1', 'game_money_change_2',\n",
       "       'game_money_change_3', 'game_money_change_4', 'enchant_count_1',\n",
       "       'enchant_count_2', 'enchant_count_3', 'enchant_count_4',\n",
       "       'combat_pledge_cnt_1', 'combat_pledge_cnt_2',\n",
       "       'combat_pledge_cnt_3', 'combat_pledge_cnt_4',\n",
       "       'combat_random_attacker_cnt_1', 'combat_random_attacker_cnt_2',\n",
       "       'combat_random_attacker_cnt_3', 'combat_random_attacker_cnt_4',\n",
       "       'combat_random_defender_cnt_1', 'combat_random_defender_cnt_2',\n",
       "       'combat_random_defender_cnt_3', 'combat_random_defender_cnt_4',\n",
       "       'combat_temp_cnt_1', 'combat_temp_cnt_2', 'combat_temp_cnt_3',\n",
       "       'combat_temp_cnt_4', 'combat_same_pledge_cnt_1',\n",
       "       'combat_same_pledge_cnt_2', 'combat_same_pledge_cnt_3',\n",
       "       'combat_same_pledge_cnt_4', 'combat_etc_cnt_1', 'combat_etc_cnt_2',\n",
       "       'combat_etc_cnt_3', 'combat_etc_cnt_4', 'combat_num_opponent_1',\n",
       "       'combat_num_opponent_2', 'combat_num_opponent_3',\n",
       "       'combat_num_opponent_4', 'amount_cnt', 'amount_mean',\n",
       "       'server_group_0', 'server_group_1', 'server_group_2', 'class_0',\n",
       "       'class_1', 'class_2', 'class_3', 'class_4', 'class_5', 'class_6',\n",
       "       'class_7', 'pledge_group_0', 'pledge_group_1', 'pledge_group_2',\n",
       "       'pledge_group_3', 'source_price_adena_1', 'source_price_adena_2',\n",
       "       'source_price_adena_3', 'source_price_adena_4',\n",
       "       'source_amount_adena_1', 'source_amount_adena_2',\n",
       "       'source_amount_adena_3', 'source_amount_adena_4',\n",
       "       'target_price_adena_1', 'target_price_adena_2',\n",
       "       'target_price_adena_3', 'target_price_adena_4',\n",
       "       'target_amount_adena_1', 'target_amount_adena_2',\n",
       "       'target_amount_adena_3', 'target_amount_adena_4',\n",
       "       'source_price_etc_1', 'source_price_etc_2', 'source_price_etc_3',\n",
       "       'source_price_etc_4', 'source_amount_etc_1', 'source_amount_etc_2',\n",
       "       'source_amount_etc_3', 'source_amount_etc_4', 'target_price_etc_1',\n",
       "       'target_price_etc_2', 'target_price_etc_3', 'target_price_etc_4',\n",
       "       'target_amount_etc_1', 'target_amount_etc_2',\n",
       "       'target_amount_etc_3', 'target_amount_etc_4',\n",
       "       'source_price_weapon', 'source_amount_weapon',\n",
       "       'target_price_weapon', 'target_amount_weapon',\n",
       "       'source_price_armor', 'source_amount_armor', 'target_price_armor',\n",
       "       'target_amount_armor', 'source_price_accessory',\n",
       "       'source_amount_accessory', 'target_price_accessory',\n",
       "       'target_amount_accessory', 'source_price_spell',\n",
       "       'source_amount_spell', 'target_price_spell', 'target_amount_spell',\n",
       "       'source_price_enchant_scroll', 'source_amount_enchant_scroll',\n",
       "       'target_price_enchant_scroll', 'target_amount_enchant_scroll'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 자체 test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "playtime done\n",
      "npc_kill done\n",
      "solo_exp done\n",
      "party_exp done\n",
      "quest_exp done\n",
      "rich_monster done\n",
      "death done\n",
      "revive done\n",
      "exp_recovery done\n",
      "fishing done\n",
      "private_shop done\n",
      "game_money_change done\n",
      "enchant_count done\n",
      "pledge_cnt done\n",
      "random_attacker_cnt done\n",
      "random_defender_cnt done\n",
      "temp_cnt done\n",
      "same_pledge_cnt done\n",
      "etc_cnt done\n",
      "num_opponent done\n",
      "play_char_cnt done\n",
      "combat_char_cnt done\n",
      "pledge_combat_cnt done\n",
      "random_attacker_cnt done\n",
      "random_defender_cnt done\n",
      "same_pledge_cnt done\n",
      "temp_cnt done\n",
      "etc_cnt done\n",
      "combat_play_time done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user3/anaconda3/bigcontest/preprocess:166: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/home/user3/anaconda3/bigcontest/preprocess:168: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/user3/anaconda3/bigcontest/preprocess:187: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/home/user3/anaconda3/bigcontest/preprocess:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/user3/anaconda3/bigcontest/preprocess:244: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/home/user3/anaconda3/bigcontest/preprocess:246: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/user3/anaconda3/envs/hun/lib/python3.6/site-packages/numpy/core/fromnumeric.py:56: FutureWarning: \n",
      "The current behaviour of 'Series.argmax' is deprecated, use 'idxmax'\n",
      "instead.\n",
      "The behavior of 'argmax' will be corrected to return the positional\n",
      "maximum in the future. For now, use 'series.values.argmax' or\n",
      "'np.argmax(np.array(values))' to get the position of the maximum\n",
      "row.\n",
      "  return getattr(obj, method)(*args, **kwds)\n",
      "/home/user3/anaconda3/bigcontest/preprocess:302: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/user3/anaconda3/bigcontest/preprocess:303: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/user3/anaconda3/bigcontest/preprocess:405: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/user3/anaconda3/bigcontest/preprocess:406: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/user3/anaconda3/bigcontest/preprocess:407: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/user3/anaconda3/bigcontest/preprocess:408: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/user3/anaconda3/bigcontest/preprocess:411: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "X_test = preprocess(train1, train2, train3, train4, train5, test_id, train = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_id</th>\n",
       "      <th>level</th>\n",
       "      <th>playtime_1</th>\n",
       "      <th>playtime_2</th>\n",
       "      <th>playtime_3</th>\n",
       "      <th>playtime_4</th>\n",
       "      <th>npc_kill_1</th>\n",
       "      <th>npc_kill_2</th>\n",
       "      <th>npc_kill_3</th>\n",
       "      <th>npc_kill_4</th>\n",
       "      <th>...</th>\n",
       "      <th>target_price_accessory</th>\n",
       "      <th>target_amount_accessory</th>\n",
       "      <th>source_price_spell</th>\n",
       "      <th>source_amount_spell</th>\n",
       "      <th>target_price_spell</th>\n",
       "      <th>target_amount_spell</th>\n",
       "      <th>source_price_enchant_scroll</th>\n",
       "      <th>source_amount_enchant_scroll</th>\n",
       "      <th>target_price_enchant_scroll</th>\n",
       "      <th>target_amount_enchant_scroll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>17</td>\n",
       "      <td>5.526287</td>\n",
       "      <td>7.014944</td>\n",
       "      <td>3.508642</td>\n",
       "      <td>9.538170</td>\n",
       "      <td>27.285960</td>\n",
       "      <td>1.631575</td>\n",
       "      <td>1.581222</td>\n",
       "      <td>3.601428</td>\n",
       "      <td>...</td>\n",
       "      <td>1.614389</td>\n",
       "      <td>2.396984e-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.722974</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62.0</td>\n",
       "      <td>16</td>\n",
       "      <td>8.983435</td>\n",
       "      <td>11.438782</td>\n",
       "      <td>7.651602</td>\n",
       "      <td>9.952466</td>\n",
       "      <td>27.273118</td>\n",
       "      <td>0.949612</td>\n",
       "      <td>0.734682</td>\n",
       "      <td>1.747826</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.190952e-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.478719</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81.0</td>\n",
       "      <td>16</td>\n",
       "      <td>7.007922</td>\n",
       "      <td>12.358660</td>\n",
       "      <td>11.382606</td>\n",
       "      <td>10.820849</td>\n",
       "      <td>29.873229</td>\n",
       "      <td>4.915677</td>\n",
       "      <td>3.930919</td>\n",
       "      <td>4.844371</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.030327</td>\n",
       "      <td>2.396984e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>86.0</td>\n",
       "      <td>0</td>\n",
       "      <td>22.800322</td>\n",
       "      <td>22.971190</td>\n",
       "      <td>22.510081</td>\n",
       "      <td>22.964168</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>34.342724</td>\n",
       "      <td>5.033666e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.396984e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>125.0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.414296</td>\n",
       "      <td>0.154483</td>\n",
       "      <td>0.482175</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088540</td>\n",
       "      <td>0.023994</td>\n",
       "      <td>0.487648</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.364684</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 151 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   acc_id  level  playtime_1  playtime_2  playtime_3  playtime_4  npc_kill_1  \\\n",
       "0    20.0     17    5.526287    7.014944    3.508642    9.538170   27.285960   \n",
       "1    62.0     16    8.983435   11.438782    7.651602    9.952466   27.273118   \n",
       "2    81.0     16    7.007922   12.358660   11.382606   10.820849   29.873229   \n",
       "3    86.0      0   22.800322   22.971190   22.510081   22.964168    0.000000   \n",
       "4   125.0     16    0.000000    0.414296    0.154483    0.482175    0.000000   \n",
       "\n",
       "   npc_kill_2  npc_kill_3  npc_kill_4  ...  target_price_accessory  \\\n",
       "0    1.631575    1.581222    3.601428  ...                1.614389   \n",
       "1    0.949612    0.734682    1.747826  ...                0.000000   \n",
       "2    4.915677    3.930919    4.844371  ...                0.000000   \n",
       "3    0.000000    0.000000    0.000000  ...                0.000000   \n",
       "4    0.088540    0.023994    0.487648  ...                0.000000   \n",
       "\n",
       "   target_amount_accessory  source_price_spell  source_amount_spell  \\\n",
       "0             2.396984e-08            0.000000         0.000000e+00   \n",
       "1             7.190952e-08            0.000000         0.000000e+00   \n",
       "2             0.000000e+00            0.000000         0.000000e+00   \n",
       "3             0.000000e+00           34.342724         5.033666e-07   \n",
       "4             0.000000e+00            0.000000         0.000000e+00   \n",
       "\n",
       "   target_price_spell  target_amount_spell  source_price_enchant_scroll  \\\n",
       "0            0.000000         0.000000e+00                          0.0   \n",
       "1            0.000000         0.000000e+00                          0.0   \n",
       "2            0.030327         2.396984e-08                          0.0   \n",
       "3            0.000000         2.396984e-08                          0.0   \n",
       "4            0.000000         0.000000e+00                          0.0   \n",
       "\n",
       "   source_amount_enchant_scroll  target_price_enchant_scroll  \\\n",
       "0                           0.0                     1.722974   \n",
       "1                           0.0                     0.478719   \n",
       "2                           0.0                     0.000000   \n",
       "3                           0.0                     0.000000   \n",
       "4                           0.0                     0.364684   \n",
       "\n",
       "   target_amount_enchant_scroll  \n",
       "0                      0.000001  \n",
       "1                      0.000004  \n",
       "2                      0.000000  \n",
       "3                      0.000000  \n",
       "4                      0.000001  \n",
       "\n",
       "[5 rows x 151 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['acc_id', 'level', 'playtime_1', 'playtime_2', 'playtime_3',\n",
       "       'playtime_4', 'npc_kill_1', 'npc_kill_2', 'npc_kill_3',\n",
       "       'npc_kill_4', 'solo_exp_1', 'solo_exp_2', 'solo_exp_3',\n",
       "       'solo_exp_4', 'party_exp_1', 'party_exp_2', 'party_exp_3',\n",
       "       'party_exp_4', 'quest_exp_1', 'quest_exp_2', 'quest_exp_3',\n",
       "       'quest_exp_4', 'rich_monster_1', 'rich_monster_2',\n",
       "       'rich_monster_3', 'rich_monster_4', 'death_1', 'death_2',\n",
       "       'death_3', 'death_4', 'revive_1', 'revive_2', 'revive_3',\n",
       "       'revive_4', 'exp_recovery_1', 'exp_recovery_2', 'exp_recovery_3',\n",
       "       'exp_recovery_4', 'fishing_1', 'fishing_2', 'fishing_3',\n",
       "       'fishing_4', 'private_shop_1', 'private_shop_2', 'private_shop_3',\n",
       "       'private_shop_4', 'game_money_change_1', 'game_money_change_2',\n",
       "       'game_money_change_3', 'game_money_change_4', 'enchant_count_1',\n",
       "       'enchant_count_2', 'enchant_count_3', 'enchant_count_4',\n",
       "       'combat_pledge_cnt_1', 'combat_pledge_cnt_2',\n",
       "       'combat_pledge_cnt_3', 'combat_pledge_cnt_4',\n",
       "       'combat_random_attacker_cnt_1', 'combat_random_attacker_cnt_2',\n",
       "       'combat_random_attacker_cnt_3', 'combat_random_attacker_cnt_4',\n",
       "       'combat_random_defender_cnt_1', 'combat_random_defender_cnt_2',\n",
       "       'combat_random_defender_cnt_3', 'combat_random_defender_cnt_4',\n",
       "       'combat_temp_cnt_1', 'combat_temp_cnt_2', 'combat_temp_cnt_3',\n",
       "       'combat_temp_cnt_4', 'combat_same_pledge_cnt_1',\n",
       "       'combat_same_pledge_cnt_2', 'combat_same_pledge_cnt_3',\n",
       "       'combat_same_pledge_cnt_4', 'combat_etc_cnt_1', 'combat_etc_cnt_2',\n",
       "       'combat_etc_cnt_3', 'combat_etc_cnt_4', 'combat_num_opponent_1',\n",
       "       'combat_num_opponent_2', 'combat_num_opponent_3',\n",
       "       'combat_num_opponent_4', 'amount_cnt', 'amount_mean',\n",
       "       'server_group_0', 'server_group_1', 'server_group_2', 'class_0',\n",
       "       'class_1', 'class_2', 'class_3', 'class_4', 'class_5', 'class_6',\n",
       "       'class_7', 'pledge_group_0', 'pledge_group_1', 'pledge_group_2',\n",
       "       'pledge_group_3', 'source_price_adena_1', 'source_price_adena_2',\n",
       "       'source_price_adena_3', 'source_price_adena_4',\n",
       "       'source_amount_adena_1', 'source_amount_adena_2',\n",
       "       'source_amount_adena_3', 'source_amount_adena_4',\n",
       "       'target_price_adena_1', 'target_price_adena_2',\n",
       "       'target_price_adena_3', 'target_price_adena_4',\n",
       "       'target_amount_adena_1', 'target_amount_adena_2',\n",
       "       'target_amount_adena_3', 'target_amount_adena_4',\n",
       "       'source_price_etc_1', 'source_price_etc_2', 'source_price_etc_3',\n",
       "       'source_price_etc_4', 'source_amount_etc_1', 'source_amount_etc_2',\n",
       "       'source_amount_etc_3', 'source_amount_etc_4', 'target_price_etc_1',\n",
       "       'target_price_etc_2', 'target_price_etc_3', 'target_price_etc_4',\n",
       "       'target_amount_etc_1', 'target_amount_etc_2',\n",
       "       'target_amount_etc_3', 'target_amount_etc_4',\n",
       "       'source_price_weapon', 'source_amount_weapon',\n",
       "       'target_price_weapon', 'target_amount_weapon',\n",
       "       'source_price_armor', 'source_amount_armor', 'target_price_armor',\n",
       "       'target_amount_armor', 'source_price_accessory',\n",
       "       'source_amount_accessory', 'target_price_accessory',\n",
       "       'target_amount_accessory', 'source_price_spell',\n",
       "       'source_amount_spell', 'target_price_spell', 'target_amount_spell',\n",
       "       'source_price_enchant_scroll', 'source_amount_enchant_scroll',\n",
       "       'target_price_enchant_scroll', 'target_amount_enchant_scroll'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv('./train_preprocess_1.csv', index = False)\n",
    "X_test.to_csv('./test_preprocess_1.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test1 set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_test1_activity = os.path.join(path, 'test1_activity.csv')\n",
    "path_test1_combat = os.path.join(path, 'test1_combat.csv')\n",
    "path_test1_pledge = os.path.join(path, 'test1_pledge.csv')\n",
    "path_test1_payment = os.path.join(path, 'test1_payment.csv')\n",
    "path_test1_trade = os.path.join(path, 'test1_trade.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1_1 = pd.read_csv(path_test1_activity, engine = 'python')\n",
    "test1_2 = pd.read_csv(path_test1_combat, engine = 'python')\n",
    "test1_3 = pd.read_csv(path_test1_pledge, engine = 'python')\n",
    "test1_4 = pd.read_csv(path_test1_payment, engine = 'python')\n",
    "test1_5 = pd.read_csv(path_test1_trade, engine = 'python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     7,     15,     16, ..., 130465, 130466, 130474])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1_id = test1_1['acc_id'].unique()\n",
    "test1_id.sort()\n",
    "test1_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "playtime done\n",
      "npc_kill done\n",
      "solo_exp done\n",
      "party_exp done\n",
      "quest_exp done\n",
      "rich_monster done\n",
      "death done\n",
      "revive done\n",
      "exp_recovery done\n",
      "fishing done\n",
      "private_shop done\n",
      "game_money_change done\n",
      "enchant_count done\n",
      "pledge_cnt done\n",
      "random_attacker_cnt done\n",
      "random_defender_cnt done\n",
      "temp_cnt done\n",
      "same_pledge_cnt done\n",
      "etc_cnt done\n",
      "num_opponent done\n",
      "play_char_cnt done\n",
      "combat_char_cnt done\n",
      "pledge_combat_cnt done\n",
      "random_attacker_cnt done\n",
      "random_defender_cnt done\n",
      "same_pledge_cnt done\n",
      "temp_cnt done\n",
      "etc_cnt done\n",
      "combat_play_time done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user3/anaconda3/envs/hun/lib/python3.6/site-packages/numpy/core/fromnumeric.py:56: FutureWarning: \n",
      "The current behaviour of 'Series.argmax' is deprecated, use 'idxmax'\n",
      "instead.\n",
      "The behavior of 'argmax' will be corrected to return the positional\n",
      "maximum in the future. For now, use 'series.values.argmax' or\n",
      "'np.argmax(np.array(values))' to get the position of the maximum\n",
      "row.\n",
      "  return getattr(obj, method)(*args, **kwds)\n",
      "/home/user3/anaconda3/bigcontest/preprocess:302: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/user3/anaconda3/bigcontest/preprocess:303: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/user3/anaconda3/bigcontest/preprocess:405: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/user3/anaconda3/bigcontest/preprocess:406: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/user3/anaconda3/bigcontest/preprocess:407: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/user3/anaconda3/bigcontest/preprocess:408: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/user3/anaconda3/bigcontest/preprocess:411: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "X_test1 = preprocess(test1_1, test1_2, test1_3, test1_4, test1_5, test1_id, train = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_id</th>\n",
       "      <th>level</th>\n",
       "      <th>playtime_1</th>\n",
       "      <th>playtime_2</th>\n",
       "      <th>playtime_3</th>\n",
       "      <th>playtime_4</th>\n",
       "      <th>npc_kill_1</th>\n",
       "      <th>npc_kill_2</th>\n",
       "      <th>npc_kill_3</th>\n",
       "      <th>npc_kill_4</th>\n",
       "      <th>...</th>\n",
       "      <th>target_price_accessory</th>\n",
       "      <th>target_amount_accessory</th>\n",
       "      <th>source_price_spell</th>\n",
       "      <th>source_amount_spell</th>\n",
       "      <th>target_price_spell</th>\n",
       "      <th>target_amount_spell</th>\n",
       "      <th>source_price_enchant_scroll</th>\n",
       "      <th>source_amount_enchant_scroll</th>\n",
       "      <th>target_price_enchant_scroll</th>\n",
       "      <th>target_amount_enchant_scroll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.294923</td>\n",
       "      <td>0.159165</td>\n",
       "      <td>0.798163</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.148018</td>\n",
       "      <td>0.069954</td>\n",
       "      <td>0.501503</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002893</td>\n",
       "      <td>2.396984e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>14</td>\n",
       "      <td>21.716599</td>\n",
       "      <td>22.599026</td>\n",
       "      <td>20.206876</td>\n",
       "      <td>21.182930</td>\n",
       "      <td>4.131994</td>\n",
       "      <td>5.162035</td>\n",
       "      <td>4.697367</td>\n",
       "      <td>4.216479</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032769</td>\n",
       "      <td>0.049154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.655562</td>\n",
       "      <td>22.353257</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.972037</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.869647e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.0</td>\n",
       "      <td>17</td>\n",
       "      <td>21.267193</td>\n",
       "      <td>20.138997</td>\n",
       "      <td>20.689051</td>\n",
       "      <td>22.044291</td>\n",
       "      <td>24.798383</td>\n",
       "      <td>26.081203</td>\n",
       "      <td>12.165168</td>\n",
       "      <td>16.821645</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.587936e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.566969</td>\n",
       "      <td>2.277135e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 151 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   acc_id  level  playtime_1  playtime_2  playtime_3  playtime_4  npc_kill_1  \\\n",
       "0     7.0     11    0.000000    0.294923    0.159165    0.798163    0.000000   \n",
       "1    15.0     14   21.716599   22.599026   20.206876   21.182930    4.131994   \n",
       "2    16.0      9    0.000000    0.000000    0.032769    0.049154    0.000000   \n",
       "3    18.0      0    0.000000    0.000000   17.655562   22.353257    0.000000   \n",
       "4    19.0     17   21.267193   20.138997   20.689051   22.044291   24.798383   \n",
       "\n",
       "   npc_kill_2  npc_kill_3  npc_kill_4  ...  target_price_accessory  \\\n",
       "0    0.148018    0.069954    0.501503  ...                     0.0   \n",
       "1    5.162035    4.697367    4.216479  ...                     0.0   \n",
       "2    0.000000    0.000000    0.000000  ...                     0.0   \n",
       "3    0.000000    0.000000    0.000000  ...                     0.0   \n",
       "4   26.081203   12.165168   16.821645  ...                     0.0   \n",
       "\n",
       "   target_amount_accessory  source_price_spell  source_amount_spell  \\\n",
       "0                      0.0                 0.0         0.000000e+00   \n",
       "1                      0.0                 0.0         0.000000e+00   \n",
       "2                      0.0                 0.0         0.000000e+00   \n",
       "3                      0.0                 0.0         0.000000e+00   \n",
       "4                      0.0                 0.0         9.587936e-08   \n",
       "\n",
       "   target_price_spell  target_amount_spell  source_price_enchant_scroll  \\\n",
       "0                 0.0                  0.0                     0.000000   \n",
       "1                 0.0                  0.0                     0.000000   \n",
       "2                 0.0                  0.0                     0.000000   \n",
       "3                 0.0                  0.0                     0.972037   \n",
       "4                 0.0                  0.0                     0.000000   \n",
       "\n",
       "   source_amount_enchant_scroll  target_price_enchant_scroll  \\\n",
       "0                      0.000000                     0.002893   \n",
       "1                      0.000000                     0.000000   \n",
       "2                      0.000000                     0.000000   \n",
       "3                      0.000007                     0.000000   \n",
       "4                      0.000000                     0.566969   \n",
       "\n",
       "   target_amount_enchant_scroll  \n",
       "0                  2.396984e-08  \n",
       "1                  0.000000e+00  \n",
       "2                  0.000000e+00  \n",
       "3                  1.869647e-06  \n",
       "4                  2.277135e-06  \n",
       "\n",
       "[5 rows x 151 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['acc_id', 'level', 'playtime_1', 'playtime_2', 'playtime_3',\n",
       "       'playtime_4', 'npc_kill_1', 'npc_kill_2', 'npc_kill_3',\n",
       "       'npc_kill_4', 'solo_exp_1', 'solo_exp_2', 'solo_exp_3',\n",
       "       'solo_exp_4', 'party_exp_1', 'party_exp_2', 'party_exp_3',\n",
       "       'party_exp_4', 'quest_exp_1', 'quest_exp_2', 'quest_exp_3',\n",
       "       'quest_exp_4', 'rich_monster_1', 'rich_monster_2',\n",
       "       'rich_monster_3', 'rich_monster_4', 'death_1', 'death_2',\n",
       "       'death_3', 'death_4', 'revive_1', 'revive_2', 'revive_3',\n",
       "       'revive_4', 'exp_recovery_1', 'exp_recovery_2', 'exp_recovery_3',\n",
       "       'exp_recovery_4', 'fishing_1', 'fishing_2', 'fishing_3',\n",
       "       'fishing_4', 'private_shop_1', 'private_shop_2', 'private_shop_3',\n",
       "       'private_shop_4', 'game_money_change_1', 'game_money_change_2',\n",
       "       'game_money_change_3', 'game_money_change_4', 'enchant_count_1',\n",
       "       'enchant_count_2', 'enchant_count_3', 'enchant_count_4',\n",
       "       'combat_pledge_cnt_1', 'combat_pledge_cnt_2',\n",
       "       'combat_pledge_cnt_3', 'combat_pledge_cnt_4',\n",
       "       'combat_random_attacker_cnt_1', 'combat_random_attacker_cnt_2',\n",
       "       'combat_random_attacker_cnt_3', 'combat_random_attacker_cnt_4',\n",
       "       'combat_random_defender_cnt_1', 'combat_random_defender_cnt_2',\n",
       "       'combat_random_defender_cnt_3', 'combat_random_defender_cnt_4',\n",
       "       'combat_temp_cnt_1', 'combat_temp_cnt_2', 'combat_temp_cnt_3',\n",
       "       'combat_temp_cnt_4', 'combat_same_pledge_cnt_1',\n",
       "       'combat_same_pledge_cnt_2', 'combat_same_pledge_cnt_3',\n",
       "       'combat_same_pledge_cnt_4', 'combat_etc_cnt_1', 'combat_etc_cnt_2',\n",
       "       'combat_etc_cnt_3', 'combat_etc_cnt_4', 'combat_num_opponent_1',\n",
       "       'combat_num_opponent_2', 'combat_num_opponent_3',\n",
       "       'combat_num_opponent_4', 'amount_cnt', 'amount_mean',\n",
       "       'server_group_0', 'server_group_1', 'server_group_2', 'class_0',\n",
       "       'class_1', 'class_2', 'class_3', 'class_4', 'class_5', 'class_6',\n",
       "       'class_7', 'pledge_group_0', 'pledge_group_1', 'pledge_group_2',\n",
       "       'pledge_group_3', 'source_price_adena_1', 'source_price_adena_2',\n",
       "       'source_price_adena_3', 'source_price_adena_4',\n",
       "       'source_amount_adena_1', 'source_amount_adena_2',\n",
       "       'source_amount_adena_3', 'source_amount_adena_4',\n",
       "       'target_price_adena_1', 'target_price_adena_2',\n",
       "       'target_price_adena_3', 'target_price_adena_4',\n",
       "       'target_amount_adena_1', 'target_amount_adena_2',\n",
       "       'target_amount_adena_3', 'target_amount_adena_4',\n",
       "       'source_price_etc_1', 'source_price_etc_2', 'source_price_etc_3',\n",
       "       'source_price_etc_4', 'source_amount_etc_1', 'source_amount_etc_2',\n",
       "       'source_amount_etc_3', 'source_amount_etc_4', 'target_price_etc_1',\n",
       "       'target_price_etc_2', 'target_price_etc_3', 'target_price_etc_4',\n",
       "       'target_amount_etc_1', 'target_amount_etc_2',\n",
       "       'target_amount_etc_3', 'target_amount_etc_4',\n",
       "       'source_price_weapon', 'source_amount_weapon',\n",
       "       'target_price_weapon', 'target_amount_weapon',\n",
       "       'source_price_armor', 'source_amount_armor', 'target_price_armor',\n",
       "       'target_amount_armor', 'source_price_accessory',\n",
       "       'source_amount_accessory', 'target_price_accessory',\n",
       "       'target_amount_accessory', 'source_price_spell',\n",
       "       'source_amount_spell', 'target_price_spell', 'target_amount_spell',\n",
       "       'source_price_enchant_scroll', 'source_amount_enchant_scroll',\n",
       "       'target_price_enchant_scroll', 'target_amount_enchant_scroll'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test1.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test2 set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_test2_activity = os.path.join(path, 'test2_activity.csv')\n",
    "path_test2_combat = os.path.join(path, 'test2_combat.csv')\n",
    "path_test2_pledge = os.path.join(path, 'test2_pledge.csv')\n",
    "path_test2_payment = os.path.join(path, 'test2_payment.csv')\n",
    "path_test2_trade = os.path.join(path, 'test2_trade.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2_1 = pd.read_csv(path_test2_activity, engine = 'python')\n",
    "test2_2 = pd.read_csv(path_test2_combat, engine = 'python')\n",
    "test2_3 = pd.read_csv(path_test2_pledge, engine = 'python')\n",
    "test2_4 = pd.read_csv(path_test2_payment, engine = 'python')\n",
    "test2_5 = pd.read_csv(path_test2_trade, engine = 'python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     1,      3,      9, ..., 130458, 130467, 130471])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2_id = test2_1['acc_id'].unique()\n",
    "test2_id.sort()\n",
    "test2_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "playtime done\n",
      "npc_kill done\n",
      "solo_exp done\n",
      "party_exp done\n",
      "quest_exp done\n",
      "rich_monster done\n",
      "death done\n",
      "revive done\n",
      "exp_recovery done\n",
      "fishing done\n",
      "private_shop done\n",
      "game_money_change done\n",
      "enchant_count done\n",
      "pledge_cnt done\n",
      "random_attacker_cnt done\n",
      "random_defender_cnt done\n",
      "temp_cnt done\n",
      "same_pledge_cnt done\n",
      "etc_cnt done\n",
      "num_opponent done\n",
      "play_char_cnt done\n",
      "combat_char_cnt done\n",
      "pledge_combat_cnt done\n",
      "random_attacker_cnt done\n",
      "random_defender_cnt done\n",
      "same_pledge_cnt done\n",
      "temp_cnt done\n",
      "etc_cnt done\n",
      "combat_play_time done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user3/anaconda3/envs/hun/lib/python3.6/site-packages/numpy/core/fromnumeric.py:56: FutureWarning: \n",
      "The current behaviour of 'Series.argmax' is deprecated, use 'idxmax'\n",
      "instead.\n",
      "The behavior of 'argmax' will be corrected to return the positional\n",
      "maximum in the future. For now, use 'series.values.argmax' or\n",
      "'np.argmax(np.array(values))' to get the position of the maximum\n",
      "row.\n",
      "  return getattr(obj, method)(*args, **kwds)\n",
      "/home/user3/anaconda3/bigcontest/preprocess:302: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/user3/anaconda3/bigcontest/preprocess:303: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/user3/anaconda3/bigcontest/preprocess:405: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/user3/anaconda3/bigcontest/preprocess:406: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/user3/anaconda3/bigcontest/preprocess:407: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/user3/anaconda3/bigcontest/preprocess:408: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/user3/anaconda3/bigcontest/preprocess:411: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "X_test2 = preprocess(test2_1, test2_2, test2_3, test2_4, test2_5, test2_id, train = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_id</th>\n",
       "      <th>level</th>\n",
       "      <th>playtime_1</th>\n",
       "      <th>playtime_2</th>\n",
       "      <th>playtime_3</th>\n",
       "      <th>playtime_4</th>\n",
       "      <th>npc_kill_1</th>\n",
       "      <th>npc_kill_2</th>\n",
       "      <th>npc_kill_3</th>\n",
       "      <th>npc_kill_4</th>\n",
       "      <th>...</th>\n",
       "      <th>target_price_accessory</th>\n",
       "      <th>target_amount_accessory</th>\n",
       "      <th>source_price_spell</th>\n",
       "      <th>source_amount_spell</th>\n",
       "      <th>target_price_spell</th>\n",
       "      <th>target_amount_spell</th>\n",
       "      <th>source_price_enchant_scroll</th>\n",
       "      <th>source_amount_enchant_scroll</th>\n",
       "      <th>target_price_enchant_scroll</th>\n",
       "      <th>target_amount_enchant_scroll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>22.030247</td>\n",
       "      <td>22.105148</td>\n",
       "      <td>21.857038</td>\n",
       "      <td>22.559235</td>\n",
       "      <td>14.669980</td>\n",
       "      <td>14.596309</td>\n",
       "      <td>14.468568</td>\n",
       "      <td>14.551025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.524307</td>\n",
       "      <td>0.936262</td>\n",
       "      <td>0.730284</td>\n",
       "      <td>0.503241</td>\n",
       "      <td>0.038525</td>\n",
       "      <td>0.015545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038525</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.004681</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.077242</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.116079e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.481095</td>\n",
       "      <td>4.077421</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054746</td>\n",
       "      <td>0.161197</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.701859e-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.793968e-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.396984e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.396984e-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26.0</td>\n",
       "      <td>17</td>\n",
       "      <td>8.910874</td>\n",
       "      <td>7.422218</td>\n",
       "      <td>8.274216</td>\n",
       "      <td>7.209218</td>\n",
       "      <td>2.049269</td>\n",
       "      <td>0.925956</td>\n",
       "      <td>0.586326</td>\n",
       "      <td>0.213240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.739295e-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.172125e-05</td>\n",
       "      <td>0.075108</td>\n",
       "      <td>9.971453e-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.190952e-08</td>\n",
       "      <td>0.300818</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 151 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   acc_id  level  playtime_1  playtime_2  playtime_3  playtime_4  npc_kill_1  \\\n",
       "0     1.0     16   22.030247   22.105148   21.857038   22.559235   14.669980   \n",
       "1     3.0     16    0.524307    0.936262    0.730284    0.503241    0.038525   \n",
       "2     9.0     11    0.004681    0.000000    0.000000    0.077242    0.000000   \n",
       "3    14.0     16    0.000000    0.000000    2.481095    4.077421    0.000000   \n",
       "4    26.0     17    8.910874    7.422218    8.274216    7.209218    2.049269   \n",
       "\n",
       "   npc_kill_2  npc_kill_3  npc_kill_4  ...  target_price_accessory  \\\n",
       "0   14.596309   14.468568   14.551025  ...                     0.0   \n",
       "1    0.015545    0.000000    0.038525  ...                     0.0   \n",
       "2    0.000000    0.000000    0.015883  ...                     0.0   \n",
       "3    0.000000    0.054746    0.161197  ...                     0.0   \n",
       "4    0.925956    0.586326    0.213240  ...                     0.0   \n",
       "\n",
       "   target_amount_accessory  source_price_spell  source_amount_spell  \\\n",
       "0             0.000000e+00                 0.0         0.000000e+00   \n",
       "1             0.000000e+00                 0.0         0.000000e+00   \n",
       "2             3.116079e-07                 0.0         0.000000e+00   \n",
       "3             1.701859e-06                 0.0         4.793968e-08   \n",
       "4             3.739295e-06                 0.0         1.172125e-05   \n",
       "\n",
       "   target_price_spell  target_amount_spell  source_price_enchant_scroll  \\\n",
       "0            0.000000         0.000000e+00                          0.0   \n",
       "1            0.000000         0.000000e+00                          0.0   \n",
       "2            0.000000         0.000000e+00                          0.0   \n",
       "3            0.000000         2.396984e-08                          0.0   \n",
       "4            0.075108         9.971453e-06                          0.0   \n",
       "\n",
       "   source_amount_enchant_scroll  target_price_enchant_scroll  \\\n",
       "0                  0.000000e+00                     0.000000   \n",
       "1                  0.000000e+00                     0.000000   \n",
       "2                  0.000000e+00                     0.000000   \n",
       "3                  2.396984e-08                     0.000000   \n",
       "4                  7.190952e-08                     0.300818   \n",
       "\n",
       "   target_amount_enchant_scroll  \n",
       "0                      0.000000  \n",
       "1                      0.000000  \n",
       "2                      0.000000  \n",
       "3                      0.000000  \n",
       "4                      0.000001  \n",
       "\n",
       "[5 rows x 151 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['acc_id', 'level', 'playtime_1', 'playtime_2', 'playtime_3',\n",
       "       'playtime_4', 'npc_kill_1', 'npc_kill_2', 'npc_kill_3',\n",
       "       'npc_kill_4', 'solo_exp_1', 'solo_exp_2', 'solo_exp_3',\n",
       "       'solo_exp_4', 'party_exp_1', 'party_exp_2', 'party_exp_3',\n",
       "       'party_exp_4', 'quest_exp_1', 'quest_exp_2', 'quest_exp_3',\n",
       "       'quest_exp_4', 'rich_monster_1', 'rich_monster_2',\n",
       "       'rich_monster_3', 'rich_monster_4', 'death_1', 'death_2',\n",
       "       'death_3', 'death_4', 'revive_1', 'revive_2', 'revive_3',\n",
       "       'revive_4', 'exp_recovery_1', 'exp_recovery_2', 'exp_recovery_3',\n",
       "       'exp_recovery_4', 'fishing_1', 'fishing_2', 'fishing_3',\n",
       "       'fishing_4', 'private_shop_1', 'private_shop_2', 'private_shop_3',\n",
       "       'private_shop_4', 'game_money_change_1', 'game_money_change_2',\n",
       "       'game_money_change_3', 'game_money_change_4', 'enchant_count_1',\n",
       "       'enchant_count_2', 'enchant_count_3', 'enchant_count_4',\n",
       "       'combat_pledge_cnt_1', 'combat_pledge_cnt_2',\n",
       "       'combat_pledge_cnt_3', 'combat_pledge_cnt_4',\n",
       "       'combat_random_attacker_cnt_1', 'combat_random_attacker_cnt_2',\n",
       "       'combat_random_attacker_cnt_3', 'combat_random_attacker_cnt_4',\n",
       "       'combat_random_defender_cnt_1', 'combat_random_defender_cnt_2',\n",
       "       'combat_random_defender_cnt_3', 'combat_random_defender_cnt_4',\n",
       "       'combat_temp_cnt_1', 'combat_temp_cnt_2', 'combat_temp_cnt_3',\n",
       "       'combat_temp_cnt_4', 'combat_same_pledge_cnt_1',\n",
       "       'combat_same_pledge_cnt_2', 'combat_same_pledge_cnt_3',\n",
       "       'combat_same_pledge_cnt_4', 'combat_etc_cnt_1', 'combat_etc_cnt_2',\n",
       "       'combat_etc_cnt_3', 'combat_etc_cnt_4', 'combat_num_opponent_1',\n",
       "       'combat_num_opponent_2', 'combat_num_opponent_3',\n",
       "       'combat_num_opponent_4', 'amount_cnt', 'amount_mean',\n",
       "       'server_group_0', 'server_group_1', 'server_group_2', 'class_0',\n",
       "       'class_1', 'class_2', 'class_3', 'class_4', 'class_5', 'class_6',\n",
       "       'class_7', 'pledge_group_0', 'pledge_group_1', 'pledge_group_2',\n",
       "       'pledge_group_3', 'source_price_adena_1', 'source_price_adena_2',\n",
       "       'source_price_adena_3', 'source_price_adena_4',\n",
       "       'source_amount_adena_1', 'source_amount_adena_2',\n",
       "       'source_amount_adena_3', 'source_amount_adena_4',\n",
       "       'target_price_adena_1', 'target_price_adena_2',\n",
       "       'target_price_adena_3', 'target_price_adena_4',\n",
       "       'target_amount_adena_1', 'target_amount_adena_2',\n",
       "       'target_amount_adena_3', 'target_amount_adena_4',\n",
       "       'source_price_etc_1', 'source_price_etc_2', 'source_price_etc_3',\n",
       "       'source_price_etc_4', 'source_amount_etc_1', 'source_amount_etc_2',\n",
       "       'source_amount_etc_3', 'source_amount_etc_4', 'target_price_etc_1',\n",
       "       'target_price_etc_2', 'target_price_etc_3', 'target_price_etc_4',\n",
       "       'target_amount_etc_1', 'target_amount_etc_2',\n",
       "       'target_amount_etc_3', 'target_amount_etc_4',\n",
       "       'source_price_weapon', 'source_amount_weapon',\n",
       "       'target_price_weapon', 'target_amount_weapon',\n",
       "       'source_price_armor', 'source_amount_armor', 'target_price_armor',\n",
       "       'target_amount_armor', 'source_price_accessory',\n",
       "       'source_amount_accessory', 'target_price_accessory',\n",
       "       'target_amount_accessory', 'source_price_spell',\n",
       "       'source_amount_spell', 'target_price_spell', 'target_amount_spell',\n",
       "       'source_price_enchant_scroll', 'source_amount_enchant_scroll',\n",
       "       'target_price_enchant_scroll', 'target_amount_enchant_scroll'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test2.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test1.to_csv('./test1_preprocess_1.csv', index = False)\n",
    "X_test2.to_csv('./test2_preprocess_1.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 추가 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 직업 변수 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('./train_preprocess_1.csv')\n",
    "X_test = pd.read_csv('./test_preprocess_1.csv')\n",
    "X_test1 = pd.read_csv('./test1_preprocess_1.csv')\n",
    "X_test2 = pd.read_csv('./test2_preprocess_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_list = []\n",
    "for i in range(0, len(X_train.columns)):\n",
    "    if('class' in X_train.columns[i]):\n",
    "        var_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(X_train.columns[var_list], axis = 1)\n",
    "X_test = X_test.drop(X_test.columns[var_list], axis = 1)\n",
    "X_test1 = X_test1.drop(X_test1.columns[var_list], axis = 1)\n",
    "X_test2 = X_test2.drop(X_test2.columns[var_list], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 플레이 시간 변동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['playtime_fluctuation'] = (X_train['playtime_4'] + 1) / (X_train['playtime_3'] + 1)\n",
    "X_test['playtime_fluctuation'] = (X_test['playtime_4'] + 1) / (X_test['playtime_3'] + 1)\n",
    "X_test1['playtime_fluctuation'] = (X_test1['playtime_4'] + 1) / (X_test1['playtime_3'] + 1)\n",
    "X_test2['playtime_fluctuation'] = (X_test2['playtime_4'] + 1) / (X_test2['playtime_3'] + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 유저별 접속일수, 서버수, 캐릭터수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = []\n",
    "for i in range(0, len(train1)):\n",
    "    if(train1['acc_id'][i] in train_id):\n",
    "        index_list.append(i)            \n",
    "train1_sub = train1.loc[index_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = []\n",
    "for i in range(0, len(train1)):\n",
    "    if(train1['acc_id'][i] in test_id):\n",
    "        index_list.append(i)            \n",
    "test1_sub = train1.loc[index_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = []\n",
    "for i in range(0, len(test1_1)):\n",
    "    if(test1_1['acc_id'][i] in test1_id):\n",
    "        index_list.append(i)            \n",
    "test1_1_sub = test1_1.loc[index_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = []\n",
    "for i in range(0, len(test2_1)):\n",
    "    if(test2_1['acc_id'][i] in test2_id):\n",
    "        index_list.append(i)            \n",
    "test2_1_sub = test2_1.loc[index_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_num(data, variable, user_id, version = 1):\n",
    "    '''\n",
    "    유저 아이디 별로 원하는 변수에 대한 unique값 count\n",
    "    원하는 user_id에 대한 sub data가 있는 경우 version = 1, 없는 경우 version = 2\n",
    "    version = 2 의 경우 subset 과정으로 시간이 더 오래 소요\n",
    "    '''\n",
    "    \n",
    "    if(version == 1):\n",
    "        data_sub = data\n",
    "    else:\n",
    "        index_list = []\n",
    "        for i in range(0, len(data)):\n",
    "            if(data['acc_id'][i] in user_id):\n",
    "                index_list.append(i)            \n",
    "        data_sub = data.loc[index_list]\n",
    "    \n",
    "    variable_unique = data_sub.groupby('acc_id')[variable].unique()\n",
    "    variable_num = np.zeros(len(user_id))\n",
    "\n",
    "    for i in range(0, len(user_id)):\n",
    "        variable_num[i] = len(variable_unique[user_id[i]])\n",
    "        \n",
    "    return variable_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_num = count_num(data = train1_sub, variable = 'day', user_id = train_id, version = 1)\n",
    "server_num = count_num(data = train1_sub, variable = 'server', user_id = train_id, version = 1)\n",
    "char_num = count_num(data = train1_sub, variable = 'char_id', user_id = train_id, version = 1)\n",
    "\n",
    "X_train['log_total'] = day_num\n",
    "X_train['server_num'] = server_num\n",
    "X_train['char_num'] = char_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_num = count_num(data = test1_sub, variable = 'day', user_id = test_id, version = 1)\n",
    "server_num = count_num(data = test1_sub, variable = 'server', user_id = test_id, version = 1)\n",
    "char_num = count_num(data = test1_sub, variable = 'char_id', user_id = test_id, version = 1)\n",
    "\n",
    "X_test['log_total'] = day_num\n",
    "X_test['server_num'] = server_num\n",
    "X_test['char_num'] = char_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_num = count_num(data = test1_1_sub, variable = 'day', user_id = test1_id, version = 1)\n",
    "server_num = count_num(data = test1_1_sub, variable = 'server', user_id = test1_id, version = 1)\n",
    "char_num = count_num(data = test1_1_sub, variable = 'char_id', user_id = test1_id, version = 1)\n",
    "\n",
    "X_test1['log_total'] = day_num\n",
    "X_test1['server_num'] = server_num\n",
    "X_test1['char_num'] = char_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_num = count_num(data = test2_1_sub, variable = 'day', user_id = test2_id, version = 1)\n",
    "server_num = count_num(data = test2_1_sub, variable = 'server', user_id = test2_id, version = 1)\n",
    "char_num = count_num(data = test2_1_sub, variable = 'char_id', user_id = test2_id, version = 1)\n",
    "\n",
    "X_test2['log_total'] = day_num\n",
    "X_test2['server_num'] = server_num\n",
    "X_test2['char_num'] = char_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이상치 대체"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기본 활동 데이터, 전투 데이터, 거래 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### npc_kill, solo_exp, rich_monster, combat_same_pledge_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['npc_kill_1'] = (X_train['npc_kill_2'] + X_train['npc_kill_3'] + X_train['npc_kill_4']) / 3\n",
    "X_train['solo_exp_1'] = (X_train['solo_exp_2'] + X_train['solo_exp_3'] + X_train['solo_exp_4']) / 3\n",
    "X_train['rich_monster_2'] = (X_train['rich_monster_1'] + X_train['rich_monster_3'] + X_train['rich_monster_4']) / 3\n",
    "X_train['combat_same_pledge_cnt_1'] = (X_train['combat_same_pledge_cnt_2'] + X_train['combat_same_pledge_cnt_3'] + X_train['combat_same_pledge_cnt_4']) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['npc_kill_1'] = (X_test['npc_kill_2'] + X_test['npc_kill_3'] + X_test['npc_kill_4']) / 3\n",
    "X_test['solo_exp_1'] = (X_test['solo_exp_2'] + X_test['solo_exp_3'] + X_test['solo_exp_4']) / 3\n",
    "X_test['rich_monster_2'] = (X_test['rich_monster_1'] + X_test['rich_monster_3'] + X_test['rich_monster_4']) / 3\n",
    "X_test['combat_same_pledge_cnt_1'] = (X_test['combat_same_pledge_cnt_2'] + X_test['combat_same_pledge_cnt_3'] + X_test['combat_same_pledge_cnt_4']) / 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### game_money_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1_sub_day = train1_sub[(train1_sub['day'] == 1) | (train1_sub['day'] == 8) | (train1_sub['day'] == 22)]\n",
    "test1_sub_day = test1_sub[(test1_sub['day'] == 1) | (test1_sub['day'] == 8) | (test1_sub['day'] == 22)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "val1 = train1_sub_day.groupby('acc_id')['game_money_change'].sum() / 3\n",
    "val2 = train1_sub[train1_sub['day'] == 16].groupby('acc_id')['game_money_change'].sum()\n",
    "val3 = train1_sub[train1_sub['day'] == 17].groupby('acc_id')['game_money_change'].sum()\n",
    "val4 = train1_sub[train1_sub['day'] == 18].groupby('acc_id')['game_money_change'].sum()\n",
    "val5 = train1_sub[train1_sub['day'] == 19].groupby('acc_id')['game_money_change'].sum()\n",
    "val6 = train1_sub[train1_sub['day'] == 20].groupby('acc_id')['game_money_change'].sum()\n",
    "val7 = train1_sub[train1_sub['day'] == 21].groupby('acc_id')['game_money_change'].sum()\n",
    "\n",
    "df1 = pd.DataFrame(val1)\n",
    "df2 = pd.DataFrame(val2)\n",
    "df3 = pd.DataFrame(val3)\n",
    "df4 = pd.DataFrame(val4)\n",
    "df5 = pd.DataFrame(val5)\n",
    "df6 = pd.DataFrame(val6)\n",
    "df7 = pd.DataFrame(val7)\n",
    "\n",
    "df = pd.DataFrame(train_id)\n",
    "df.columns = ['acc_id']\n",
    "\n",
    "df = pd.merge(df, df1, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df2, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df3, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df4, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df5, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df6, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df7, how = 'left', on = 'acc_id')\n",
    "\n",
    "df = df.fillna(0)\n",
    "game_money_change_sum = df.iloc[:, 1:].sum(axis = 1)\n",
    "X_train['game_money_change_3'] = game_money_change_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "val1 = test1_sub_day.groupby('acc_id')['game_money_change'].sum() / 3\n",
    "val2 = test1_sub[test1_sub['day'] == 16].groupby('acc_id')['game_money_change'].sum()\n",
    "val3 = test1_sub[test1_sub['day'] == 17].groupby('acc_id')['game_money_change'].sum()\n",
    "val4 = test1_sub[test1_sub['day'] == 18].groupby('acc_id')['game_money_change'].sum()\n",
    "val5 = test1_sub[test1_sub['day'] == 19].groupby('acc_id')['game_money_change'].sum()\n",
    "val6 = test1_sub[test1_sub['day'] == 20].groupby('acc_id')['game_money_change'].sum()\n",
    "val7 = test1_sub[test1_sub['day'] == 21].groupby('acc_id')['game_money_change'].sum()\n",
    "\n",
    "df1 = pd.DataFrame(val1)\n",
    "df2 = pd.DataFrame(val2)\n",
    "df3 = pd.DataFrame(val3)\n",
    "df4 = pd.DataFrame(val4)\n",
    "df5 = pd.DataFrame(val5)\n",
    "df6 = pd.DataFrame(val6)\n",
    "df7 = pd.DataFrame(val7)\n",
    "\n",
    "df = pd.DataFrame(test_id)\n",
    "df.columns = ['acc_id']\n",
    "\n",
    "df = pd.merge(df, df1, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df2, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df3, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df4, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df5, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df6, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df7, how = 'left', on = 'acc_id')\n",
    "\n",
    "df = df.fillna(0)\n",
    "game_money_change_sum = df.iloc[:, 1:].sum(axis = 1)\n",
    "X_test['game_money_change_3'] = game_money_change_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### enchant_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "val1 = train1_sub_day.groupby('acc_id')['enchant_count'].sum() / 3\n",
    "val2 = train1_sub[train1_sub['day'] == 16].groupby('acc_id')['enchant_count'].sum()\n",
    "val3 = train1_sub[train1_sub['day'] == 17].groupby('acc_id')['enchant_count'].sum()\n",
    "val4 = train1_sub[train1_sub['day'] == 18].groupby('acc_id')['enchant_count'].sum()\n",
    "val5 = train1_sub[train1_sub['day'] == 19].groupby('acc_id')['enchant_count'].sum()\n",
    "val6 = train1_sub[train1_sub['day'] == 20].groupby('acc_id')['enchant_count'].sum()\n",
    "val7 = train1_sub[train1_sub['day'] == 21].groupby('acc_id')['enchant_count'].sum()\n",
    "\n",
    "df1 = pd.DataFrame(val1)\n",
    "df2 = pd.DataFrame(val2)\n",
    "df3 = pd.DataFrame(val3)\n",
    "df4 = pd.DataFrame(val4)\n",
    "df5 = pd.DataFrame(val5)\n",
    "df6 = pd.DataFrame(val6)\n",
    "df7 = pd.DataFrame(val7)\n",
    "\n",
    "df = pd.DataFrame(train_id)\n",
    "df.columns = ['acc_id']\n",
    "\n",
    "df = pd.merge(df, df1, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df2, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df3, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df4, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df5, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df6, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df7, how = 'left', on = 'acc_id')\n",
    "\n",
    "df = df.fillna(0)\n",
    "enchant_count_sum = df.iloc[:, 1:].sum(axis = 1)\n",
    "X_train['enchant_count_3'] = enchant_count_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "val1 = test1_sub_day.groupby('acc_id')['enchant_count'].sum() / 3\n",
    "val2 = test1_sub[test1_sub['day'] == 16].groupby('acc_id')['enchant_count'].sum()\n",
    "val3 = test1_sub[test1_sub['day'] == 17].groupby('acc_id')['enchant_count'].sum()\n",
    "val4 = test1_sub[test1_sub['day'] == 18].groupby('acc_id')['enchant_count'].sum()\n",
    "val5 = test1_sub[test1_sub['day'] == 19].groupby('acc_id')['enchant_count'].sum()\n",
    "val6 = test1_sub[test1_sub['day'] == 20].groupby('acc_id')['enchant_count'].sum()\n",
    "val7 = test1_sub[test1_sub['day'] == 21].groupby('acc_id')['enchant_count'].sum()\n",
    "\n",
    "df1 = pd.DataFrame(val1)\n",
    "df2 = pd.DataFrame(val2)\n",
    "df3 = pd.DataFrame(val3)\n",
    "df4 = pd.DataFrame(val4)\n",
    "df5 = pd.DataFrame(val5)\n",
    "df6 = pd.DataFrame(val6)\n",
    "df7 = pd.DataFrame(val7)\n",
    "\n",
    "df = pd.DataFrame(test_id)\n",
    "df.columns = ['acc_id']\n",
    "\n",
    "df = pd.merge(df, df1, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df2, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df3, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df4, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df5, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df6, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df7, how = 'left', on = 'acc_id')\n",
    "\n",
    "df = df.fillna(0)\n",
    "enchant_count_sum = df.iloc[:, 1:].sum(axis = 1)\n",
    "X_test['enchant_count_3'] = enchant_count_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### combat_temp_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = []\n",
    "for i in range(0, len(train2)):\n",
    "    if(train2['acc_id'][i] in train_id):\n",
    "        index_list.append(i)            \n",
    "train2_sub = train2.loc[index_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = []\n",
    "for i in range(0, len(train2)):\n",
    "    if(train2['acc_id'][i] in test_id):\n",
    "        index_list.append(i)            \n",
    "test2_sub = train2.loc[index_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = []\n",
    "for i in range(0, len(test1_2)):\n",
    "    if(test1_2['acc_id'][i] in test1_id):\n",
    "        index_list.append(i)            \n",
    "test1_2_sub = test1_2.loc[index_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = []\n",
    "for i in range(0, len(test2_2)):\n",
    "    if(test2_2['acc_id'][i] in test2_id):\n",
    "        index_list.append(i)            \n",
    "test2_2_sub = test2_2.loc[index_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2_sub_day_1 = train2_sub[(train2_sub['day'] == 8) | (train2_sub['day'] == 15)]\n",
    "train2_sub_day_2 = train2_sub[(train2_sub['day'] == 9) | (train2_sub['day'] == 16)]\n",
    "train2_sub_day_3 = train2_sub[(train2_sub['day'] == 10) | (train2_sub['day'] == 17)]\n",
    "train2_sub_day_4 = train2_sub[(train2_sub['day'] == 11) | (train2_sub['day'] == 18)]\n",
    "train2_sub_day_5 = train2_sub[(train2_sub['day'] == 12) | (train2_sub['day'] == 19)]\n",
    "train2_sub_day_6 = train2_sub[(train2_sub['day'] == 13) | (train2_sub['day'] == 20)]\n",
    "train2_sub_day_7 = train2_sub[(train2_sub['day'] == 14) | (train2_sub['day'] == 21)]\n",
    "\n",
    "test2_sub_day_1 = test2_sub[(test2_sub['day'] == 8) | (test2_sub['day'] == 15)]\n",
    "test2_sub_day_2 = test2_sub[(test2_sub['day'] == 9) | (test2_sub['day'] == 16)]\n",
    "test2_sub_day_3 = test2_sub[(test2_sub['day'] == 10) | (test2_sub['day'] == 17)]\n",
    "test2_sub_day_4 = test2_sub[(test2_sub['day'] == 11) | (test2_sub['day'] == 18)]\n",
    "test2_sub_day_5 = test2_sub[(test2_sub['day'] == 12) | (test2_sub['day'] == 19)]\n",
    "test2_sub_day_6 = test2_sub[(test2_sub['day'] == 13) | (test2_sub['day'] == 20)]\n",
    "test2_sub_day_7 = test2_sub[(test2_sub['day'] == 14) | (test2_sub['day'] == 21)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "val1 = train2_sub_day_1.groupby('acc_id')['temp_cnt'].sum() / 2\n",
    "val2 = train2_sub_day_2.groupby('acc_id')['temp_cnt'].sum() / 2\n",
    "val3 = train2_sub_day_3.groupby('acc_id')['temp_cnt'].sum() / 2\n",
    "val4 = train2_sub[train2_sub['day'] == 4].groupby('acc_id')['temp_cnt'].sum()\n",
    "val5 = train2_sub[train2_sub['day'] == 5].groupby('acc_id')['temp_cnt'].sum()\n",
    "val6 = train2_sub[train2_sub['day'] == 6].groupby('acc_id')['temp_cnt'].sum()\n",
    "val7 = train2_sub[train2_sub['day'] == 7].groupby('acc_id')['temp_cnt'].sum()\n",
    "\n",
    "df1 = pd.DataFrame(val1)\n",
    "df2 = pd.DataFrame(val2)\n",
    "df3 = pd.DataFrame(val3)\n",
    "df4 = pd.DataFrame(val4)\n",
    "df5 = pd.DataFrame(val5)\n",
    "df6 = pd.DataFrame(val6)\n",
    "df7 = pd.DataFrame(val7)\n",
    "\n",
    "df = pd.DataFrame(train_id)\n",
    "df.columns = ['acc_id']\n",
    "\n",
    "df = pd.merge(df, df1, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df2, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df3, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df4, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df5, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df6, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df7, how = 'left', on = 'acc_id')\n",
    "\n",
    "df = df.fillna(0)\n",
    "combat_temp_cnt_sum = df.iloc[:, 1:].sum(axis = 1)\n",
    "X_train['combat_temp_cnt_1'] = combat_temp_cnt_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "val1 = train2_sub[train2_sub['day'] == 22].groupby('acc_id')['temp_cnt'].sum()\n",
    "val2 = train2_sub_day_2.groupby('acc_id')['temp_cnt'].sum() / 2\n",
    "val3 = train2_sub_day_3.groupby('acc_id')['temp_cnt'].sum() / 2\n",
    "val4 = train2_sub_day_4.groupby('acc_id')['temp_cnt'].sum() / 2\n",
    "val5 = train2_sub_day_5.groupby('acc_id')['temp_cnt'].sum() / 2\n",
    "val6 = train2_sub_day_6.groupby('acc_id')['temp_cnt'].sum() / 2\n",
    "val7 = train2_sub_day_7.groupby('acc_id')['temp_cnt'].sum() / 2\n",
    "\n",
    "df1 = pd.DataFrame(val1)\n",
    "df2 = pd.DataFrame(val2)\n",
    "df3 = pd.DataFrame(val3)\n",
    "df4 = pd.DataFrame(val4)\n",
    "df5 = pd.DataFrame(val5)\n",
    "df6 = pd.DataFrame(val6)\n",
    "df7 = pd.DataFrame(val7)\n",
    "\n",
    "df = pd.DataFrame(train_id)\n",
    "df.columns = ['acc_id']\n",
    "\n",
    "df = pd.merge(df, df1, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df2, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df3, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df4, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df5, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df6, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df7, how = 'left', on = 'acc_id')\n",
    "\n",
    "df = df.fillna(0)\n",
    "combat_temp_cnt_sum = df.iloc[:, 1:].sum(axis = 1)\n",
    "X_train['combat_temp_cnt_4'] = combat_temp_cnt_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "val1 = test2_sub_day_1.groupby('acc_id')['temp_cnt'].sum() / 2\n",
    "val2 = test2_sub_day_2.groupby('acc_id')['temp_cnt'].sum() / 2\n",
    "val3 = test2_sub_day_3.groupby('acc_id')['temp_cnt'].sum() / 2\n",
    "val4 = test2_sub[test2_sub['day'] == 4].groupby('acc_id')['temp_cnt'].sum()\n",
    "val5 = test2_sub[test2_sub['day'] == 5].groupby('acc_id')['temp_cnt'].sum()\n",
    "val6 = test2_sub[test2_sub['day'] == 6].groupby('acc_id')['temp_cnt'].sum()\n",
    "val7 = test2_sub[test2_sub['day'] == 7].groupby('acc_id')['temp_cnt'].sum()\n",
    "\n",
    "df1 = pd.DataFrame(val1)\n",
    "df2 = pd.DataFrame(val2)\n",
    "df3 = pd.DataFrame(val3)\n",
    "df4 = pd.DataFrame(val4)\n",
    "df5 = pd.DataFrame(val5)\n",
    "df6 = pd.DataFrame(val6)\n",
    "df7 = pd.DataFrame(val7)\n",
    "\n",
    "df = pd.DataFrame(test_id)\n",
    "df.columns = ['acc_id']\n",
    "\n",
    "df = pd.merge(df, df1, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df2, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df3, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df4, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df5, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df6, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df7, how = 'left', on = 'acc_id')\n",
    "\n",
    "df = df.fillna(0)\n",
    "combat_temp_cnt_sum = df.iloc[:, 1:].sum(axis = 1)\n",
    "X_test['combat_temp_cnt_1'] = combat_temp_cnt_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "val1 = test2_sub[test2_sub['day'] == 22].groupby('acc_id')['temp_cnt'].sum()\n",
    "val2 = test2_sub_day_2.groupby('acc_id')['temp_cnt'].sum() / 2\n",
    "val3 = test2_sub_day_3.groupby('acc_id')['temp_cnt'].sum() / 2\n",
    "val4 = test2_sub_day_4.groupby('acc_id')['temp_cnt'].sum() / 2\n",
    "val5 = test2_sub_day_5.groupby('acc_id')['temp_cnt'].sum() / 2\n",
    "val6 = test2_sub_day_6.groupby('acc_id')['temp_cnt'].sum() / 2\n",
    "val7 = test2_sub_day_7.groupby('acc_id')['temp_cnt'].sum() / 2\n",
    "\n",
    "df1 = pd.DataFrame(val1)\n",
    "df2 = pd.DataFrame(val2)\n",
    "df3 = pd.DataFrame(val3)\n",
    "df4 = pd.DataFrame(val4)\n",
    "df5 = pd.DataFrame(val5)\n",
    "df6 = pd.DataFrame(val6)\n",
    "df7 = pd.DataFrame(val7)\n",
    "\n",
    "df = pd.DataFrame(test_id)\n",
    "df.columns = ['acc_id']\n",
    "\n",
    "df = pd.merge(df, df1, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df2, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df3, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df4, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df5, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df6, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df7, how = 'left', on = 'acc_id')\n",
    "\n",
    "df = df.fillna(0)\n",
    "combat_temp_cnt_sum = df.iloc[:, 1:].sum(axis = 1)\n",
    "X_test['combat_temp_cnt_4'] = combat_temp_cnt_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### source_amount_etc, target_amount_etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = []\n",
    "for i in range(0, len(train5)):\n",
    "    if(train5['source_acc_id'][i] in train_id):\n",
    "        index_list.append(i)            \n",
    "train5_source = train5.loc[index_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = []\n",
    "for i in range(0, len(train5)):\n",
    "    if(train5['target_acc_id'][i] in train_id):\n",
    "        index_list.append(i)            \n",
    "train5_target = train5.loc[index_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = []\n",
    "for i in range(0, len(train5)):\n",
    "    if(train5['source_acc_id'][i] in test_id):\n",
    "        index_list.append(i)            \n",
    "test5_source = train5.loc[index_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = []\n",
    "for i in range(0, len(train5)):\n",
    "    if(train5['target_acc_id'][i] in test_id):\n",
    "        index_list.append(i)            \n",
    "test5_target = train5.loc[index_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train5_source = train5_source.rename(columns = {'source_acc_id' : 'acc_id'})\n",
    "train5_target = train5_target.rename(columns = {'target_acc_id' : 'acc_id'})\n",
    "test5_source = test5_source.rename(columns = {'source_acc_id' : 'acc_id'})\n",
    "test5_target = test5_target.rename(columns = {'target_acc_id' : 'acc_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['source_amount_etc_3'] = (X_train['source_amount_etc_1'] + X_train['source_amount_etc_2']) / 2\n",
    "X_train['target_amount_etc_3'] = (X_train['target_amount_etc_1'] + X_train['target_amount_etc_2']) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['source_amount_etc_3'] = (X_test['source_amount_etc_1'] + X_test['source_amount_etc_2']) / 2\n",
    "X_test['target_amount_etc_3'] = (X_test['target_amount_etc_1'] + X_test['target_amount_etc_2']) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "train5_source_day_1 = train5_source[(train5_source['day'] == 1) | (train5_source['day'] == 8)]\n",
    "train5_source_day_2 = train5_source[(train5_source['day'] == 2) | (train5_source['day'] == 9)]\n",
    "\n",
    "test5_source_day_1 = test5_source[(test5_source['day'] == 1) | (test5_source['day'] == 8)]\n",
    "test5_source_day_2 = test5_source[(test5_source['day'] == 2) | (test5_source['day'] == 9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "val1 = train5_source_day_1[train5_source_day_1['item_type'] == 'etc'].groupby('acc_id')['item_amount'].sum() / 2\n",
    "val2 = train5_source_day_2[train5_source_day_2['item_type'] == 'etc'].groupby('acc_id')['item_amount'].sum() / 2\n",
    "val3 = train5_source[(train5_source['day'] == 24) & (train5_source['item_type'] == 'etc')].groupby('acc_id')['item_amount'].sum()\n",
    "val4 = train5_source[(train5_source['day'] == 25) & (train5_source['item_type'] == 'etc')].groupby('acc_id')['item_amount'].sum()\n",
    "val5 = train5_source[(train5_source['day'] == 26) & (train5_source['item_type'] == 'etc')].groupby('acc_id')['item_amount'].sum()\n",
    "val6 = train5_source[(train5_source['day'] == 27) & (train5_source['item_type'] == 'etc')].groupby('acc_id')['item_amount'].sum()\n",
    "val7 = train5_source[(train5_source['day'] == 28) & (train5_source['item_type'] == 'etc')].groupby('acc_id')['item_amount'].sum()\n",
    "\n",
    "df1 = pd.DataFrame(val1)\n",
    "df2 = pd.DataFrame(val2)\n",
    "df3 = pd.DataFrame(val3)\n",
    "df4 = pd.DataFrame(val4)\n",
    "df5 = pd.DataFrame(val5)\n",
    "df6 = pd.DataFrame(val6)\n",
    "df7 = pd.DataFrame(val7)\n",
    "\n",
    "df = pd.DataFrame(train_id)\n",
    "df.columns = ['acc_id']\n",
    "\n",
    "df = pd.merge(df, df1, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df2, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df3, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df4, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df5, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df6, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df7, how = 'left', on = 'acc_id')\n",
    "\n",
    "df = df.fillna(0)\n",
    "source_amount_etc_sum = df.iloc[:, 1:].sum(axis = 1)\n",
    "X_train['source_amount_etc_4'] = source_amount_etc_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "val1 = test5_source_day_1[test5_source_day_1['item_type'] == 'etc'].groupby('acc_id')['item_amount'].sum() / 2\n",
    "val2 = test5_source_day_2[test5_source_day_2['item_type'] == 'etc'].groupby('acc_id')['item_amount'].sum() / 2\n",
    "val3 = test5_source[(test5_source['day'] == 24) & (test5_source['item_type'] == 'etc')].groupby('acc_id')['item_amount'].sum()\n",
    "val4 = test5_source[(test5_source['day'] == 25) & (test5_source['item_type'] == 'etc')].groupby('acc_id')['item_amount'].sum()\n",
    "val5 = test5_source[(test5_source['day'] == 26) & (test5_source['item_type'] == 'etc')].groupby('acc_id')['item_amount'].sum()\n",
    "val6 = test5_source[(test5_source['day'] == 27) & (test5_source['item_type'] == 'etc')].groupby('acc_id')['item_amount'].sum()\n",
    "val7 = test5_source[(test5_source['day'] == 28) & (test5_source['item_type'] == 'etc')].groupby('acc_id')['item_amount'].sum()\n",
    "\n",
    "df1 = pd.DataFrame(val1)\n",
    "df2 = pd.DataFrame(val2)\n",
    "df3 = pd.DataFrame(val3)\n",
    "df4 = pd.DataFrame(val4)\n",
    "df5 = pd.DataFrame(val5)\n",
    "df6 = pd.DataFrame(val6)\n",
    "df7 = pd.DataFrame(val7)\n",
    "\n",
    "df = pd.DataFrame(train_id)\n",
    "df.columns = ['acc_id']\n",
    "\n",
    "df = pd.merge(df, df1, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df2, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df3, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df4, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df5, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df6, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df7, how = 'left', on = 'acc_id')\n",
    "\n",
    "df = df.fillna(0)\n",
    "source_amount_etc_sum = df.iloc[:, 1:].sum(axis = 1)\n",
    "X_test['source_amount_etc_4'] = source_amount_etc_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "train5_target_day_1 = train5_target[(train5_target['day'] == 1) | (train5_target['day'] == 8)]\n",
    "train5_target_day_2 = train5_target[(train5_target['day'] == 2) | (train5_target['day'] == 9)]\n",
    "\n",
    "test5_target_day_1 = test5_target[(test5_target['day'] == 1) | (test5_target['day'] == 8)]\n",
    "test5_target_day_2 = test5_target[(test5_target['day'] == 2) | (test5_target['day'] == 9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "val1 = train5_target_day_1[train5_target_day_1['item_type'] == 'etc'].groupby('acc_id')['item_amount'].sum() / 2\n",
    "val2 = train5_target_day_2[train5_target_day_2['item_type'] == 'etc'].groupby('acc_id')['item_amount'].sum() / 2\n",
    "val3 = train5_target[(train5_target['day'] == 24) & (train5_target['item_type'] == 'etc')].groupby('acc_id')['item_amount'].sum()\n",
    "val4 = train5_target[(train5_target['day'] == 25) & (train5_target['item_type'] == 'etc')].groupby('acc_id')['item_amount'].sum()\n",
    "val5 = train5_target[(train5_target['day'] == 26) & (train5_target['item_type'] == 'etc')].groupby('acc_id')['item_amount'].sum()\n",
    "val6 = train5_target[(train5_target['day'] == 27) & (train5_target['item_type'] == 'etc')].groupby('acc_id')['item_amount'].sum()\n",
    "val7 = train5_target[(train5_target['day'] == 28) & (train5_target['item_type'] == 'etc')].groupby('acc_id')['item_amount'].sum()\n",
    "\n",
    "df1 = pd.DataFrame(val1)\n",
    "df2 = pd.DataFrame(val2)\n",
    "df3 = pd.DataFrame(val3)\n",
    "df4 = pd.DataFrame(val4)\n",
    "df5 = pd.DataFrame(val5)\n",
    "df6 = pd.DataFrame(val6)\n",
    "df7 = pd.DataFrame(val7)\n",
    "\n",
    "df = pd.DataFrame(train_id)\n",
    "df.columns = ['acc_id']\n",
    "\n",
    "df = pd.merge(df, df1, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df2, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df3, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df4, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df5, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df6, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df7, how = 'left', on = 'acc_id')\n",
    "\n",
    "df = df.fillna(0)\n",
    "target_amount_etc_sum = df.iloc[:, 1:].sum(axis = 1)\n",
    "X_train['target_amount_etc_4'] = target_amount_etc_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "val1 = test5_target_day_1[test5_target_day_1['item_type'] == 'etc'].groupby('acc_id')['item_amount'].sum() / 2\n",
    "val2 = test5_target_day_2[test5_target_day_2['item_type'] == 'etc'].groupby('acc_id')['item_amount'].sum() / 2\n",
    "val3 = test5_target[(test5_target['day'] == 24) & (test5_target['item_type'] == 'etc')].groupby('acc_id')['item_amount'].sum()\n",
    "val4 = test5_target[(test5_target['day'] == 25) & (test5_target['item_type'] == 'etc')].groupby('acc_id')['item_amount'].sum()\n",
    "val5 = test5_target[(test5_target['day'] == 26) & (test5_target['item_type'] == 'etc')].groupby('acc_id')['item_amount'].sum()\n",
    "val6 = test5_target[(test5_target['day'] == 27) & (test5_target['item_type'] == 'etc')].groupby('acc_id')['item_amount'].sum()\n",
    "val7 = test5_target[(test5_target['day'] == 28) & (test5_target['item_type'] == 'etc')].groupby('acc_id')['item_amount'].sum()\n",
    "\n",
    "df1 = pd.DataFrame(val1)\n",
    "df2 = pd.DataFrame(val2)\n",
    "df3 = pd.DataFrame(val3)\n",
    "df4 = pd.DataFrame(val4)\n",
    "df5 = pd.DataFrame(val5)\n",
    "df6 = pd.DataFrame(val6)\n",
    "df7 = pd.DataFrame(val7)\n",
    "\n",
    "df = pd.DataFrame(train_id)\n",
    "df.columns = ['acc_id']\n",
    "\n",
    "df = pd.merge(df, df1, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df2, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df3, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df4, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df5, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df6, how = 'left', on = 'acc_id')\n",
    "df = pd.merge(df, df7, how = 'left', on = 'acc_id')\n",
    "\n",
    "df = df.fillna(0)\n",
    "target_amount_etc_sum = df.iloc[:, 1:].sum(axis = 1)\n",
    "X_test['target_amount_etc_4'] = target_amount_etc_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 불필요한 주차별 데이터 28일 평균으로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_adena = ['source_price_adena_1', 'source_price_adena_2', 'source_price_adena_3', 'source_price_adena_4',\n",
    "              'target_price_adena_1', 'target_price_adena_2', 'target_price_adena_3', 'target_price_adena_4']\n",
    "\n",
    "X_train = X_train.drop(price_adena, axis = 1)\n",
    "X_test = X_test.drop(price_adena, axis = 1)\n",
    "X_test1 = X_test1.drop(price_adena, axis = 1)\n",
    "X_test2 = X_test2.drop(price_adena, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def week_to_mean(data, variable, drop = True):\n",
    "    '''\n",
    "    주차별 합으로 이루어진 변수를 28일 동안의 평균으로 변환\n",
    "    주차별 변수는 삭제\n",
    "    '''\n",
    "    \n",
    "    var_list = []\n",
    "    for i in range(0, len(data.columns)):\n",
    "        if(variable in data.columns[i]):\n",
    "            var_list.append(i)\n",
    "        \n",
    "    column_name = variable + '_mean'\n",
    "    data[column_name] = data.iloc[:, var_list].mean(axis = 1)\n",
    "    if(drop == True):\n",
    "        data = data.drop(data.columns[var_list], axis = 1)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_list = ['exp_recovery', 'private_shop', 'enchant_count', 'combat_pledge_cnt', 'combat_random_attacker_cnt',\n",
    "                'combat_random_defender_cnt', 'combat_same_pledge_cnt', 'source_price_etc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "for variable in variable_list:\n",
    "    X_train = week_to_mean(data = X_train, variable = variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "for variable in variable_list:\n",
    "    X_test = week_to_mean(data = X_test, variable = variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "for variable in variable_list:\n",
    "    X_test1 = week_to_mean(data = X_test1, variable = variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "for variable in variable_list:\n",
    "    X_test2 = week_to_mean(data = X_test2, variable = variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 레벨 변화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def level_diff(data, user_id):\n",
    "    '''\n",
    "    28일 동안의 레별 변화를 구함\n",
    "    '''\n",
    "    \n",
    "    char_list = []\n",
    "    char_matrix = data.groupby(['acc_id', 'char_id']).count()['day']\n",
    "    for i in user_id:\n",
    "        char_list.append(np.argmax(char_matrix[i]))\n",
    "        \n",
    "    level_diff_list = []\n",
    "    for i in char_list:\n",
    "        user_char = data[data['char_id'] == i]\n",
    "        char_level_diff = user_char['level'].max() - user_char['level'].min()\n",
    "        level_diff_list.append(char_level_diff)\n",
    "        \n",
    "    return np.array(level_diff_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_level_diff = level_diff(data = train2_sub, user_id = train_id)\n",
    "X_train['level_diff'] = train_level_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_level_diff = level_diff(data = test2_sub, user_id = test_id)\n",
    "X_test['level_diff'] = test_level_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1_level_diff = level_diff(data = test1_2_sub, user_id = test1_id)\n",
    "X_test1['level_diff'] = test1_level_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2_level_diff = level_diff(data = test2_2_sub, user_id = test2_id)\n",
    "X_test2['level_diff'] = test2_level_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 혈맹수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = []\n",
    "for i in range(0, len(train3)):\n",
    "    if(train3['acc_id'][i] in train_id):\n",
    "        index_list.append(i)            \n",
    "train3_sub = train3.loc[index_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = []\n",
    "for i in range(0, len(train3)):\n",
    "    if(train3['acc_id'][i] in test_id):\n",
    "        index_list.append(i)            \n",
    "test3_sub = train3.loc[index_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = []\n",
    "for i in range(0, len(test1_3)):\n",
    "    if(test1_3['acc_id'][i] in test1_id):\n",
    "        index_list.append(i)            \n",
    "test1_3_sub = test1_3.loc[index_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = []\n",
    "for i in range(0, len(test2_3)):\n",
    "    if(test2_3['acc_id'][i] in test2_id):\n",
    "        index_list.append(i)            \n",
    "test2_3_sub = test2_3.loc[index_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_num(data, variable, user_id, version = 1):\n",
    "    '''\n",
    "    유저 아이디 별로 원하는 변수에 대한 unique값 count\n",
    "    원하는 user_id에 대한 sub data가 있는 경우 version = 1, 없는 경우 version = 2\n",
    "    version = 2 의 경우 subset 과정으로 시간이 더 오래 소요\n",
    "    '''\n",
    "    \n",
    "    if(version == 1):\n",
    "        data_sub = data\n",
    "    else:\n",
    "        index_list = []\n",
    "        for i in range(0, len(data)):\n",
    "            if(data['acc_id'][i] in user_id):\n",
    "                index_list.append(i)            \n",
    "        data_sub = data.loc[index_list]\n",
    "    \n",
    "    variable_unique = data_sub.groupby('acc_id')[variable].unique()\n",
    "    variable_num = np.zeros(len(user_id))\n",
    "\n",
    "    for i in range(0, len(user_id)):\n",
    "        variable_num[i] = len(variable_unique[user_id[i]])\n",
    "        \n",
    "    return variable_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "pledge_train_id = train3_sub['acc_id'].unique()\n",
    "pledge_test_id = test3_sub['acc_id'].unique()\n",
    "pledge_test1_id = test1_3_sub['acc_id'].unique()\n",
    "pledge_test2_id = test2_3_sub['acc_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pledge_num = char_num(train3_sub, 'pledge_id', pledge_train_id)\n",
    "train_pledge_num = np.concatenate([pledge_train_id.reshape(-1, 1), train_pledge_num.reshape(-1, 1)], axis = 1)\n",
    "train_pledge_num = pd.DataFrame(train_pledge_num)\n",
    "train_pledge_num.columns = ['acc_id', 'pledge_num']\n",
    "X_train = pd.merge(X_train, train_pledge_num, how = 'left', on = 'acc_id')\n",
    "X_train = X_train.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pledge_num = char_num(test3_sub, 'pledge_id', pledge_test_id)\n",
    "test_pledge_num = np.concatenate([pledge_test_id.reshape(-1, 1), test_pledge_num.reshape(-1, 1)], axis = 1)\n",
    "test_pledge_num = pd.DataFrame(test_pledge_num)\n",
    "test_pledge_num.columns = ['acc_id', 'pledge_num']\n",
    "X_test = pd.merge(X_test, test_pledge_num, how = 'left', on = 'acc_id')\n",
    "X_test = X_test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1_pledge_num = char_num(test1_3_sub, 'pledge_id', pledge_test1_id)\n",
    "test1_pledge_num = np.concatenate([pledge_test1_id.reshape(-1, 1), test1_pledge_num.reshape(-1, 1)], axis = 1)\n",
    "test1_pledge_num = pd.DataFrame(test1_pledge_num)\n",
    "test1_pledge_num.columns = ['acc_id', 'pledge_num']\n",
    "X_test1 = pd.merge(X_test1, test1_pledge_num, how = 'left', on = 'acc_id')\n",
    "X_test1 = X_test1.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2_pledge_num = char_num(test2_3_sub, 'pledge_id', pledge_test2_id)\n",
    "test2_pledge_num = np.concatenate([pledge_test2_id.reshape(-1, 1), test2_pledge_num.reshape(-1, 1)], axis = 1)\n",
    "test2_pledge_num = pd.DataFrame(test2_pledge_num)\n",
    "test2_pledge_num.columns = ['acc_id', 'pledge_num']\n",
    "X_test2 = pd.merge(X_test2, test2_pledge_num, how = 'left', on = 'acc_id')\n",
    "X_test2 = X_test2.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 최초 접속일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_day(data, variable, user_id, version = 1):\n",
    "    '''\n",
    "    유저 아이디 별로 원하는 변수에 대한 unique값 count\n",
    "    원하는 user_id에 대한 sub data가 있는 경우 version = 1, 없는 경우 version = 2\n",
    "    version = 2 의 경우 subset 과정으로 시간이 더 오래 소요\n",
    "    '''\n",
    "    \n",
    "    if(version == 1):\n",
    "        data_sub = data\n",
    "    else:\n",
    "        index_list = []\n",
    "        for i in range(0, len(data)):\n",
    "            if(data['acc_id'][i] in user_id):\n",
    "                index_list.append(i)            \n",
    "        data_sub = data.loc[index_list]\n",
    "    \n",
    "    variable_unique = data_sub.groupby('acc_id')[variable].unique()\n",
    "    variable_num = np.zeros(len(user_id))\n",
    "\n",
    "    for i in range(0, len(user_id)):\n",
    "        variable_num[i] = variable_unique[user_id[i]][0]\n",
    "        \n",
    "    return variable_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_log_day = first_day(train1_sub, 'day', train_id, version = 1)\n",
    "X_train['first_log'] = first_log_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_log_day = first_day(test1_sub, 'day', test_id, version = 1)\n",
    "X_test['first_log'] = first_log_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_log_day = first_day(test1_1_sub, 'day', test1_id, version = 1)\n",
    "X_test1['first_log'] = first_log_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_log_day = first_day(test2_1_sub, 'day', test2_id, version = 1)\n",
    "X_test2['first_log'] = first_log_day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 주차별 접속일수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "day1 = (train1_sub.groupby(['acc_id', 'day'])['playtime'].sum().unstack('day').fillna(0) != 0).iloc[:, 0:7].sum(axis = 1)\n",
    "day2 = (train1_sub.groupby(['acc_id', 'day'])['playtime'].sum().unstack('day').fillna(0) != 0).iloc[:, 7:14].sum(axis = 1)\n",
    "day3 = (train1_sub.groupby(['acc_id', 'day'])['playtime'].sum().unstack('day').fillna(0) != 0).iloc[:, 14:21].sum(axis = 1)\n",
    "day4 = (train1_sub.groupby(['acc_id', 'day'])['playtime'].sum().unstack('day').fillna(0) != 0).iloc[:, 21:28].sum(axis = 1)\n",
    "\n",
    "X_train['log_1'] = day1.values\n",
    "X_train['log_2'] = day2.values\n",
    "X_train['log_3'] = day3.values\n",
    "X_train['log_4'] = day4.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "day1 = (test1_sub.groupby(['acc_id', 'day'])['playtime'].sum().unstack('day').fillna(0) != 0).iloc[:, 0:7].sum(axis = 1)\n",
    "day2 = (test1_sub.groupby(['acc_id', 'day'])['playtime'].sum().unstack('day').fillna(0) != 0).iloc[:, 7:14].sum(axis = 1)\n",
    "day3 = (test1_sub.groupby(['acc_id', 'day'])['playtime'].sum().unstack('day').fillna(0) != 0).iloc[:, 14:21].sum(axis = 1)\n",
    "day4 = (test1_sub.groupby(['acc_id', 'day'])['playtime'].sum().unstack('day').fillna(0) != 0).iloc[:, 21:28].sum(axis = 1)\n",
    "\n",
    "X_test['log_1'] = day1.values\n",
    "X_test['log_2'] = day2.values\n",
    "X_test['log_3'] = day3.values\n",
    "X_test['log_4'] = day4.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "day1 = (test1_1_sub.groupby(['acc_id', 'day'])['playtime'].sum().unstack('day').fillna(0) != 0).iloc[:, 0:7].sum(axis = 1)\n",
    "day2 = (test1_1_sub.groupby(['acc_id', 'day'])['playtime'].sum().unstack('day').fillna(0) != 0).iloc[:, 7:14].sum(axis = 1)\n",
    "day3 = (test1_1_sub.groupby(['acc_id', 'day'])['playtime'].sum().unstack('day').fillna(0) != 0).iloc[:, 14:21].sum(axis = 1)\n",
    "day4 = (test1_1_sub.groupby(['acc_id', 'day'])['playtime'].sum().unstack('day').fillna(0) != 0).iloc[:, 21:28].sum(axis = 1)\n",
    "\n",
    "X_test1['log_1'] = day1.values\n",
    "X_test1['log_2'] = day2.values\n",
    "X_test1['log_3'] = day3.values\n",
    "X_test1['log_4'] = day4.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "day1 = (test2_1_sub.groupby(['acc_id', 'day'])['playtime'].sum().unstack('day').fillna(0) != 0).iloc[:, 0:7].sum(axis = 1)\n",
    "day2 = (test2_1_sub.groupby(['acc_id', 'day'])['playtime'].sum().unstack('day').fillna(0) != 0).iloc[:, 7:14].sum(axis = 1)\n",
    "day3 = (test2_1_sub.groupby(['acc_id', 'day'])['playtime'].sum().unstack('day').fillna(0) != 0).iloc[:, 14:21].sum(axis = 1)\n",
    "day4 = (test2_1_sub.groupby(['acc_id', 'day'])['playtime'].sum().unstack('day').fillna(0) != 0).iloc[:, 21:28].sum(axis = 1)\n",
    "\n",
    "X_test2['log_1'] = day1.values\n",
    "X_test2['log_2'] = day2.values\n",
    "X_test2['log_3'] = day3.values\n",
    "X_test2['log_4'] = day4.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 주차별 혈맹활동, 총 혈맹활동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "week1 = (train3_sub.groupby(['acc_id', 'day'])['play_char_cnt'].sum().unstack('day').fillna(0) != 0).iloc[:, 0:7].sum(axis =1)\n",
    "week2 = (train3_sub.groupby(['acc_id', 'day'])['play_char_cnt'].sum().unstack('day').fillna(0) != 0).iloc[:, 7:14].sum(axis =1)\n",
    "week3 = (train3_sub.groupby(['acc_id', 'day'])['play_char_cnt'].sum().unstack('day').fillna(0) != 0).iloc[:, 14:21].sum(axis =1)\n",
    "week4 = (train3_sub.groupby(['acc_id', 'day'])['play_char_cnt'].sum().unstack('day').fillna(0) != 0).iloc[:, 21:28].sum(axis =1)\n",
    "\n",
    "week1 = pd.DataFrame(week1)\n",
    "week1.columns = ['pledge_log_1']\n",
    "week2 = pd.DataFrame(week2)\n",
    "week2.columns = ['pledge_log_2']\n",
    "week3 = pd.DataFrame(week3)\n",
    "week3.columns = ['pledge_log_3']\n",
    "week4 = pd.DataFrame(week4)\n",
    "week4.columns = ['pledge_log_4']\n",
    "\n",
    "X_train = pd.merge(X_train, week1, how = 'left', on = 'acc_id')\n",
    "X_train = pd.merge(X_train, week2, how = 'left', on = 'acc_id')\n",
    "X_train = pd.merge(X_train, week3, how = 'left', on = 'acc_id')\n",
    "X_train = pd.merge(X_train, week4, how = 'left', on = 'acc_id')\n",
    "X_train = X_train.fillna(0)\n",
    "X_train['pledge_log_total'] = X_train['pledge_log_1'] +  X_train['pledge_log_2'] + X_train['pledge_log_3'] + X_train['pledge_log_4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "week1 = (test3_sub.groupby(['acc_id', 'day'])['play_char_cnt'].sum().unstack('day').fillna(0) != 0).iloc[:, 0:7].sum(axis =1)\n",
    "week2 = (test3_sub.groupby(['acc_id', 'day'])['play_char_cnt'].sum().unstack('day').fillna(0) != 0).iloc[:, 7:14].sum(axis =1)\n",
    "week3 = (test3_sub.groupby(['acc_id', 'day'])['play_char_cnt'].sum().unstack('day').fillna(0) != 0).iloc[:, 14:21].sum(axis =1)\n",
    "week4 = (test3_sub.groupby(['acc_id', 'day'])['play_char_cnt'].sum().unstack('day').fillna(0) != 0).iloc[:, 21:28].sum(axis =1)\n",
    "\n",
    "week1 = pd.DataFrame(week1)\n",
    "week1.columns = ['pledge_log_1']\n",
    "week2 = pd.DataFrame(week2)\n",
    "week2.columns = ['pledge_log_2']\n",
    "week3 = pd.DataFrame(week3)\n",
    "week3.columns = ['pledge_log_3']\n",
    "week4 = pd.DataFrame(week4)\n",
    "week4.columns = ['pledge_log_4']\n",
    "\n",
    "X_test = pd.merge(X_test, week1, how = 'left', on = 'acc_id')\n",
    "X_test = pd.merge(X_test, week2, how = 'left', on = 'acc_id')\n",
    "X_test = pd.merge(X_test, week3, how = 'left', on = 'acc_id')\n",
    "X_test = pd.merge(X_test, week4, how = 'left', on = 'acc_id')\n",
    "X_test = X_test.fillna(0)\n",
    "X_test['pledge_log_total'] = X_test['pledge_log_1'] +  X_test['pledge_log_2'] + X_test['pledge_log_3'] + X_test['pledge_log_4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "week1 = (test1_3_sub.groupby(['acc_id', 'day'])['play_char_cnt'].sum().unstack('day').fillna(0) != 0).iloc[:, 0:7].sum(axis =1)\n",
    "week2 = (test1_3_sub.groupby(['acc_id', 'day'])['play_char_cnt'].sum().unstack('day').fillna(0) != 0).iloc[:, 7:14].sum(axis =1)\n",
    "week3 = (test1_3_sub.groupby(['acc_id', 'day'])['play_char_cnt'].sum().unstack('day').fillna(0) != 0).iloc[:, 14:21].sum(axis =1)\n",
    "week4 = (test1_3_sub.groupby(['acc_id', 'day'])['play_char_cnt'].sum().unstack('day').fillna(0) != 0).iloc[:, 21:28].sum(axis =1)\n",
    "\n",
    "week1 = pd.DataFrame(week1)\n",
    "week1.columns = ['pledge_log_1']\n",
    "week2 = pd.DataFrame(week2)\n",
    "week2.columns = ['pledge_log_2']\n",
    "week3 = pd.DataFrame(week3)\n",
    "week3.columns = ['pledge_log_3']\n",
    "week4 = pd.DataFrame(week4)\n",
    "week4.columns = ['pledge_log_4']\n",
    "\n",
    "X_test1 = pd.merge(X_test1, week1, how = 'left', on = 'acc_id')\n",
    "X_test1 = pd.merge(X_test1, week2, how = 'left', on = 'acc_id')\n",
    "X_test1 = pd.merge(X_test1, week3, how = 'left', on = 'acc_id')\n",
    "X_test1 = pd.merge(X_test1, week4, how = 'left', on = 'acc_id')\n",
    "X_test1 = X_test1.fillna(0)\n",
    "X_test1['pledge_log_total'] = X_test1['pledge_log_1'] +  X_test1['pledge_log_2'] + X_test1['pledge_log_3'] + X_test1['pledge_log_4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "week1 = (test2_3_sub.groupby(['acc_id', 'day'])['play_char_cnt'].sum().unstack('day').fillna(0) != 0).iloc[:, 0:7].sum(axis =1)\n",
    "week2 = (test2_3_sub.groupby(['acc_id', 'day'])['play_char_cnt'].sum().unstack('day').fillna(0) != 0).iloc[:, 7:14].sum(axis =1)\n",
    "week3 = (test2_3_sub.groupby(['acc_id', 'day'])['play_char_cnt'].sum().unstack('day').fillna(0) != 0).iloc[:, 14:21].sum(axis =1)\n",
    "week4 = (test2_3_sub.groupby(['acc_id', 'day'])['play_char_cnt'].sum().unstack('day').fillna(0) != 0).iloc[:, 21:28].sum(axis =1)\n",
    "\n",
    "week1 = pd.DataFrame(week1)\n",
    "week1.columns = ['pledge_log_1']\n",
    "week2 = pd.DataFrame(week2)\n",
    "week2.columns = ['pledge_log_2']\n",
    "week3 = pd.DataFrame(week3)\n",
    "week3.columns = ['pledge_log_3']\n",
    "week4 = pd.DataFrame(week4)\n",
    "week4.columns = ['pledge_log_4']\n",
    "\n",
    "X_test2 = pd.merge(X_test2, week1, how = 'left', on = 'acc_id')\n",
    "X_test2 = pd.merge(X_test2, week2, how = 'left', on = 'acc_id')\n",
    "X_test2 = pd.merge(X_test2, week3, how = 'left', on = 'acc_id')\n",
    "X_test2 = pd.merge(X_test2, week4, how = 'left', on = 'acc_id')\n",
    "X_test2 = X_test2.fillna(0)\n",
    "X_test2['pledge_log_total'] = X_test2['pledge_log_1'] +  X_test2['pledge_log_2'] + X_test2['pledge_log_3'] + X_test2['pledge_log_4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv('./train_preprocess_2.csv', index = False)\n",
    "X_test.to_csv('./test_preprocess_2.csv', index = False)\n",
    "X_test1.to_csv('./test1_preprocess_2.csv', index = False)\n",
    "X_test2.to_csv('./test2_preprocess_2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
