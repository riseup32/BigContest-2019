{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from preprocessing import preprocessing, convert_spectrograms, convert_tensor\n",
    "from model_ae import Encoder\n",
    "from utils.optimization import WarmupLinearSchedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, num_attn_heads, attn_hidden_size, dropout_prob, with_focus_attn):\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        self.num_attn_heads = num_attn_heads\n",
    "        self.hidden_size = attn_hidden_size\n",
    "        self.dropout_prob = dropout_prob\n",
    "        self.with_focus_attn = with_focus_attn\n",
    "        \n",
    "        self.attn_head_size = int(self.hidden_size / self.num_attn_heads)\n",
    "        self.all_head_size = self.num_attn_heads * self.attn_head_size\n",
    "\n",
    "        self.query = nn.Linear(self.hidden_size, self.all_head_size)\n",
    "        self.key = nn.Linear(self.hidden_size, self.all_head_size)\n",
    "        self.value = nn.Linear(self.hidden_size, self.all_head_size)\n",
    "\n",
    "        self.o_proj = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_prob)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        \n",
    "        if(with_focus_attn == True):\n",
    "            self.tanh = nn.Tanh()\n",
    "            self.sigmoid = nn.Sigmoid()\n",
    "            \n",
    "            self.linear_focus_query = nn.Linear(num_attn_heads * self.attn_head_size, \n",
    "                                                num_attn_heads * self.attn_head_size)\n",
    "            self.linear_focus_global = nn.Linear(num_attn_heads * self.attn_head_size, \n",
    "                                                 num_attn_heads * self.attn_head_size)\n",
    "            \n",
    "            up = torch.randn(num_attn_heads, 1, self.attn_head_size)\n",
    "            self.up = Variable(up, requires_grad=True).cuda()\n",
    "            torch.nn.init.xavier_uniform_(self.up)\n",
    "            \n",
    "            uz = torch.randn(num_attn_heads, 1, self.attn_head_size)\n",
    "            self.uz = Variable(uz, requires_grad=True).cuda()\n",
    "            torch.nn.init.xavier_uniform_(self.uz)\n",
    "\n",
    "    def transpose_for_scores(self, x):\n",
    "        new_x_shape = x.size()[:-1] + (self.num_attn_heads, self.attn_head_size)\n",
    "        x = x.view(*new_x_shape)\n",
    "        return x.permute(0, 2, 1, 3)\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        key_len = hidden_states.size(1)\n",
    "        mixed_query_layer = self.query(hidden_states)\n",
    "        mixed_key_layer = self.key(hidden_states)\n",
    "        mixed_value_layer = self.value(hidden_states)\n",
    "        \n",
    "        if(self.with_focus_attn == True):\n",
    "            glo = torch.mean(mixed_query_layer, dim=1, keepdim=True)\n",
    "            \n",
    "            c = self.tanh(self.linear_focus_query(mixed_query_layer) + self.linear_focus_global(glo))\n",
    "            c = self.transpose_for_scores(c)\n",
    "            \n",
    "            p = c * self.up\n",
    "            p = p.sum(3).squeeze()\n",
    "            z = c * self.uz\n",
    "            z = z.sum(3).squeeze()\n",
    "            \n",
    "            P = self.sigmoid(p) * key_len\n",
    "            Z = self.sigmoid(z) * key_len\n",
    "            \n",
    "            j = torch.arange(start=0, end=key_len, dtype=P.dtype).unsqueeze(0).unsqueeze(0).unsqueeze(0).to('cuda')\n",
    "            P = P.unsqueeze(-1)\n",
    "            Z = Z.unsqueeze(-1)\n",
    "            \n",
    "            G = -(j - P)**2 * 2 / (Z**2)\n",
    "\n",
    "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
    "        key_layer = self.transpose_for_scores(mixed_key_layer)\n",
    "        value_layer = self.transpose_for_scores(mixed_value_layer)\n",
    "\n",
    "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
    "        attention_scores = attention_scores / math.sqrt(self.attn_head_size)\n",
    "        \n",
    "        if(self.with_focus_attn == True):\n",
    "            attention_scores = attention_scores + G\n",
    "            \n",
    "        attention_probs = self.softmax(attention_scores)\n",
    "        attention_probs = self.dropout(attention_probs)\n",
    "\n",
    "        context_layer = torch.matmul(attention_probs, value_layer)\n",
    "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
    "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
    "        context_layer = context_layer.view(*new_context_layer_shape)\n",
    "        attention_output = self.o_proj(context_layer)\n",
    "\n",
    "        return attention_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class CLDNN(nn.Module):\n",
    "    def __init__(self, conv_dim, checkpoint=None, hidden_size=60, num_layers=2,\n",
    "                 bidirectional=True, with_focus_attn=False):\n",
    "        super(CLDNN, self).__init__()\n",
    "        self.conv_dim = conv_dim\n",
    "        if(conv_dim == '2d'):\n",
    "            self.conv1 = nn.Sequential(\n",
    "                nn.Conv2d(1, 64, (3, 3)), # (1, 128, 50) -> (64, 126, 48)\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(3, 3)  # (64, 126, 48) -> (64, 42, 16)\n",
    "            )\n",
    "            self.conv2 = nn.Sequential(\n",
    "                nn.Conv2d(64, 64, (3, 3)), # (64, 42, 16) -> (64, 40, 14)\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(3, 3)  # (64, 40, 14) -> (64, 13, 4)\n",
    "            )\n",
    "            self.lstm = nn.LSTM(832, hidden_size=hidden_size, num_layers=num_layers, bidirectional=bidirectional)\n",
    "            self.tanh = nn.Tanh()\n",
    "            self.dropout = nn.Dropout(0.5)\n",
    "            self.attn = MultiHeadedAttention(num_attn_heads=8, attn_hidden_size=120, dropout_prob=0.1,\n",
    "                                             with_focus_attn=with_focus_attn)\n",
    "            self.fc = nn.Sequential(\n",
    "                nn.Linear(4*2*hidden_size if bidirectional else hidden_size, 4)\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"Convolution dimension not found: %s\" % (conv_dim))\n",
    "            \n",
    "    def forward(self, x):\n",
    "        if(self.conv_dim == '2d'):\n",
    "            out = self.conv1(x)  # (batch, 1, 128, 50) -> (batch, 64, 42, 16)\n",
    "            out = self.conv2(out)  # (batch, 64, 42, 16) -> (batch, 64, 13, 4)\n",
    "            new_out_shape = out.size()[:1] + (out.size()[1] * out.size()[2], out.size()[3])\n",
    "            out = out.reshape(*new_out_shape)  # (batch, 64, 13, 4) -> (batch, 832, 4)\n",
    "            out = out.permute(2, 0, 1)  # (batch, 832, 4) -> (4, batch, 832)\n",
    "            self.lstm.flatten_parameters()\n",
    "            out, _ = self.lstm(out)  # (4, batch, 832) -> (4, batch, 2*60)\n",
    "            out = self.tanh(out)\n",
    "            out = self.dropout(out)\n",
    "            out = out.permute(1, 0, 2)  # (4, batch, 2*60) -> (batch, 4, 2*60)\n",
    "            out = self.attn(out)  # (batch, 4, 2*60) -> (batch, 4, 2*60)\n",
    "            new_out_shape = out.size()[:1] + (out.size()[1] * out.size()[2],)\n",
    "            out = out.view(*new_out_shape)  # (batch, 4, 2*60) -> (batch, 4*2*60)\n",
    "            out = self.fc(out)  # (batch, 4*2*60) -> (batch, 4)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN -> LSTM -> self-attention -> DNN\n",
    "class CLDNN(nn.Module):\n",
    "    def __init__(self, conv_dim, checkpoint=None, hidden_size=64, num_layers=2,\n",
    "                 bidirectional=True, with_focus_attn=False):\n",
    "        super(CLDNN, self).__init__()\n",
    "        self.conv_dim = conv_dim\n",
    "        if(conv_dim == '1d'):\n",
    "            self.conv1 = nn.Sequential(\n",
    "                nn.Conv1d(1, 64, (3, 1)), # (1, 40, 50) -> (64, 38, 50)\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d((2, 1), (2, 1))  # (64, 38, 50) -> (64, 19, 50)\n",
    "            )\n",
    "            self.conv2 = nn.Sequential(\n",
    "                nn.Conv1d(64, 64, (3, 1)), # (64, 19, 50) -> (64, 17, 50)\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d((2, 1), (2, 1))  # (64, 17, 50) -> (64, 8, 50)\n",
    "            )\n",
    "            self.lstm = nn.LSTM(512, hidden_size=hidden_size, num_layers=num_layers, bidirectional=bidirectional)\n",
    "            self.tanh = nn.Tanh()\n",
    "            self.dropout = nn.Dropout(0.5)\n",
    "            self.attn = MultiHeadedAttention(num_attn_heads=8, attn_hidden_size=128, dropout_prob=0.1,\n",
    "                                             with_focus_attn=with_focus_attn)\n",
    "            self.fc = nn.Sequential(\n",
    "                nn.Linear(50*2*hidden_size if bidirectional else hidden_size, 128),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(128, 4),\n",
    "                nn.Softmax()\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"Convolution dimension not found: %s\" % (conv_dim))\n",
    "            \n",
    "    def forward(self, x):\n",
    "        if(self.conv_dim == '1d'):\n",
    "            out = self.conv1(x)  # (batch, 1, 40, 50) -> (batch, 64, 19, 50)\n",
    "            out = self.conv2(out)  # (batch, 64, 19, 50) -> (batch, 64, 8, 50)\n",
    "            out = out.contiguous()\n",
    "            new_out_shape = out.size()[:1] + (out.size()[1] * out.size()[2], out.size()[3])\n",
    "            out = out.view(*new_out_shape)  # (batch, 64, 8, 50) -> (batch, 512, 50)\n",
    "            out = out.permute(2, 0, 1)  # (batch, 512, 50) -> (50, batch, 512)\n",
    "            self.lstm.flatten_parameters()\n",
    "            out, _ = self.lstm(out)  # (50, batch, 512) -> (50, batch, 2*64)\n",
    "            out = self.tanh(out)\n",
    "            out = self.dropout(out)\n",
    "            out = out.permute(1, 0, 2)  # (50, batch, 2*64) -> (batch, 50, 2*64)\n",
    "            out = self.attn(out)  # (batch, 50, 2*64) -> (batch, 50, 2*64)\n",
    "            new_out_shape = out.size()[:1] + (out.size()[1] * out.size()[2],)\n",
    "            out = out.view(*new_out_shape)  # (batch, 50, 2*64) -> (batch, 50*2*64)\n",
    "            out = self.fc(out)  # (batch, 50*2*64) -> (batch, 4)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN -> self-attention -> LSTM -> DNN\n",
    "class CLDNN(nn.Module):\n",
    "    def __init__(self, conv_dim, checkpoint=None, hidden_size=64, num_layers=2,\n",
    "                 bidirectional=True, with_focus_attn=False):\n",
    "        super(CLDNN, self).__init__()\n",
    "        self.conv_dim = conv_dim\n",
    "        if(conv_dim == '1d'):\n",
    "            self.conv1 = nn.Sequential(\n",
    "                nn.Conv1d(1, 64, (3, 1)), # (1, 40, 50) -> (64, 38, 50)\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d((2, 1), (2, 1))  # (64, 38, 50) -> (64, 19, 50)\n",
    "            )\n",
    "            self.conv2 = nn.Sequential(\n",
    "                nn.Conv1d(64, 64, (3, 1)), # (64, 19, 50) -> (64, 17, 50)\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d((2, 1), (2, 1))  # (64, 17, 50) -> (64, 8, 50)\n",
    "            )\n",
    "            self.attn = MultiHeadedAttention(num_attn_heads=8, attn_hidden_size=512, dropout_prob=0.1,\n",
    "                                             with_focus_attn=with_focus_attn)\n",
    "            self.lstm = nn.LSTM(512, hidden_size=hidden_size, num_layers=num_layers, bidirectional=bidirectional)\n",
    "            self.tanh = nn.Tanh()\n",
    "            self.dropout = nn.Dropout(0.5)\n",
    "            self.fc = nn.Sequential(\n",
    "                nn.Linear(50*2*hidden_size if bidirectional else hidden_size, 128),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(128, 4)\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"Convolution dimension not found: %s\" % (conv_dim))\n",
    "            \n",
    "    def forward(self, x):\n",
    "        if(self.conv_dim == '1d'):\n",
    "            out = self.conv1(x)  # (batch, 1, 40, 50) -> (batch, 64, 19, 50)\n",
    "            out = self.conv2(out)  # (batch, 64, 19, 50) -> (batch, 64, 8, 50)\n",
    "            new_out_shape = out.size()[:1] + (out.size()[1] * out.size()[2], out.size()[3])\n",
    "            out = out.reshape(*new_out_shape)  # (batch, 64, 8, 50) -> (batch, 512, 50)\n",
    "            out = out.permute(0, 2, 1)  # (batch, 512, 50) -> (batch, 50, 512)\n",
    "            h = out\n",
    "            out = self.attn(out)  # (batch, 50, 512) -> (batch, 50, 512)\n",
    "            out = h + out\n",
    "            out = out.permute(1, 0, 2)  # (batch, 50, 512) -> (50, batch, 512)\n",
    "            self.lstm.flatten_parameters()\n",
    "            out, _ = self.lstm(out)  # (50, batch, 512) -> (50, batch, 2*64)\n",
    "            #out = out[-1]  # (50, batch, 2*64) -> (batch, num_directions*hidden_size)\n",
    "            out = self.tanh(out)\n",
    "            out = self.dropout(out)\n",
    "            out = out.permute(1, 0, 2)  # (50, batch, 2*64) -> (batch, 50, 2*64)\n",
    "            new_out_shape = out.size()[:1] + (out.size()[1] * out.size()[2],)\n",
    "            out = out.view(*new_out_shape)  # (batch, 50, 2*64) -> (batch, 50*2*64)       \n",
    "            out = self.fc(out)  # (batch, 50*2*64) -> (batch, 4)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLDNN_G(nn.Module):\n",
    "    def __init__(self, conv_dim, checkpoint=None, hidden_size=64, num_layers=2,\n",
    "                 bidirectional=True, with_focus_attn=False):\n",
    "        super(CLDNN_G, self).__init__()\n",
    "        self.conv_dim = conv_dim\n",
    "        if(conv_dim == '1d'):\n",
    "            self.encoder = Encoder(conv_dim)\n",
    "            if checkpoint:\n",
    "                self.encoder.load_state_dict(torch.load(checkpoint))\n",
    "            self.attn = MultiHeadedAttention(num_attn_heads=4, attn_hidden_size=8, dropout_prob=0.1,\n",
    "                                             with_focus_attn=with_focus_attn)\n",
    "            self.lstm = nn.LSTM(8, hidden_size=hidden_size, num_layers=num_layers, bidirectional=bidirectional)\n",
    "            self.fc = nn.Sequential(\n",
    "                nn.Linear(hidden_size*2 if bidirectional else hidden_size, 1),\n",
    "                nn.Sigmoid()\n",
    "            )\n",
    "        elif(conv_dim == '2d'):\n",
    "            self.encoder = Encoder(conv_dim)\n",
    "            if checkpoint:\n",
    "                self.encoder.load_state_dict(torch.load(checkpoint))\n",
    "            self.attn = MultiHeadedAttention(num_attn_heads=4, attn_hidden_size=176, dropout_prob=0.1, \n",
    "                                             with_focus_attn=with_focus_attn)\n",
    "            self.gap = nn.AdaptiveAvgPool2d((1, 11))\n",
    "            self.lstm = nn.LSTM(11, hidden_size=hidden_size, num_layers=num_layers, bidirectional=bidirectional)\n",
    "            self.fc = nn.Sequential(\n",
    "                nn.Linear(hidden_size*2 if bidirectional else hidden_size, 1),\n",
    "                nn.Sigmoid()\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"Convolution dimension not found: %s\" % (conv_dim))\n",
    "            \n",
    "    def forward(self, x):\n",
    "        if(self.conv_dim == '1d'):\n",
    "            out = self.encoder(x)  # (batch, 1, 40, 100) -> (batch, 8, 1, 100)\n",
    "            out = torch.squeeze(out, 2)  # (batch, 8, 1, 100) -> (batch, 8, 100)\n",
    "            out = out.permute(0, 2, 1)  # (batch, 8, 100) -> (batch, 100, 8)\n",
    "            h = out\n",
    "            out = self.attn(out)  # (batch, 100, 8) -> (batch, 100, 8)\n",
    "            out = h + out\n",
    "            out = out.permute(1, 0, 2)  # (batch, 100, 8) -> (100, batch, 8)\n",
    "            self.lstm.flatten_parameters()\n",
    "            out, _ = self.lstm(out)  # (100, batch, 8) -> (100, batch, num_directions*hidden_size)\n",
    "            out = out[-1]  # (100, batch, num_directions*hidden_size) -> (batch, num_directions*hidden_size)\n",
    "            out = self.fc(out)  # (batch, num_directions*hidden_size) -> (batch, 1)\n",
    "        elif(self.conv_dim == '2d'):\n",
    "            out = self.encoder(x)  # (batch, 1, 128, 100) -> (batch, 16, 11, 8)\n",
    "            out = out.permute(0, 3, 1, 2)  # (batch, 16, 11, 8) -> (batch, 8, 16, 11)\n",
    "            h = out\n",
    "            new_out_shape = out.size()[:2] + (out.size()[2] * out.size()[3],)\n",
    "            out = out.view(*new_out_shape)  # (batch, 8, 16, 11) -> (batch, 8, 176)\n",
    "            out = self.attn(out)  # (batch, 8, 176) -> (batch, 8, 176)\n",
    "            out = out.view(h.size())  # (batch, 8, 176) -> (batch, 8, 16, 11)\n",
    "            out = h + out\n",
    "            out = self.gap(out)  # (batch, 8, 16, 11) -> (batch, 8, 1, 11)\n",
    "            out = torch.squeeze(out, 2)  # (batch, 8, 1, 11) -> (batch, 8, 11)\n",
    "            out = out.permute(1, 0, 2)  # (batch, 8, 11) -> (8, batch, 11)\n",
    "            self.lstm.flatten_parameters()\n",
    "            out, _ = self.lstm(out)  # (8, batch, 11) -> (8, batch, num_directions*hidden_size)\n",
    "            out = out[-1]  # (8, batch, num_directions*hidden_size) -> (batch, num_directions*hidden_size)\n",
    "            out = self.fc(out)  # (batch, num_directions*hidden_size) -> (batch, 1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader, eval_dataloader, epochs):\n",
    "    print('Start training')\n",
    "    max_acc = 0\n",
    "    acc_list = []\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        nb_train_steps = 0\n",
    "        correct = 0\n",
    "        num_samples = 0\n",
    "\n",
    "        if(multi_task == 'true'):\n",
    "            for X_batch, y_batch, y_g_batch in train_dataloader:\n",
    "                X_batch = X_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                y_g_batch = y_g_batch.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = model(X_batch)\n",
    "                outputs_g = model_g(X_batch)\n",
    "\n",
    "                loss_1 = loss_func(outputs, y_batch)\n",
    "                loss_2 = loss_func_g(outputs_g, y_g_batch)\n",
    "                loss = loss_1 + 0.8 * loss_2\n",
    "                loss.backward(retain_graph=True)\n",
    "\n",
    "                optimizer.step()\n",
    "                opt_scheduler.step()\n",
    "\n",
    "                train_loss += loss.mean().item()\n",
    "                nb_train_steps += 1\n",
    "\n",
    "                outputs = softmax(outputs)\n",
    "                outputs = torch.argmax(outputs, dim=1)\n",
    "                correct += (outputs == y_batch).float().sum()\n",
    "                num_samples += len(X_batch)\n",
    "\n",
    "            train_loss = train_loss / nb_train_steps\n",
    "            train_accuracy = correct / num_samples\n",
    "\n",
    "            model.eval()\n",
    "            eval_loss = 0\n",
    "            nb_eval_steps = 0\n",
    "            correct = 0\n",
    "            num_samples = 0\n",
    "\n",
    "            for X_batch, y_batch, y_g_batch in eval_dataloader:\n",
    "                X_batch = X_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                y_g_batch = y_g_batch.to(device)\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(X_batch)\n",
    "                    outputs_g = model_g(X_batch)\n",
    "\n",
    "                tmp_eval_loss_1 = loss_func(outputs, y_batch)\n",
    "                tmp_eval_loss_2 = loss_func_g(outputs_g, y_g_batch)\n",
    "                tmp_eval_loss = tmp_eval_loss_1 + 0.8 * tmp_eval_loss_2\n",
    "                eval_loss += tmp_eval_loss.mean().item()\n",
    "                nb_eval_steps += 1\n",
    "\n",
    "                outputs = softmax(outputs)\n",
    "                outputs = torch.argmax(outputs, dim=1)\n",
    "                correct += (outputs == y_batch).float().sum()\n",
    "                num_samples += len(X_batch)\n",
    "\n",
    "            eval_loss = eval_loss / nb_eval_steps\n",
    "            eval_accuracy = correct / num_samples\n",
    "        else:\n",
    "            for X_batch, y_batch in train_dataloader:\n",
    "                X_batch = X_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = model(X_batch)\n",
    "\n",
    "                loss = loss_func(outputs, y_batch)\n",
    "                loss.backward()\n",
    "\n",
    "                optimizer.step()\n",
    "                if(use_warmup == 'true'):\n",
    "                    opt_scheduler.step()\n",
    "\n",
    "                train_loss += loss.mean().item()\n",
    "                nb_train_steps += 1\n",
    "\n",
    "                #outputs = softmax(outputs)\n",
    "                #outputs = torch.argmax(outputs, dim=1)\n",
    "                #correct += (outputs == y_batch).float().sum()\n",
    "                #num_samples += len(X_batch)\n",
    "\n",
    "            train_loss = train_loss / nb_train_steps\n",
    "            #train_accuracy = correct / num_samples\n",
    "\n",
    "            model.eval()\n",
    "            eval_loss = 0\n",
    "            nb_eval_steps = 0\n",
    "            correct = 0\n",
    "            num_samples = 0\n",
    "\n",
    "            for X_batch, y_batch in eval_dataloader:\n",
    "                X_batch = X_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(X_batch)\n",
    "\n",
    "                tmp_eval_loss = loss_func(outputs, y_batch)\n",
    "                eval_loss += tmp_eval_loss.mean().item()\n",
    "                nb_eval_steps += 1\n",
    "\n",
    "                #outputs = softmax(outputs)\n",
    "                #outputs = torch.argmax(outputs, dim=1)\n",
    "                #correct += (outputs == y_batch).float().sum()\n",
    "                #num_samples += len(X_batch)\n",
    "\n",
    "            eval_loss = eval_loss / nb_eval_steps\n",
    "            #eval_accuracy = correct / num_samples\n",
    "\n",
    "        for param_group in optimizer.param_groups:\n",
    "            lr = param_group['lr']\n",
    "        print('epoch: {:3d},    lr={:6f},    loss={:5f},    eval_loss={:5f}'\n",
    "              .format(epoch+1, lr, train_loss, eval_loss))\n",
    "        #print('epoch: {:3d},    lr={:6f},    loss={:5f},    train_acc={:5f},    eval_loss={:5f},    eval_acc={:5f}'\n",
    "        #      .format(epoch+1, lr, train_loss, train_accuracy, eval_loss, eval_accuracy))\n",
    "\n",
    "        if((epoch+1) % save_checkpoint_steps == 0):\n",
    "            '''\n",
    "            correct = 0\n",
    "            n = 0\n",
    "            for i in range(len(eval_samples)):\n",
    "                try:\n",
    "                    X_new = preprocessing(eval_samples[i], method='mfcc', sr=16000, n_mfcc=n_mfcc)\n",
    "                    X_new = convert_tensor(X_new).to(device)\n",
    "                    y_new = model(X_new)\n",
    "                    y_new = torch.argmax(torch.mean(nn.Softmax(dim=-1)(y_new), dim=0))\n",
    "                    #y_new = torch.argmax(nn.Softmax(dim=-1)(torch.mean(y_new, dim=0)))\n",
    "                    #y_new = sorted(dict(collections.Counter(torch.argmax(nn.Softmax(dim=-1)(y_new), dim=1).cpu().numpy()))\n",
    "                    #               .items(), key=(lambda x: x[1]), reverse=True)[0][0]\n",
    "                    y_new = 1 if (y_new.item() == np.array(eval_label)[i]) else 0\n",
    "                    correct += y_new\n",
    "                    n += 1\n",
    "                except:\n",
    "                    pass\n",
    "            acc = correct / n\n",
    "            acc_list.append(acc)\n",
    "            print('Test accuray:', round(acc, 5))\n",
    "            '''\n",
    "            \n",
    "            model_checkpoint = \"CLDNN_cv%d_step%d_epoch%d.pt\" % (cv_iter, en+1, epoch+1)\n",
    "            output_model_file = os.path.join(output_dir, model_checkpoint)\n",
    "            torch.save(model.state_dict(), output_model_file)\n",
    "            print(\"Saving checkpoint %s\" % output_model_file)\n",
    "            #if(acc > max_acc):\n",
    "            #    max_acc =acc\n",
    "            #    torch.save(model.state_dict(), output_model_file)\n",
    "            #    print(\"Saving checkpoint %s\" % output_model_file)\n",
    "    #return max(acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "focus_attn_list = [True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('IEMOCAP_sub_label.csv')\n",
    "di = {'neu': 0, 'hap': 1, 'ang': 2, 'sad': 3}\n",
    "df = df.replace({'sample_label': di})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_path = './wav_data/pretrain/IEMOCAP_label/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for with_focus_attn in focus_attn_list:\n",
    "    cv_eval = []\n",
    "    cv_iter = 0\n",
    "    #with_focus_attn = True if(with_focus_attn == 'true') else False\n",
    "    for train_index, eval_index in skf.split(df['sample_name'], df['sample_label']):\n",
    "        '''\n",
    "    for ses_num in range(1, 6):\n",
    "        eval_ses = 'Ses0' + str(ses_num)\n",
    "        train_index = []\n",
    "        eval_index = []\n",
    "        for i, sample_name in enumerate(df['sample_name']):\n",
    "            if eval_ses in sample_name:\n",
    "                eval_index.append(i)\n",
    "            else:\n",
    "                train_index.append(i)\n",
    "        '''\n",
    "        cv_iter += 1\n",
    "        conv_dim = '1d'\n",
    "        checkpoint = ''\n",
    "        hidden_size = 64\n",
    "        num_layers = 2\n",
    "        bidirectional = 'true'\n",
    "\n",
    "        batch_size = 128\n",
    "        num_epochs = 30\n",
    "        learning_rate = 0.0001\n",
    "\n",
    "        use_warmup = 'false'\n",
    "        data_dir = './wav_data/pretrain/IEMOCAP_sub/'\n",
    "        multi_task = 'false'\n",
    "        augmentation = 'false'\n",
    "        \n",
    "        save_checkpoint_steps = 5\n",
    "        output_dir = './model'\n",
    "\n",
    "        bidirectional = True if(bidirectional == 'true') else False  \n",
    "        n_mfcc = 40 if(conv_dim == '1d') else 128\n",
    "\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        train_samples, eval_samples = df['sample_name'][train_index], df['sample_name'][eval_index]\n",
    "        train_label = [label_path + train_sample + '.npy' for train_sample in train_samples]\n",
    "        eval_label = [label_path + eval_sample + '.npy' for eval_sample in eval_samples]\n",
    "        \n",
    "        train_samples = [data_dir + train_sample + '.wav' for train_sample in train_samples]\n",
    "        eval_samples = [data_dir + eval_sample + '.wav' for eval_sample in eval_samples]\n",
    "\n",
    "        train_label_list = []\n",
    "        for i in range(len(train_label)):\n",
    "            label = np.load(train_label[i])\n",
    "            train_label_list.append(label)\n",
    "        y_train = np.concatenate(train_label_list)\n",
    "\n",
    "        eval_label_list = []\n",
    "        for i in range(len(eval_label)):\n",
    "            label = np.load(eval_label[i])\n",
    "            eval_label_list.append(label)\n",
    "        y_eval = np.concatenate(eval_label_list)\n",
    "\n",
    "        if(multi_task == 'true'):\n",
    "            speaker = np.array(list(map(lambda x: int(x.split('/')[-1].split('-')[-1].split('.')[0]), sample_datas)))\n",
    "            y_gender = np.array(list(map(lambda x: 1 if x % 2 ==0 else 0, speaker)))\n",
    "\n",
    "            y_g_train = y_gender[train_idx]\n",
    "            y_g_eval = y_gender[eval_idx]\n",
    "\n",
    "        X_train = convert_spectrograms(train_samples, conv_dim=conv_dim, sr=16000)\n",
    "        X_eval = convert_spectrograms(eval_samples, conv_dim=conv_dim, sr=16000)\n",
    "\n",
    "        if(augmentation == 'true'):\n",
    "            X_train_flip = X_train[:, :, :, ::-1]\n",
    "            y_train_flip = y_train.copy()\n",
    "\n",
    "            X_train = np.concatenate((X_train, X_train_flip), axis=0)\n",
    "            y_train = np.concatenate((y_train, y_train_flip), axis=0)\n",
    "\n",
    "        X_train, y_train = convert_tensor(X_train, y_train)\n",
    "        X_eval, y_eval = convert_tensor(X_eval, y_eval)\n",
    "\n",
    "        #y_train = y_train.long()\n",
    "        #y_eval = y_eval.long()\n",
    "\n",
    "        if(multi_task == 'true'):\n",
    "            _, y_g_train = convert_spectrograms(train_samples, conv_dim=conv_dim, sr=16000, labels=y_g_train)\n",
    "            _, y_g_eval = convert_spectrograms(eval_samples, conv_dim=conv_dim, sr=16000, labels=y_g_eval)\n",
    "\n",
    "            if(augmentation == 'true'):\n",
    "                y_g_train_flip = y_g_train.copy()\n",
    "                y_g_train = np.concatenate((y_g_train, y_g_train_flip))\n",
    "\n",
    "            y_g_train = torch.tensor(y_g_train).float()\n",
    "            y_g_eval = torch.tensor(y_g_eval).float()\n",
    "\n",
    "            y_g_train = y_g_train.unsqueeze(-1)\n",
    "            y_g_eval = y_g_eval.unsqueeze(-1)\n",
    "\n",
    "        if(multi_task == 'true'):\n",
    "            train_ds = TensorDataset(X_train, y_train, y_g_train)\n",
    "            eval_ds = TensorDataset(X_eval, y_eval, y_g_eval)\n",
    "        else:\n",
    "            train_ds = TensorDataset(X_train, y_train)\n",
    "            eval_ds = TensorDataset(X_eval, y_eval)\n",
    "\n",
    "        train_dataloader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=0, drop_last=True)\n",
    "        eval_dataloader = DataLoader(eval_ds, batch_size=batch_size, num_workers=0)\n",
    "\n",
    "        for en in range(2):\n",
    "            model = CLDNN(conv_dim=conv_dim, checkpoint=checkpoint, hidden_size=hidden_size,\n",
    "                          num_layers=num_layers, bidirectional=bidirectional,\n",
    "                          with_focus_attn=with_focus_attn).to(device)\n",
    "\n",
    "            if(multi_task == 'true'):\n",
    "                model_g = CLDNN_G(conv_dim=conv_dim, checkpoint=checkpoint, hidden_size=hidden_size,\n",
    "                                    num_layers=num_layers, bidirectional=bidirectional,\n",
    "                                    with_focus_attn=with_focus_attn).to(device)\n",
    "\n",
    "            if(multi_task == 'true'):\n",
    "                loss_func = nn.CrossEntropyLoss()\n",
    "                loss_func_g = nn.BCELoss()\n",
    "                optimizer = optim.Adam(list(model.parameters()) + list(model_g.parameters()), lr=learning_rate)\n",
    "            else:\n",
    "                loss_func = nn.KLDivLoss()\n",
    "                optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "            if(use_warmup == 'true'):\n",
    "                t_total = len(train_dataloader) // 1 * num_epochs\n",
    "                opt_scheduler = WarmupLinearSchedule(optimizer, warmup_steps=t_total * 0.1, t_total=t_total)\n",
    "\n",
    "            eval_acc = train(train_dataloader, eval_dataloader, num_epochs)\n",
    "            cv_eval.append(eval_acc)\n",
    "\n",
    "    print('conv_dim:', conv_dim, '\\twith_focus_attn:', with_focus_attn)\n",
    "    print('Test accuray:', cv_eval)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = './model/KLloss'\n",
    "model_path_list = glob.glob(os.path.join(model_dir, '*pt'), recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./model/KLloss/CLDNN_cv1_step1_epoch5.pt',\n",
       " './model/KLloss/CLDNN_cv1_step1_epoch10.pt',\n",
       " './model/KLloss/CLDNN_cv1_step1_epoch15.pt',\n",
       " './model/KLloss/CLDNN_cv1_step1_epoch25.pt',\n",
       " './model/KLloss/CLDNN_cv1_step1_epoch30.pt',\n",
       " './model/KLloss/CLDNN_cv1_step1_epoch20.pt',\n",
       " './model/KLloss/CLDNN_cv1_step2_epoch5.pt',\n",
       " './model/KLloss/CLDNN_cv1_step2_epoch10.pt',\n",
       " './model/KLloss/CLDNN_cv1_step2_epoch15.pt',\n",
       " './model/KLloss/CLDNN_cv1_step2_epoch20.pt',\n",
       " './model/KLloss/CLDNN_cv1_step2_epoch25.pt',\n",
       " './model/KLloss/CLDNN_cv1_step2_epoch30.pt']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/449 [00:00<?, ?it/s]/home/junghun/.local/lib/python3.6/site-packages/torch/nn/modules/container.py:117: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n",
      "100%|██████████| 449/449 [00:08<00:00, 55.79it/s]\n",
      "  2%|▏         | 8/449 [00:00<00:06, 73.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLDNN_cv1_step1_epoch5.pt : 0.5679287305122495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [00:08<00:00, 55.69it/s]\n",
      "  2%|▏         | 8/449 [00:00<00:05, 75.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLDNN_cv1_step1_epoch10.pt : 0.621380846325167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [00:07<00:00, 58.15it/s]\n",
      "  2%|▏         | 8/449 [00:00<00:05, 74.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLDNN_cv1_step1_epoch15.pt : 0.621380846325167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [00:07<00:00, 57.45it/s]\n",
      "  2%|▏         | 8/449 [00:00<00:05, 74.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLDNN_cv1_step1_epoch25.pt : 0.621380846325167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [00:07<00:00, 57.44it/s]\n",
      "  2%|▏         | 8/449 [00:00<00:05, 73.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLDNN_cv1_step1_epoch30.pt : 0.5924276169265034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [00:07<00:00, 56.83it/s]\n",
      "  2%|▏         | 8/449 [00:00<00:06, 63.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLDNN_cv1_step1_epoch20.pt : 0.6080178173719376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [00:07<00:00, 56.25it/s]\n",
      "  1%|▏         | 6/449 [00:00<00:07, 59.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLDNN_cv1_step2_epoch5.pt : 0.532293986636971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [00:07<00:00, 56.26it/s]\n",
      "  2%|▏         | 8/449 [00:00<00:06, 72.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLDNN_cv1_step2_epoch10.pt : 0.6035634743875279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [00:07<00:00, 57.01it/s]\n",
      "  2%|▏         | 8/449 [00:00<00:05, 73.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLDNN_cv1_step2_epoch15.pt : 0.5545657015590201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [00:07<00:00, 56.30it/s]\n",
      "  2%|▏         | 8/449 [00:00<00:05, 74.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLDNN_cv1_step2_epoch20.pt : 0.5946547884187082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [00:07<00:00, 56.56it/s]\n",
      "  2%|▏         | 8/449 [00:00<00:06, 71.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLDNN_cv1_step2_epoch25.pt : 0.6102449888641426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [00:07<00:00, 56.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLDNN_cv1_step2_epoch30.pt : 0.5679287305122495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cv_iter = 0\n",
    "for train_index, eval_index in skf.split(df['sample_name'], df['sample_label']):\n",
    "    cv_iter += 1\n",
    "    data_dir = './wav_data/pretrain/IEMOCAP_sub/'\n",
    "    \n",
    "    train_samples, eval_samples = df['sample_name'][train_index], df['sample_name'][eval_index]\n",
    "    train_label, eval_label = df['sample_label'][train_index], df['sample_label'][eval_index]\n",
    "\n",
    "    train_samples = [data_dir + train_sample + '.wav' for train_sample in train_samples]\n",
    "    eval_samples = [data_dir + eval_sample + '.wav' for eval_sample in eval_samples]\n",
    "    \n",
    "    model_paths = [ckpt for ckpt in model_path_list if 'cv%d'%cv_iter in ckpt][:12]\n",
    "    \n",
    "    for ckpt in model_paths:\n",
    "        model = CLDNN(conv_dim=conv_dim, checkpoint=checkpoint, hidden_size=hidden_size,\n",
    "                              num_layers=num_layers, bidirectional=bidirectional,\n",
    "                              with_focus_attn=with_focus_attn).to(device)\n",
    "        model.load_state_dict(torch.load(ckpt))\n",
    "        model.eval()\n",
    "\n",
    "        correct = 0\n",
    "        n = 0\n",
    "        for i in tqdm(range(len(eval_samples))):\n",
    "            try:\n",
    "                X_new = preprocessing(eval_samples[i], method='mfcc', sr=16000, n_mfcc=n_mfcc)\n",
    "                X_new = convert_tensor(X_new).to(device)\n",
    "                y_new = model(X_new)\n",
    "                y_new = torch.argmax(torch.mean(nn.Softmax(dim=-1)(y_new), dim=0))\n",
    "                #y_new = torch.argmax(nn.Softmax(dim=-1)(torch.mean(y_new, dim=0)))\n",
    "                #y_new = sorted(dict(collections.Counter(torch.argmax(nn.Softmax(dim=-1)(y_new), dim=1).cpu().numpy()))\n",
    "                #               .items(), key=(lambda x: x[1]), reverse=True)[0][0]\n",
    "                y_new = 1 if (y_new.item() == np.array(eval_label)[i]) else 0\n",
    "                correct += y_new\n",
    "                n += 1\n",
    "            except:\n",
    "                pass\n",
    "        acc = correct / n\n",
    "        \n",
    "        print(ckpt.split('/')[-1], ':', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_focus_attn = [0.6570155902004454, 0.6124721603563474, 0.6347438752783965, \n",
    "                   0.6926503340757239, 0.6280623608017817, 0.6169265033407573, \n",
    "                   0.5812917594654788, 0.6013363028953229, 0.6948775055679287, 0.6792873051224945]\n",
    "without_focus_attn = [0.6347438752783965, 0.6258351893095768, 0.6057906458797327, \n",
    "                      0.7037861915367484, 0.6035634743875279, 0.5946547884187082, \n",
    "                      0.6146993318485523, 0.6325167037861915, 0.688195991091314, 0.6681514476614699]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with_focus_attn: 0.6398663697104678\n",
      "without_focus_attn: 0.6371937639198219\n"
     ]
    }
   ],
   "source": [
    "print('with_focus_attn:', sum(with_focus_attn) / 10)\n",
    "print('without_focus_attn:', sum(without_focus_attn) / 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1327044"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p.numel() for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLDNN(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv1d(1, 64, kernel_size=(3, 1), stride=(1,))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv1d(64, 64, kernel_size=(3, 1), stride=(1,))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (lstm): LSTM(512, 64, num_layers=2, bidirectional=True)\n",
       "  (tanh): Tanh()\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (attn): MultiHeadedAttention(\n",
       "    (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (o_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (softmax): Softmax(dim=-1)\n",
       "    (tanh): Tanh()\n",
       "    (sigmoid): Sigmoid()\n",
       "    (linear_focus_query): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (linear_focus_global): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=6400, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_focus_attn = [0.623608017817372, 0.6503340757238307, 0.6280623608017817, \n",
    "                   0.7015590200445434, 0.6302895322939867, 0.6057906458797327, \n",
    "                   0.6057906458797327, 0.6102449888641426, 0.6547884187082406, 0.6570155902004454]\n",
    "without_focus_attn = [0.6302895322939867, 0.6391982182628062, 0.623608017817372, \n",
    "                      0.7082405345211581, 0.6124721603563474, 0.6035634743875279, \n",
    "                      0.6102449888641426, 0.6124721603563474, 0.6547884187082406, 0.6636971046770601]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with_focus_attn: 0.6367483296213808\n",
      "without_focus_attn: 0.6358574610244988\n"
     ]
    }
   ],
   "source": [
    "print('with_focus_attn:', sum(with_focus_attn) / 10)\n",
    "print('without_focus_attn:', sum(without_focus_attn) / 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLDNN(nn.Module):\n",
    "    def __init__(self, conv_dim, checkpoint=None, hidden_size=128, num_layers=2,\n",
    "                 bidirectional=True, with_focus_attn=False):\n",
    "        super(CLDNN, self).__init__()\n",
    "        self.conv_dim = conv_dim\n",
    "        if(conv_dim == '1d'):\n",
    "            self.encoder = Encoder(conv_dim)\n",
    "            if checkpoint:\n",
    "                self.encoder.load_state_dict(torch.load(checkpoint))\n",
    "            self.lstm = nn.LSTM(8, hidden_size=hidden_size, num_layers=num_layers, bidirectional=bidirectional)\n",
    "            self.tanh = nn.Tanh()\n",
    "            self.dropout = nn.Dropout(0.1)\n",
    "            self.attn = MultiHeadedAttention(num_attn_heads=4, attn_hidden_size=256, dropout_prob=0.1,\n",
    "                                             with_focus_attn=with_focus_attn)\n",
    "            self.fc = nn.Sequential(\n",
    "                nn.Linear(50*2*hidden_size if bidirectional else 50*hidden_size, 64),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(64, 4)\n",
    "            )\n",
    "        elif(conv_dim == '2d'):\n",
    "            self.encoder = Encoder(conv_dim)\n",
    "            if checkpoint:\n",
    "                self.encoder.load_state_dict(torch.load(checkpoint))\n",
    "            self.attn = MultiHeadedAttention(num_attn_heads=4, attn_hidden_size=176, dropout_prob=0.1, \n",
    "                                             with_focus_attn=with_focus_attn)\n",
    "            self.gap = nn.AdaptiveAvgPool2d((1, 11))\n",
    "            self.lstm = nn.LSTM(11, hidden_size=hidden_size, num_layers=num_layers, bidirectional=bidirectional) \n",
    "            self.fc = nn.Sequential(\n",
    "                nn.Linear(hidden_size*2 if bidirectional else hidden_size, 4)\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"Convolution dimension not found: %s\" % (conv_dim))\n",
    "            \n",
    "    def forward(self, x):\n",
    "        if(self.conv_dim == '1d'):\n",
    "            out = self.encoder(x)  # (batch, 1, 40, 50) -> (batch, 8, 1, 50)\n",
    "            out = torch.squeeze(out, 2)  # (batch, 8, 1, 50) -> (batch, 8, 50)\n",
    "            out = out.permute(2, 0, 1)  # (batch, 8, 50) -> (50, batch, 8)\n",
    "            out, _ = self.lstm(out)  # (50, batch, 8) -> (50, batch, num_directions*hidden_size)\n",
    "            out = self.tanh(out)\n",
    "            out = self.dropout(out)\n",
    "            out = out.permute(1, 0, 2)  # (50, batch, num_directions*hidden_size) -> (batch, 50, num_directions*hidden_size)\n",
    "            h = out\n",
    "            out = self.attn(out) # (batch, 50, num_directions*hidden_size) -> (batch, 50, num_directions*hidden_size)\n",
    "            out = h + out\n",
    "            new_out_shape = out.size()[:1] + (out.size()[1] * out.size()[2],)\n",
    "            out = out.reshape(*new_out_shape)  # (batch, 50, num_directions*hidden_size) -> (batch, 50*num_directions*hidden_size)\n",
    "            out = self.fc(out)  # (batch, 50*num_directions*hidden_size) -> (batch, 4)\n",
    "        elif(self.conv_dim == '2d'):\n",
    "            out = self.encoder(x)  # (batch, 1, 128, 100) -> (batch, 16, 11, 8)\n",
    "            out = out.permute(0, 3, 1, 2)  # (batch, 16, 11, 8) -> (batch, 8, 16, 11)\n",
    "            h = out\n",
    "            new_out_shape = out.size()[:2] + (out.size()[2] * out.size()[3],)\n",
    "            out = out.view(*new_out_shape)  # (batch, 8, 16, 11) -> (batch, 8, 176)\n",
    "            out = self.attn(out)  # (batch, 8, 176) -> (batch, 8, 176)\n",
    "            out = out.view(h.size())  # (batch, 8, 176) -> (batch, 8, 16, 11)\n",
    "            out = h + out\n",
    "            out = self.gap(out)  # (batch, 8, 16, 11) -> (batch, 8, 1, 11)\n",
    "            out = torch.squeeze(out, 2)  # (batch, 8, 1, 11) -> (batch, 8, 11)\n",
    "            out = out.permute(1, 0, 2)  # (batch, 8, 11) -> (8, batch, 11)\n",
    "            out, _ = self.lstm(out)  # (8, batch, 11) -> (8, batch, num_directions*hidden_size)\n",
    "            out = out[-1]  # (8, batch, num_directions*hidden_size) -> (batch, num_directions*hidden_size)\n",
    "            out = self.fc(out)  # (batch, num_directions*hidden_size) -> (batch, 1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4041it [00:28, 141.44it/s]\n",
      "449it [00:03, 139.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "epoch:   1,    lr=0.000200,    loss=1.145764,    train_acc=0.494389,    eval_loss=0.975452,    eval_acc=0.564436\n",
      "epoch:   2,    lr=0.000400,    loss=0.999604,    train_acc=0.592781,    eval_loss=0.927232,    eval_acc=0.603390\n",
      "epoch:   3,    lr=0.000600,    loss=0.949947,    train_acc=0.618561,    eval_loss=0.928751,    eval_acc=0.599315\n",
      "epoch:   4,    lr=0.000800,    loss=0.923217,    train_acc=0.631525,    eval_loss=0.895027,    eval_acc=0.618005\n",
      "epoch:   5,    lr=0.001000,    loss=0.904673,    train_acc=0.640466,    eval_loss=0.982887,    eval_acc=0.582636\n",
      "Test accuray: 0.57238\n",
      "epoch:   6,    lr=0.000978,    loss=0.889310,    train_acc=0.646794,    eval_loss=0.904333,    eval_acc=0.623492\n",
      "epoch:   7,    lr=0.000956,    loss=0.874368,    train_acc=0.653000,    eval_loss=0.917226,    eval_acc=0.616212\n",
      "epoch:   8,    lr=0.000933,    loss=0.860490,    train_acc=0.658562,    eval_loss=0.890120,    eval_acc=0.616321\n",
      "epoch:   9,    lr=0.000911,    loss=0.846037,    train_acc=0.665246,    eval_loss=0.895317,    eval_acc=0.610073\n",
      "epoch:  10,    lr=0.000889,    loss=0.826945,    train_acc=0.671900,    eval_loss=0.909821,    eval_acc=0.617299\n",
      "Test accuray: 0.57906\n",
      "epoch:  11,    lr=0.000867,    loss=0.808135,    train_acc=0.680773,    eval_loss=0.941112,    eval_acc=0.612463\n",
      "epoch:  12,    lr=0.000844,    loss=0.780554,    train_acc=0.689383,    eval_loss=0.964364,    eval_acc=0.600511\n",
      "epoch:  13,    lr=0.000822,    loss=0.739217,    train_acc=0.706326,    eval_loss=1.024825,    eval_acc=0.596436\n",
      "epoch:  14,    lr=0.000800,    loss=0.689224,    train_acc=0.726697,    eval_loss=1.038567,    eval_acc=0.597251\n",
      "epoch:  15,    lr=0.000778,    loss=0.626413,    train_acc=0.752330,    eval_loss=1.150384,    eval_acc=0.593774\n",
      "Test accuray: 0.60802\n",
      "epoch:  16,    lr=0.000756,    loss=0.560354,    train_acc=0.777957,    eval_loss=1.353483,    eval_acc=0.582636\n",
      "epoch:  17,    lr=0.000733,    loss=0.492161,    train_acc=0.805656,    eval_loss=1.390579,    eval_acc=0.589101\n",
      "epoch:  18,    lr=0.000711,    loss=0.428529,    train_acc=0.830382,    eval_loss=1.541723,    eval_acc=0.581712\n",
      "epoch:  19,    lr=0.000689,    loss=0.373464,    train_acc=0.853506,    eval_loss=1.661980,    eval_acc=0.573889\n",
      "epoch:  20,    lr=0.000667,    loss=0.321069,    train_acc=0.874393,    eval_loss=1.884315,    eval_acc=0.554765\n",
      "Test accuray: 0.58797\n",
      "epoch:  21,    lr=0.000644,    loss=0.278301,    train_acc=0.891796,    eval_loss=2.034026,    eval_acc=0.562914\n",
      "epoch:  22,    lr=0.000622,    loss=0.241198,    train_acc=0.906851,    eval_loss=2.154237,    eval_acc=0.563077\n",
      "epoch:  23,    lr=0.000600,    loss=0.207713,    train_acc=0.919827,    eval_loss=2.305000,    eval_acc=0.564816\n",
      "epoch:  24,    lr=0.000578,    loss=0.179129,    train_acc=0.931368,    eval_loss=2.344684,    eval_acc=0.565576\n",
      "epoch:  25,    lr=0.000556,    loss=0.157634,    train_acc=0.940591,    eval_loss=2.534377,    eval_acc=0.564979\n",
      "Test accuray: 0.60134\n",
      "epoch:  26,    lr=0.000533,    loss=0.131924,    train_acc=0.950997,    eval_loss=2.826271,    eval_acc=0.569054\n",
      "epoch:  27,    lr=0.000511,    loss=0.116794,    train_acc=0.957221,    eval_loss=2.754945,    eval_acc=0.575682\n",
      "epoch:  28,    lr=0.000489,    loss=0.100044,    train_acc=0.963403,    eval_loss=2.888766,    eval_acc=0.568347\n",
      "epoch:  29,    lr=0.000467,    loss=0.084469,    train_acc=0.969474,    eval_loss=3.127480,    eval_acc=0.565196\n",
      "epoch:  30,    lr=0.000444,    loss=0.076943,    train_acc=0.972129,    eval_loss=3.254899,    eval_acc=0.564273\n",
      "Test accuray: 0.60579\n",
      "epoch:  31,    lr=0.000422,    loss=0.068546,    train_acc=0.975729,    eval_loss=3.289328,    eval_acc=0.561719\n",
      "epoch:  32,    lr=0.000400,    loss=0.055220,    train_acc=0.980457,    eval_loss=3.403726,    eval_acc=0.559817\n",
      "epoch:  33,    lr=0.000378,    loss=0.049804,    train_acc=0.982517,    eval_loss=3.745397,    eval_acc=0.559600\n",
      "epoch:  34,    lr=0.000356,    loss=0.045400,    train_acc=0.984289,    eval_loss=3.611315,    eval_acc=0.562317\n",
      "epoch:  35,    lr=0.000333,    loss=0.039617,    train_acc=0.986411,    eval_loss=3.827218,    eval_acc=0.564055\n",
      "Test accuray: 0.61247\n",
      "epoch:  36,    lr=0.000311,    loss=0.033506,    train_acc=0.988416,    eval_loss=3.967992,    eval_acc=0.563675\n",
      "epoch:  37,    lr=0.000289,    loss=0.030003,    train_acc=0.989986,    eval_loss=3.921733,    eval_acc=0.559220\n",
      "epoch:  38,    lr=0.000267,    loss=0.025743,    train_acc=0.991513,    eval_loss=4.066288,    eval_acc=0.561067\n",
      "epoch:  39,    lr=0.000244,    loss=0.023548,    train_acc=0.992053,    eval_loss=4.199607,    eval_acc=0.557481\n",
      "epoch:  40,    lr=0.000222,    loss=0.019575,    train_acc=0.993586,    eval_loss=4.311086,    eval_acc=0.554004\n",
      "Test accuray: 0.59243\n",
      "epoch:  41,    lr=0.000200,    loss=0.016480,    train_acc=0.994732,    eval_loss=4.299868,    eval_acc=0.570086\n",
      "epoch:  42,    lr=0.000178,    loss=0.014853,    train_acc=0.995088,    eval_loss=4.404168,    eval_acc=0.563947\n",
      "epoch:  43,    lr=0.000156,    loss=0.013035,    train_acc=0.996063,    eval_loss=4.383989,    eval_acc=0.565631\n",
      "epoch:  44,    lr=0.000133,    loss=0.010810,    train_acc=0.996658,    eval_loss=4.492995,    eval_acc=0.562806\n",
      "epoch:  45,    lr=0.000111,    loss=0.008238,    train_acc=0.997639,    eval_loss=4.605075,    eval_acc=0.563132\n",
      "Test accuray: 0.6147\n",
      "epoch:  46,    lr=0.000089,    loss=0.007253,    train_acc=0.997940,    eval_loss=4.620021,    eval_acc=0.565848\n",
      "epoch:  47,    lr=0.000067,    loss=0.006452,    train_acc=0.998142,    eval_loss=4.768097,    eval_acc=0.560415\n",
      "epoch:  48,    lr=0.000044,    loss=0.004615,    train_acc=0.998792,    eval_loss=4.792300,    eval_acc=0.566609\n",
      "epoch:  49,    lr=0.000022,    loss=0.003743,    train_acc=0.999092,    eval_loss=4.823821,    eval_acc=0.562860\n",
      "epoch:  50,    lr=0.000000,    loss=0.003359,    train_acc=0.999258,    eval_loss=4.805515,    eval_acc=0.565142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 97.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuray: 0.61024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4041it [00:26, 150.54it/s]\n",
      "449it [00:02, 152.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "epoch:   1,    lr=0.000200,    loss=1.134331,    train_acc=0.504795,    eval_loss=1.063269,    eval_acc=0.543951\n",
      "epoch:   2,    lr=0.000400,    loss=0.996155,    train_acc=0.591232,    eval_loss=1.031240,    eval_acc=0.554123\n",
      "epoch:   3,    lr=0.000600,    loss=0.946596,    train_acc=0.617700,    eval_loss=1.007301,    eval_acc=0.597329\n",
      "epoch:   4,    lr=0.000800,    loss=0.926464,    train_acc=0.628752,    eval_loss=1.048615,    eval_acc=0.584536\n",
      "epoch:   5,    lr=0.001000,    loss=0.909606,    train_acc=0.635380,    eval_loss=1.017928,    eval_acc=0.591266\n",
      "Test accuray: 0.5657\n",
      "epoch:   6,    lr=0.000978,    loss=0.895379,    train_acc=0.642174,    eval_loss=1.007189,    eval_acc=0.592859\n",
      "epoch:   7,    lr=0.000956,    loss=0.882240,    train_acc=0.648259,    eval_loss=0.974077,    eval_acc=0.604572\n",
      "epoch:   8,    lr=0.000933,    loss=0.867170,    train_acc=0.651986,    eval_loss=1.011275,    eval_acc=0.587413\n",
      "epoch:   9,    lr=0.000911,    loss=0.852197,    train_acc=0.659706,    eval_loss=1.061467,    eval_acc=0.567994\n",
      "epoch:  10,    lr=0.000889,    loss=0.837099,    train_acc=0.665284,    eval_loss=1.052066,    eval_acc=0.570254\n",
      "Test accuray: 0.60134\n",
      "epoch:  11,    lr=0.000867,    loss=0.819026,    train_acc=0.673060,    eval_loss=1.059901,    eval_acc=0.591164\n",
      "epoch:  12,    lr=0.000844,    loss=0.789850,    train_acc=0.683507,    eval_loss=1.067645,    eval_acc=0.603956\n",
      "epoch:  13,    lr=0.000822,    loss=0.752551,    train_acc=0.697762,    eval_loss=1.157489,    eval_acc=0.581094\n",
      "epoch:  14,    lr=0.000800,    loss=0.703514,    train_acc=0.718769,    eval_loss=1.251168,    eval_acc=0.580529\n",
      "epoch:  15,    lr=0.000778,    loss=0.639250,    train_acc=0.743749,    eval_loss=1.482254,    eval_acc=0.554637\n",
      "Test accuray: 0.60356\n",
      "epoch:  16,    lr=0.000756,    loss=0.567685,    train_acc=0.774363,    eval_loss=1.444173,    eval_acc=0.564552\n",
      "epoch:  17,    lr=0.000733,    loss=0.490409,    train_acc=0.805749,    eval_loss=1.744528,    eval_acc=0.554431\n",
      "epoch:  18,    lr=0.000711,    loss=0.421948,    train_acc=0.834364,    eval_loss=1.864440,    eval_acc=0.551297\n",
      "epoch:  19,    lr=0.000689,    loss=0.353697,    train_acc=0.861985,    eval_loss=2.118635,    eval_acc=0.547598\n",
      "epoch:  20,    lr=0.000667,    loss=0.296485,    train_acc=0.885503,    eval_loss=2.258777,    eval_acc=0.534806\n",
      "Test accuray: 0.5902\n",
      "epoch:  21,    lr=0.000644,    loss=0.246924,    train_acc=0.905904,    eval_loss=2.458648,    eval_acc=0.549294\n",
      "epoch:  22,    lr=0.000622,    loss=0.202046,    train_acc=0.923381,    eval_loss=2.852616,    eval_acc=0.529104\n",
      "epoch:  23,    lr=0.000600,    loss=0.173467,    train_acc=0.934927,    eval_loss=2.819292,    eval_acc=0.537067\n",
      "epoch:  24,    lr=0.000578,    loss=0.146702,    train_acc=0.944948,    eval_loss=3.035652,    eval_acc=0.537015\n",
      "epoch:  25,    lr=0.000556,    loss=0.124750,    train_acc=0.954501,    eval_loss=3.256266,    eval_acc=0.542307\n",
      "Test accuray: 0.59688\n",
      "epoch:  26,    lr=0.000533,    loss=0.104714,    train_acc=0.961684,    eval_loss=3.320112,    eval_acc=0.537426\n",
      "epoch:  27,    lr=0.000511,    loss=0.091738,    train_acc=0.967164,    eval_loss=3.594917,    eval_acc=0.537940\n",
      "epoch:  28,    lr=0.000489,    loss=0.081291,    train_acc=0.970385,    eval_loss=3.822365,    eval_acc=0.534395\n",
      "epoch:  29,    lr=0.000467,    loss=0.070919,    train_acc=0.974545,    eval_loss=3.774105,    eval_acc=0.536707\n",
      "epoch:  30,    lr=0.000444,    loss=0.062150,    train_acc=0.977784,    eval_loss=4.047144,    eval_acc=0.533368\n",
      "Test accuray: 0.5902\n",
      "epoch:  31,    lr=0.000422,    loss=0.053774,    train_acc=0.981086,    eval_loss=4.129672,    eval_acc=0.543231\n",
      "epoch:  32,    lr=0.000400,    loss=0.046554,    train_acc=0.983338,    eval_loss=4.210953,    eval_acc=0.538865\n",
      "epoch:  33,    lr=0.000378,    loss=0.040258,    train_acc=0.985628,    eval_loss=4.307345,    eval_acc=0.535114\n",
      "epoch:  34,    lr=0.000356,    loss=0.037091,    train_acc=0.987121,    eval_loss=4.588994,    eval_acc=0.542255\n",
      "epoch:  35,    lr=0.000333,    loss=0.035271,    train_acc=0.987948,    eval_loss=4.587708,    eval_acc=0.541125\n",
      "Test accuray: 0.59911\n",
      "epoch:  36,    lr=0.000311,    loss=0.029618,    train_acc=0.989880,    eval_loss=4.647336,    eval_acc=0.540406\n",
      "epoch:  37,    lr=0.000289,    loss=0.024533,    train_acc=0.991533,    eval_loss=4.838480,    eval_acc=0.540714\n",
      "epoch:  38,    lr=0.000267,    loss=0.023927,    train_acc=0.991953,    eval_loss=4.834470,    eval_acc=0.536912\n",
      "epoch:  39,    lr=0.000244,    loss=0.020246,    train_acc=0.993224,    eval_loss=4.867358,    eval_acc=0.541844\n",
      "epoch:  40,    lr=0.000222,    loss=0.017056,    train_acc=0.994317,    eval_loss=5.157032,    eval_acc=0.535525\n",
      "Test accuray: 0.59243\n",
      "epoch:  41,    lr=0.000200,    loss=0.014891,    train_acc=0.995125,    eval_loss=5.213437,    eval_acc=0.535782\n",
      "epoch:  42,    lr=0.000178,    loss=0.012469,    train_acc=0.995958,    eval_loss=5.200058,    eval_acc=0.539019\n",
      "epoch:  43,    lr=0.000156,    loss=0.011822,    train_acc=0.996168,    eval_loss=5.124404,    eval_acc=0.540560\n",
      "epoch:  44,    lr=0.000133,    loss=0.009716,    train_acc=0.996902,    eval_loss=5.425433,    eval_acc=0.540303\n",
      "epoch:  45,    lr=0.000111,    loss=0.007085,    train_acc=0.997951,    eval_loss=5.461900,    eval_acc=0.543797\n",
      "Test accuray: 0.57906\n",
      "epoch:  46,    lr=0.000089,    loss=0.005839,    train_acc=0.998396,    eval_loss=5.529992,    eval_acc=0.539481\n",
      "epoch:  47,    lr=0.000067,    loss=0.005407,    train_acc=0.998439,    eval_loss=5.528521,    eval_acc=0.539327\n",
      "epoch:  48,    lr=0.000044,    loss=0.004319,    train_acc=0.998846,    eval_loss=5.509455,    eval_acc=0.543026\n",
      "epoch:  49,    lr=0.000022,    loss=0.003355,    train_acc=0.999222,    eval_loss=5.495588,    eval_acc=0.542872\n",
      "epoch:  50,    lr=0.000000,    loss=0.002953,    train_acc=0.999297,    eval_loss=5.516471,    eval_acc=0.543488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [00:00, 121.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuray: 0.58797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4041it [00:26, 152.89it/s]\n",
      "449it [00:03, 133.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "epoch:   1,    lr=0.000200,    loss=1.122892,    train_acc=0.503592,    eval_loss=1.054889,    eval_acc=0.545941\n",
      "epoch:   2,    lr=0.000400,    loss=1.000687,    train_acc=0.591584,    eval_loss=1.028591,    eval_acc=0.559883\n",
      "epoch:   3,    lr=0.000600,    loss=0.967778,    train_acc=0.610264,    eval_loss=1.025362,    eval_acc=0.568731\n",
      "epoch:   4,    lr=0.000800,    loss=0.942446,    train_acc=0.622525,    eval_loss=1.068094,    eval_acc=0.563124\n",
      "epoch:   5,    lr=0.001000,    loss=0.919155,    train_acc=0.634121,    eval_loss=1.103954,    eval_acc=0.570789\n",
      "Test accuray: 0.52784\n",
      "epoch:   6,    lr=0.000978,    loss=0.897082,    train_acc=0.643957,    eval_loss=1.049303,    eval_acc=0.559317\n",
      "epoch:   7,    lr=0.000956,    loss=0.878778,    train_acc=0.651159,    eval_loss=1.242520,    eval_acc=0.538070\n",
      "epoch:   8,    lr=0.000933,    loss=0.863506,    train_acc=0.656324,    eval_loss=1.059775,    eval_acc=0.585040\n",
      "epoch:   9,    lr=0.000911,    loss=0.848030,    train_acc=0.663223,    eval_loss=1.037811,    eval_acc=0.590596\n",
      "epoch:  10,    lr=0.000889,    loss=0.832531,    train_acc=0.668925,    eval_loss=1.083954,    eval_acc=0.576808\n",
      "Test accuray: 0.59465\n",
      "epoch:  11,    lr=0.000867,    loss=0.811360,    train_acc=0.677768,    eval_loss=1.211808,    eval_acc=0.556642\n",
      "epoch:  12,    lr=0.000844,    loss=0.784946,    train_acc=0.687031,    eval_loss=1.139642,    eval_acc=0.580564\n",
      "epoch:  13,    lr=0.000822,    loss=0.753201,    train_acc=0.699632,    eval_loss=1.160560,    eval_acc=0.567239\n",
      "epoch:  14,    lr=0.000800,    loss=0.707529,    train_acc=0.719398,    eval_loss=1.183276,    eval_acc=0.573259\n",
      "epoch:  15,    lr=0.000778,    loss=0.648009,    train_acc=0.742990,    eval_loss=1.317976,    eval_acc=0.544809\n",
      "Test accuray: 0.61024\n",
      "epoch:  16,    lr=0.000756,    loss=0.582500,    train_acc=0.770426,    eval_loss=1.445963,    eval_acc=0.561683\n",
      "epoch:  17,    lr=0.000733,    loss=0.512848,    train_acc=0.798578,    eval_loss=1.730760,    eval_acc=0.541414\n",
      "epoch:  18,    lr=0.000711,    loss=0.446003,    train_acc=0.825144,    eval_loss=1.798488,    eval_acc=0.557876\n",
      "epoch:  19,    lr=0.000689,    loss=0.380974,    train_acc=0.851038,    eval_loss=1.954166,    eval_acc=0.541259\n",
      "epoch:  20,    lr=0.000667,    loss=0.325858,    train_acc=0.874019,    eval_loss=2.138730,    eval_acc=0.525414\n",
      "Test accuray: 0.60579\n",
      "epoch:  21,    lr=0.000644,    loss=0.276758,    train_acc=0.893383,    eval_loss=2.258972,    eval_acc=0.528552\n",
      "epoch:  22,    lr=0.000622,    loss=0.236300,    train_acc=0.909366,    eval_loss=2.543207,    eval_acc=0.535497\n",
      "epoch:  23,    lr=0.000600,    loss=0.199736,    train_acc=0.924109,    eval_loss=2.632437,    eval_acc=0.527215\n",
      "epoch:  24,    lr=0.000578,    loss=0.170112,    train_acc=0.935550,    eval_loss=2.892369,    eval_acc=0.529221\n",
      "epoch:  25,    lr=0.000556,    loss=0.142601,    train_acc=0.946485,    eval_loss=3.079584,    eval_acc=0.527369\n",
      "Test accuray: 0.60356\n",
      "epoch:  26,    lr=0.000533,    loss=0.123010,    train_acc=0.954705,    eval_loss=3.346986,    eval_acc=0.523974\n",
      "epoch:  27,    lr=0.000511,    loss=0.105366,    train_acc=0.961308,    eval_loss=3.378620,    eval_acc=0.527781\n",
      "epoch:  28,    lr=0.000489,    loss=0.090738,    train_acc=0.967164,    eval_loss=3.709728,    eval_acc=0.523048\n",
      "epoch:  29,    lr=0.000467,    loss=0.078712,    train_acc=0.972113,    eval_loss=3.826569,    eval_acc=0.518418\n",
      "epoch:  30,    lr=0.000444,    loss=0.068793,    train_acc=0.975779,    eval_loss=3.990367,    eval_acc=0.528964\n",
      "Test accuray: 0.5902\n",
      "epoch:  31,    lr=0.000422,    loss=0.063202,    train_acc=0.977858,    eval_loss=3.924314,    eval_acc=0.534108\n",
      "epoch:  32,    lr=0.000400,    loss=0.053212,    train_acc=0.981191,    eval_loss=4.255940,    eval_acc=0.525105\n",
      "epoch:  33,    lr=0.000378,    loss=0.049355,    train_acc=0.983240,    eval_loss=4.105067,    eval_acc=0.527266\n",
      "epoch:  34,    lr=0.000356,    loss=0.040744,    train_acc=0.986220,    eval_loss=4.307399,    eval_acc=0.529067\n",
      "epoch:  35,    lr=0.000333,    loss=0.035545,    train_acc=0.988238,    eval_loss=4.538340,    eval_acc=0.530096\n",
      "Test accuray: 0.60579\n",
      "epoch:  36,    lr=0.000311,    loss=0.029550,    train_acc=0.990077,    eval_loss=4.618293,    eval_acc=0.533440\n",
      "epoch:  37,    lr=0.000289,    loss=0.028071,    train_acc=0.990534,    eval_loss=4.735709,    eval_acc=0.534571\n",
      "epoch:  38,    lr=0.000267,    loss=0.023908,    train_acc=0.992348,    eval_loss=4.687661,    eval_acc=0.543472\n",
      "epoch:  39,    lr=0.000244,    loss=0.019606,    train_acc=0.993749,    eval_loss=4.848760,    eval_acc=0.539767\n",
      "epoch:  40,    lr=0.000222,    loss=0.019240,    train_acc=0.993780,    eval_loss=4.933667,    eval_acc=0.529478\n",
      "Test accuray: 0.61693\n",
      "epoch:  41,    lr=0.000200,    loss=0.016440,    train_acc=0.994742,    eval_loss=5.113806,    eval_acc=0.535755\n",
      "epoch:  42,    lr=0.000178,    loss=0.013387,    train_acc=0.995705,    eval_loss=5.144204,    eval_acc=0.534057\n",
      "epoch:  43,    lr=0.000156,    loss=0.011539,    train_acc=0.996501,    eval_loss=5.137085,    eval_acc=0.535806\n",
      "epoch:  44,    lr=0.000133,    loss=0.009634,    train_acc=0.997032,    eval_loss=5.356976,    eval_acc=0.536526\n",
      "epoch:  45,    lr=0.000111,    loss=0.008356,    train_acc=0.997507,    eval_loss=5.421445,    eval_acc=0.534211\n",
      "Test accuray: 0.60356\n",
      "epoch:  46,    lr=0.000089,    loss=0.007742,    train_acc=0.997815,    eval_loss=5.337639,    eval_acc=0.535086\n",
      "epoch:  47,    lr=0.000067,    loss=0.006052,    train_acc=0.998309,    eval_loss=5.456274,    eval_acc=0.537813\n",
      "epoch:  48,    lr=0.000044,    loss=0.004767,    train_acc=0.998686,    eval_loss=5.519028,    eval_acc=0.536526\n",
      "epoch:  49,    lr=0.000022,    loss=0.004004,    train_acc=0.998982,    eval_loss=5.578330,    eval_acc=0.531793\n",
      "epoch:  50,    lr=0.000000,    loss=0.003270,    train_acc=0.999303,    eval_loss=5.576741,    eval_acc=0.534520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [00:00, 175.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuray: 0.59688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4041it [00:26, 150.68it/s]\n",
      "449it [00:03, 139.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "epoch:   1,    lr=0.000200,    loss=1.144920,    train_acc=0.491032,    eval_loss=1.038871,    eval_acc=0.594206\n",
      "epoch:   2,    lr=0.000400,    loss=1.014668,    train_acc=0.578412,    eval_loss=0.944145,    eval_acc=0.663498\n",
      "epoch:   3,    lr=0.000600,    loss=0.959869,    train_acc=0.608073,    eval_loss=0.888004,    eval_acc=0.688440\n",
      "epoch:   4,    lr=0.000800,    loss=0.932449,    train_acc=0.621681,    eval_loss=0.846709,    eval_acc=0.702869\n",
      "epoch:   5,    lr=0.001000,    loss=0.912382,    train_acc=0.631254,    eval_loss=0.886670,    eval_acc=0.673676\n",
      "Test accuray: 0.6882\n",
      "epoch:   6,    lr=0.000978,    loss=0.892746,    train_acc=0.639714,    eval_loss=0.871824,    eval_acc=0.682121\n",
      "epoch:   7,    lr=0.000956,    loss=0.875067,    train_acc=0.647741,    eval_loss=0.919950,    eval_acc=0.651753\n",
      "epoch:   8,    lr=0.000933,    loss=0.862153,    train_acc=0.651842,    eval_loss=0.932563,    eval_acc=0.636821\n",
      "epoch:   9,    lr=0.000911,    loss=0.849390,    train_acc=0.656635,    eval_loss=0.889354,    eval_acc=0.668419\n",
      "epoch:  10,    lr=0.000889,    loss=0.835024,    train_acc=0.664007,    eval_loss=0.908935,    eval_acc=0.656171\n",
      "Test accuray: 0.69488\n",
      "epoch:  11,    lr=0.000867,    loss=0.819506,    train_acc=0.669057,    eval_loss=0.906433,    eval_acc=0.664616\n",
      "epoch:  12,    lr=0.000844,    loss=0.796538,    train_acc=0.678532,    eval_loss=0.968514,    eval_acc=0.637269\n",
      "epoch:  13,    lr=0.000822,    loss=0.763903,    train_acc=0.690306,    eval_loss=0.938060,    eval_acc=0.660366\n",
      "epoch:  14,    lr=0.000800,    loss=0.722387,    train_acc=0.706952,    eval_loss=1.013623,    eval_acc=0.643309\n",
      "epoch:  15,    lr=0.000778,    loss=0.667275,    train_acc=0.729399,    eval_loss=1.040774,    eval_acc=0.643364\n",
      "Test accuray: 0.69488\n",
      "epoch:  16,    lr=0.000756,    loss=0.601705,    train_acc=0.755734,    eval_loss=1.168423,    eval_acc=0.629663\n",
      "epoch:  17,    lr=0.000733,    loss=0.534156,    train_acc=0.783469,    eval_loss=1.260672,    eval_acc=0.605503\n",
      "epoch:  18,    lr=0.000711,    loss=0.468762,    train_acc=0.811632,    eval_loss=1.458478,    eval_acc=0.599239\n",
      "epoch:  19,    lr=0.000689,    loss=0.406872,    train_acc=0.838175,    eval_loss=1.623781,    eval_acc=0.605503\n",
      "epoch:  20,    lr=0.000667,    loss=0.351931,    train_acc=0.860384,    eval_loss=1.742498,    eval_acc=0.583189\n",
      "Test accuray: 0.6637\n",
      "epoch:  21,    lr=0.000644,    loss=0.302017,    train_acc=0.880814,    eval_loss=1.926068,    eval_acc=0.595157\n",
      "epoch:  22,    lr=0.000622,    loss=0.265001,    train_acc=0.895656,    eval_loss=1.983930,    eval_acc=0.604440\n",
      "epoch:  23,    lr=0.000600,    loss=0.223690,    train_acc=0.912455,    eval_loss=2.181541,    eval_acc=0.581735\n",
      "epoch:  24,    lr=0.000578,    loss=0.194333,    train_acc=0.924589,    eval_loss=2.310862,    eval_acc=0.596331\n",
      "epoch:  25,    lr=0.000556,    loss=0.166322,    train_acc=0.936730,    eval_loss=2.491095,    eval_acc=0.593759\n",
      "Test accuray: 0.68597\n",
      "epoch:  26,    lr=0.000533,    loss=0.141302,    train_acc=0.946969,    eval_loss=2.642813,    eval_acc=0.572787\n",
      "epoch:  27,    lr=0.000511,    loss=0.124182,    train_acc=0.953755,    eval_loss=2.832600,    eval_acc=0.581791\n",
      "epoch:  28,    lr=0.000489,    loss=0.104787,    train_acc=0.960938,    eval_loss=2.878826,    eval_acc=0.583021\n",
      "epoch:  29,    lr=0.000467,    loss=0.095576,    train_acc=0.965155,    eval_loss=3.132247,    eval_acc=0.588222\n",
      "epoch:  30,    lr=0.000444,    loss=0.076613,    train_acc=0.971898,    eval_loss=3.391780,    eval_acc=0.580504\n",
      "Test accuray: 0.67929\n",
      "epoch:  31,    lr=0.000422,    loss=0.070519,    train_acc=0.974722,    eval_loss=3.381475,    eval_acc=0.576086\n",
      "epoch:  32,    lr=0.000400,    loss=0.061703,    train_acc=0.978164,    eval_loss=3.440367,    eval_acc=0.586880\n",
      "epoch:  33,    lr=0.000378,    loss=0.054450,    train_acc=0.981013,    eval_loss=3.535984,    eval_acc=0.577373\n",
      "epoch:  34,    lr=0.000356,    loss=0.047434,    train_acc=0.983458,    eval_loss=3.712489,    eval_acc=0.574073\n",
      "epoch:  35,    lr=0.000333,    loss=0.041955,    train_acc=0.985695,    eval_loss=3.719511,    eval_acc=0.584195\n",
      "Test accuray: 0.67706\n",
      "epoch:  36,    lr=0.000311,    loss=0.035261,    train_acc=0.988018,    eval_loss=3.786251,    eval_acc=0.582518\n",
      "epoch:  37,    lr=0.000289,    loss=0.031675,    train_acc=0.989638,    eval_loss=3.961065,    eval_acc=0.583748\n",
      "epoch:  38,    lr=0.000267,    loss=0.026461,    train_acc=0.990885,    eval_loss=4.023777,    eval_acc=0.592305\n",
      "epoch:  39,    lr=0.000244,    loss=0.023532,    train_acc=0.992151,    eval_loss=4.116130,    eval_acc=0.596443\n",
      "epoch:  40,    lr=0.000222,    loss=0.020115,    train_acc=0.993410,    eval_loss=4.189883,    eval_acc=0.585650\n",
      "Test accuray: 0.67929\n",
      "epoch:  41,    lr=0.000200,    loss=0.016760,    train_acc=0.994828,    eval_loss=4.357636,    eval_acc=0.584755\n",
      "epoch:  42,    lr=0.000178,    loss=0.013817,    train_acc=0.995764,    eval_loss=4.402486,    eval_acc=0.590124\n",
      "epoch:  43,    lr=0.000156,    loss=0.012433,    train_acc=0.996222,    eval_loss=4.397593,    eval_acc=0.585594\n",
      "epoch:  44,    lr=0.000133,    loss=0.010697,    train_acc=0.996907,    eval_loss=4.448533,    eval_acc=0.588278\n",
      "epoch:  45,    lr=0.000111,    loss=0.009568,    train_acc=0.997194,    eval_loss=4.512600,    eval_acc=0.584699\n",
      "Test accuray: 0.67038\n",
      "epoch:  46,    lr=0.000089,    loss=0.007119,    train_acc=0.997958,    eval_loss=4.638918,    eval_acc=0.589788\n",
      "epoch:  47,    lr=0.000067,    loss=0.005420,    train_acc=0.998594,    eval_loss=4.724291,    eval_acc=0.586265\n",
      "epoch:  48,    lr=0.000044,    loss=0.004569,    train_acc=0.998851,    eval_loss=4.680606,    eval_acc=0.595213\n",
      "epoch:  49,    lr=0.000022,    loss=0.003992,    train_acc=0.998997,    eval_loss=4.754178,    eval_acc=0.593479\n",
      "epoch:  50,    lr=0.000000,    loss=0.003565,    train_acc=0.999138,    eval_loss=4.744122,    eval_acc=0.592808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17it [00:00, 167.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuray: 0.68374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4041it [00:27, 146.48it/s]\n",
      "449it [00:02, 150.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "epoch:   1,    lr=0.000200,    loss=1.137610,    train_acc=0.497965,    eval_loss=1.108246,    eval_acc=0.529388\n",
      "epoch:   2,    lr=0.000400,    loss=0.998736,    train_acc=0.587153,    eval_loss=1.098290,    eval_acc=0.537263\n",
      "epoch:   3,    lr=0.000600,    loss=0.956651,    train_acc=0.611471,    eval_loss=1.045356,    eval_acc=0.564653\n",
      "epoch:   4,    lr=0.000800,    loss=0.931836,    train_acc=0.623530,    eval_loss=1.067405,    eval_acc=0.563947\n",
      "epoch:   5,    lr=0.001000,    loss=0.914995,    train_acc=0.632011,    eval_loss=1.103991,    eval_acc=0.551252\n",
      "Test accuray: 0.61693\n",
      "epoch:   6,    lr=0.000978,    loss=0.895906,    train_acc=0.641348,    eval_loss=1.090756,    eval_acc=0.569296\n",
      "epoch:   7,    lr=0.000956,    loss=0.874147,    train_acc=0.652070,    eval_loss=1.072761,    eval_acc=0.562537\n",
      "epoch:   8,    lr=0.000933,    loss=0.860043,    train_acc=0.657908,    eval_loss=1.059622,    eval_acc=0.582344\n",
      "epoch:   9,    lr=0.000911,    loss=0.846032,    train_acc=0.663880,    eval_loss=1.099452,    eval_acc=0.558951\n",
      "epoch:  10,    lr=0.000889,    loss=0.831338,    train_acc=0.669724,    eval_loss=1.056237,    eval_acc=0.577701\n",
      "Test accuray: 0.61024\n",
      "epoch:  11,    lr=0.000867,    loss=0.813925,    train_acc=0.675307,    eval_loss=1.072469,    eval_acc=0.577877\n",
      "epoch:  12,    lr=0.000844,    loss=0.791180,    train_acc=0.684827,    eval_loss=1.098990,    eval_acc=0.565123\n",
      "epoch:  13,    lr=0.000822,    loss=0.755394,    train_acc=0.698131,    eval_loss=1.161775,    eval_acc=0.564182\n",
      "epoch:  14,    lr=0.000800,    loss=0.706068,    train_acc=0.717912,    eval_loss=1.161554,    eval_acc=0.562478\n",
      "epoch:  15,    lr=0.000778,    loss=0.641901,    train_acc=0.743409,    eval_loss=1.288400,    eval_acc=0.554955\n",
      "Test accuray: 0.61247\n",
      "epoch:  16,    lr=0.000756,    loss=0.563926,    train_acc=0.775849,    eval_loss=1.465981,    eval_acc=0.544375\n",
      "epoch:  17,    lr=0.000733,    loss=0.488302,    train_acc=0.807579,    eval_loss=1.612404,    eval_acc=0.524568\n",
      "epoch:  18,    lr=0.000711,    loss=0.411410,    train_acc=0.837651,    eval_loss=1.732636,    eval_acc=0.529152\n",
      "epoch:  19,    lr=0.000689,    loss=0.345966,    train_acc=0.865268,    eval_loss=1.920476,    eval_acc=0.530622\n",
      "epoch:  20,    lr=0.000667,    loss=0.292658,    train_acc=0.886524,    eval_loss=2.174056,    eval_acc=0.528036\n",
      "Test accuray: 0.60802\n",
      "epoch:  21,    lr=0.000644,    loss=0.243315,    train_acc=0.906268,    eval_loss=2.358404,    eval_acc=0.524979\n",
      "epoch:  22,    lr=0.000622,    loss=0.203586,    train_acc=0.922191,    eval_loss=2.591430,    eval_acc=0.523804\n",
      "epoch:  23,    lr=0.000600,    loss=0.170098,    train_acc=0.935775,    eval_loss=2.709246,    eval_acc=0.519984\n",
      "epoch:  24,    lr=0.000578,    loss=0.147574,    train_acc=0.944231,    eval_loss=2.997692,    eval_acc=0.515223\n",
      "epoch:  25,    lr=0.000556,    loss=0.124237,    train_acc=0.953720,    eval_loss=3.100104,    eval_acc=0.520042\n",
      "Test accuray: 0.60356\n",
      "epoch:  26,    lr=0.000533,    loss=0.103769,    train_acc=0.962450,    eval_loss=3.374180,    eval_acc=0.518984\n",
      "epoch:  27,    lr=0.000511,    loss=0.090456,    train_acc=0.967122,    eval_loss=3.526468,    eval_acc=0.530916\n",
      "epoch:  28,    lr=0.000489,    loss=0.080029,    train_acc=0.970919,    eval_loss=3.742155,    eval_acc=0.521277\n",
      "epoch:  29,    lr=0.000467,    loss=0.068704,    train_acc=0.975451,    eval_loss=3.927246,    eval_acc=0.517045\n",
      "epoch:  30,    lr=0.000444,    loss=0.062104,    train_acc=0.978282,    eval_loss=4.060917,    eval_acc=0.531268\n",
      "Test accuray: 0.60802\n",
      "epoch:  31,    lr=0.000422,    loss=0.052352,    train_acc=0.981824,    eval_loss=4.136580,    eval_acc=0.509639\n",
      "epoch:  32,    lr=0.000400,    loss=0.047853,    train_acc=0.983275,    eval_loss=4.218843,    eval_acc=0.523392\n",
      "epoch:  33,    lr=0.000378,    loss=0.044033,    train_acc=0.984539,    eval_loss=4.346541,    eval_acc=0.523921\n",
      "epoch:  34,    lr=0.000356,    loss=0.035505,    train_acc=0.987765,    eval_loss=4.432868,    eval_acc=0.529152\n",
      "epoch:  35,    lr=0.000333,    loss=0.032803,    train_acc=0.988707,    eval_loss=4.712951,    eval_acc=0.518573\n",
      "Test accuray: 0.61247\n",
      "epoch:  36,    lr=0.000311,    loss=0.026584,    train_acc=0.991045,    eval_loss=4.546662,    eval_acc=0.521629\n",
      "epoch:  37,    lr=0.000289,    loss=0.023520,    train_acc=0.992358,    eval_loss=4.786880,    eval_acc=0.520748\n",
      "epoch:  38,    lr=0.000267,    loss=0.024146,    train_acc=0.991926,    eval_loss=4.809291,    eval_acc=0.523510\n",
      "epoch:  39,    lr=0.000244,    loss=0.018996,    train_acc=0.993755,    eval_loss=4.983460,    eval_acc=0.527742\n",
      "epoch:  40,    lr=0.000222,    loss=0.014909,    train_acc=0.995195,    eval_loss=4.997972,    eval_acc=0.522452\n",
      "Test accuray: 0.59911\n",
      "epoch:  41,    lr=0.000200,    loss=0.014262,    train_acc=0.995286,    eval_loss=5.171876,    eval_acc=0.520219\n",
      "epoch:  42,    lr=0.000178,    loss=0.011627,    train_acc=0.996428,    eval_loss=5.268632,    eval_acc=0.525920\n",
      "epoch:  43,    lr=0.000156,    loss=0.011344,    train_acc=0.996410,    eval_loss=5.274794,    eval_acc=0.524686\n",
      "epoch:  44,    lr=0.000133,    loss=0.008856,    train_acc=0.997357,    eval_loss=5.493480,    eval_acc=0.526449\n",
      "epoch:  45,    lr=0.000111,    loss=0.008174,    train_acc=0.997388,    eval_loss=5.436676,    eval_acc=0.527037\n",
      "Test accuray: 0.60579\n",
      "epoch:  46,    lr=0.000089,    loss=0.005349,    train_acc=0.998572,    eval_loss=5.612425,    eval_acc=0.529917\n",
      "epoch:  47,    lr=0.000067,    loss=0.004700,    train_acc=0.998785,    eval_loss=5.691927,    eval_acc=0.528682\n",
      "epoch:  48,    lr=0.000044,    loss=0.004226,    train_acc=0.998967,    eval_loss=5.729197,    eval_acc=0.527037\n",
      "epoch:  49,    lr=0.000022,    loss=0.003798,    train_acc=0.999077,    eval_loss=5.772602,    eval_acc=0.528095\n",
      "epoch:  50,    lr=0.000000,    loss=0.002616,    train_acc=0.999399,    eval_loss=5.809468,    eval_acc=0.526331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [00:00, 172.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuray: 0.60802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4041it [00:26, 154.00it/s]\n",
      "449it [00:02, 171.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "epoch:   1,    lr=0.000200,    loss=1.128229,    train_acc=0.502992,    eval_loss=1.040221,    eval_acc=0.560176\n",
      "epoch:   2,    lr=0.000400,    loss=0.980787,    train_acc=0.599369,    eval_loss=1.002814,    eval_acc=0.590365\n",
      "epoch:   3,    lr=0.000600,    loss=0.942731,    train_acc=0.619205,    eval_loss=1.111848,    eval_acc=0.541674\n",
      "epoch:   4,    lr=0.000800,    loss=0.921155,    train_acc=0.628352,    eval_loss=1.105911,    eval_acc=0.553016\n",
      "epoch:   5,    lr=0.001000,    loss=0.905803,    train_acc=0.636810,    eval_loss=1.117677,    eval_acc=0.558744\n",
      "Test accuray: 0.53229\n",
      "epoch:   6,    lr=0.000978,    loss=0.892758,    train_acc=0.643501,    eval_loss=1.007829,    eval_acc=0.575242\n",
      "epoch:   7,    lr=0.000956,    loss=0.879278,    train_acc=0.648986,    eval_loss=1.007086,    eval_acc=0.590422\n",
      "epoch:   8,    lr=0.000933,    loss=0.868656,    train_acc=0.653837,    eval_loss=1.037538,    eval_acc=0.582975\n",
      "epoch:   9,    lr=0.000911,    loss=0.857542,    train_acc=0.658639,    eval_loss=1.031530,    eval_acc=0.584350\n",
      "epoch:  10,    lr=0.000889,    loss=0.846312,    train_acc=0.662240,    eval_loss=1.078023,    eval_acc=0.569055\n",
      "Test accuray: 0.54788\n",
      "epoch:  11,    lr=0.000867,    loss=0.830232,    train_acc=0.669163,    eval_loss=1.052741,    eval_acc=0.572836\n",
      "epoch:  12,    lr=0.000844,    loss=0.807476,    train_acc=0.677140,    eval_loss=1.064175,    eval_acc=0.586298\n",
      "epoch:  13,    lr=0.000822,    loss=0.773255,    train_acc=0.688707,    eval_loss=1.086624,    eval_acc=0.580340\n",
      "epoch:  14,    lr=0.000800,    loss=0.721762,    train_acc=0.710846,    eval_loss=1.171748,    eval_acc=0.567222\n",
      "epoch:  15,    lr=0.000778,    loss=0.658793,    train_acc=0.735758,    eval_loss=1.274574,    eval_acc=0.555536\n",
      "Test accuray: 0.58575\n",
      "epoch:  16,    lr=0.000756,    loss=0.583016,    train_acc=0.766813,    eval_loss=1.350328,    eval_acc=0.556510\n",
      "epoch:  17,    lr=0.000733,    loss=0.505076,    train_acc=0.798862,    eval_loss=1.460855,    eval_acc=0.565160\n",
      "epoch:  18,    lr=0.000711,    loss=0.425277,    train_acc=0.831288,    eval_loss=1.724485,    eval_acc=0.551584\n",
      "epoch:  19,    lr=0.000689,    loss=0.361899,    train_acc=0.856852,    eval_loss=1.866176,    eval_acc=0.542934\n",
      "epoch:  20,    lr=0.000667,    loss=0.306181,    train_acc=0.879406,    eval_loss=2.052762,    eval_acc=0.538409\n",
      "Test accuray: 0.58129\n",
      "epoch:  21,    lr=0.000644,    loss=0.254913,    train_acc=0.900382,    eval_loss=2.266580,    eval_acc=0.534456\n",
      "epoch:  22,    lr=0.000622,    loss=0.217922,    train_acc=0.916573,    eval_loss=2.453153,    eval_acc=0.549063\n",
      "epoch:  23,    lr=0.000600,    loss=0.182351,    train_acc=0.929529,    eval_loss=2.678492,    eval_acc=0.532909\n",
      "epoch:  24,    lr=0.000578,    loss=0.158679,    train_acc=0.939694,    eval_loss=2.720302,    eval_acc=0.543679\n",
      "epoch:  25,    lr=0.000556,    loss=0.134199,    train_acc=0.949578,    eval_loss=3.194794,    eval_acc=0.529129\n",
      "Test accuray: 0.58129\n",
      "epoch:  26,    lr=0.000533,    loss=0.115740,    train_acc=0.956769,    eval_loss=3.206123,    eval_acc=0.524546\n",
      "epoch:  27,    lr=0.000511,    loss=0.098237,    train_acc=0.963893,    eval_loss=3.242963,    eval_acc=0.538065\n",
      "epoch:  28,    lr=0.000489,    loss=0.083896,    train_acc=0.969847,    eval_loss=3.644826,    eval_acc=0.540013\n",
      "epoch:  29,    lr=0.000467,    loss=0.076003,    train_acc=0.972480,    eval_loss=3.686256,    eval_acc=0.528155\n",
      "epoch:  30,    lr=0.000444,    loss=0.067148,    train_acc=0.975862,    eval_loss=3.984369,    eval_acc=0.532279\n",
      "Test accuray: 0.57906\n",
      "epoch:  31,    lr=0.000422,    loss=0.057404,    train_acc=0.979731,    eval_loss=3.968446,    eval_acc=0.540356\n",
      "epoch:  32,    lr=0.000400,    loss=0.050826,    train_acc=0.982321,    eval_loss=4.161819,    eval_acc=0.527525\n",
      "epoch:  33,    lr=0.000378,    loss=0.044406,    train_acc=0.984814,    eval_loss=4.320522,    eval_acc=0.538810\n",
      "epoch:  34,    lr=0.000356,    loss=0.036267,    train_acc=0.987641,    eval_loss=4.481558,    eval_acc=0.538351\n",
      "epoch:  35,    lr=0.000333,    loss=0.035648,    train_acc=0.987727,    eval_loss=4.445705,    eval_acc=0.535544\n",
      "Test accuray: 0.58129\n",
      "epoch:  36,    lr=0.000311,    loss=0.029732,    train_acc=0.989988,    eval_loss=4.649396,    eval_acc=0.527467\n",
      "epoch:  37,    lr=0.000289,    loss=0.026754,    train_acc=0.991340,    eval_loss=4.793926,    eval_acc=0.533196\n",
      "epoch:  38,    lr=0.000267,    loss=0.021923,    train_acc=0.992870,    eval_loss=5.007170,    eval_acc=0.527181\n",
      "epoch:  39,    lr=0.000244,    loss=0.020405,    train_acc=0.993437,    eval_loss=4.880344,    eval_acc=0.531248\n",
      "epoch:  40,    lr=0.000222,    loss=0.017480,    train_acc=0.994339,    eval_loss=5.154472,    eval_acc=0.534399\n",
      "Test accuray: 0.5902\n",
      "epoch:  41,    lr=0.000200,    loss=0.014424,    train_acc=0.995454,    eval_loss=5.207837,    eval_acc=0.535945\n",
      "epoch:  42,    lr=0.000178,    loss=0.012942,    train_acc=0.995996,    eval_loss=5.201011,    eval_acc=0.530274\n",
      "epoch:  43,    lr=0.000156,    loss=0.010028,    train_acc=0.996874,    eval_loss=5.323604,    eval_acc=0.531936\n",
      "epoch:  44,    lr=0.000133,    loss=0.009054,    train_acc=0.997325,    eval_loss=5.375872,    eval_acc=0.535888\n",
      "epoch:  45,    lr=0.000111,    loss=0.007803,    train_acc=0.997648,    eval_loss=5.482668,    eval_acc=0.528728\n",
      "Test accuray: 0.5902\n",
      "epoch:  46,    lr=0.000089,    loss=0.005690,    train_acc=0.998391,    eval_loss=5.664146,    eval_acc=0.536346\n",
      "epoch:  47,    lr=0.000067,    loss=0.004830,    train_acc=0.998739,    eval_loss=5.640508,    eval_acc=0.540184\n",
      "epoch:  48,    lr=0.000044,    loss=0.004048,    train_acc=0.998952,    eval_loss=5.740116,    eval_acc=0.539039\n",
      "epoch:  49,    lr=0.000022,    loss=0.003626,    train_acc=0.999141,    eval_loss=5.622464,    eval_acc=0.539211\n",
      "epoch:  50,    lr=0.000000,    loss=0.003028,    train_acc=0.999330,    eval_loss=5.651979,    eval_acc=0.538981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17it [00:00, 161.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuray: 0.59911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4041it [00:25, 156.22it/s]\n",
      "449it [00:02, 159.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "epoch:   1,    lr=0.000200,    loss=1.162923,    train_acc=0.484762,    eval_loss=1.146793,    eval_acc=0.521399\n",
      "epoch:   2,    lr=0.000400,    loss=1.002536,    train_acc=0.583683,    eval_loss=1.127047,    eval_acc=0.558190\n",
      "epoch:   3,    lr=0.000600,    loss=0.925923,    train_acc=0.628611,    eval_loss=1.158791,    eval_acc=0.509118\n",
      "epoch:   4,    lr=0.000800,    loss=0.896138,    train_acc=0.641012,    eval_loss=1.096435,    eval_acc=0.559466\n",
      "epoch:   5,    lr=0.001000,    loss=0.879179,    train_acc=0.648548,    eval_loss=1.071605,    eval_acc=0.565368\n",
      "Test accuray: 0.59465\n",
      "epoch:   6,    lr=0.000978,    loss=0.862817,    train_acc=0.653314,    eval_loss=1.294675,    eval_acc=0.465788\n",
      "epoch:   7,    lr=0.000956,    loss=0.842159,    train_acc=0.662699,    eval_loss=1.231891,    eval_acc=0.541709\n",
      "epoch:   8,    lr=0.000933,    loss=0.828345,    train_acc=0.667662,    eval_loss=1.169254,    eval_acc=0.543729\n",
      "epoch:   9,    lr=0.000911,    loss=0.812619,    train_acc=0.674792,    eval_loss=1.125507,    eval_acc=0.562231\n",
      "epoch:  10,    lr=0.000889,    loss=0.795617,    train_acc=0.680425,    eval_loss=1.229188,    eval_acc=0.511564\n",
      "Test accuray: 0.5657\n",
      "epoch:  11,    lr=0.000867,    loss=0.770906,    train_acc=0.690964,    eval_loss=1.200308,    eval_acc=0.528311\n",
      "epoch:  12,    lr=0.000844,    loss=0.740784,    train_acc=0.703770,    eval_loss=1.303439,    eval_acc=0.525068\n",
      "epoch:  13,    lr=0.000822,    loss=0.695682,    train_acc=0.721477,    eval_loss=1.318721,    eval_acc=0.526078\n",
      "epoch:  14,    lr=0.000800,    loss=0.636946,    train_acc=0.743293,    eval_loss=1.561396,    eval_acc=0.490669\n",
      "epoch:  15,    lr=0.000778,    loss=0.567230,    train_acc=0.774125,    eval_loss=1.560606,    eval_acc=0.538093\n",
      "Test accuray: 0.59243\n",
      "epoch:  16,    lr=0.000756,    loss=0.494251,    train_acc=0.802704,    eval_loss=1.898377,    eval_acc=0.471476\n",
      "epoch:  17,    lr=0.000733,    loss=0.419053,    train_acc=0.835145,    eval_loss=1.873676,    eval_acc=0.502579\n",
      "epoch:  18,    lr=0.000711,    loss=0.354127,    train_acc=0.861285,    eval_loss=2.203365,    eval_acc=0.487852\n",
      "epoch:  19,    lr=0.000689,    loss=0.298141,    train_acc=0.883918,    eval_loss=2.375127,    eval_acc=0.483545\n",
      "epoch:  20,    lr=0.000667,    loss=0.246064,    train_acc=0.905660,    eval_loss=2.622566,    eval_acc=0.469084\n",
      "Test accuray: 0.5657\n",
      "epoch:  21,    lr=0.000644,    loss=0.208095,    train_acc=0.920597,    eval_loss=2.826168,    eval_acc=0.498910\n",
      "epoch:  22,    lr=0.000622,    loss=0.174228,    train_acc=0.933698,    eval_loss=2.986015,    eval_acc=0.495135\n",
      "epoch:  23,    lr=0.000600,    loss=0.147305,    train_acc=0.945325,    eval_loss=2.954014,    eval_acc=0.483970\n",
      "epoch:  24,    lr=0.000578,    loss=0.128941,    train_acc=0.952038,    eval_loss=3.216240,    eval_acc=0.479292\n",
      "epoch:  25,    lr=0.000556,    loss=0.110386,    train_acc=0.959328,    eval_loss=3.334461,    eval_acc=0.496943\n",
      "Test accuray: 0.59465\n",
      "epoch:  26,    lr=0.000533,    loss=0.091893,    train_acc=0.966275,    eval_loss=3.532235,    eval_acc=0.488490\n",
      "epoch:  27,    lr=0.000511,    loss=0.080460,    train_acc=0.970734,    eval_loss=3.757958,    eval_acc=0.488330\n",
      "epoch:  28,    lr=0.000489,    loss=0.072865,    train_acc=0.974075,    eval_loss=3.938335,    eval_acc=0.494763\n",
      "epoch:  29,    lr=0.000467,    loss=0.063582,    train_acc=0.977545,    eval_loss=4.030635,    eval_acc=0.486735\n",
      "epoch:  30,    lr=0.000444,    loss=0.054541,    train_acc=0.980764,    eval_loss=4.064731,    eval_acc=0.492052\n",
      "Test accuray: 0.58352\n",
      "epoch:  31,    lr=0.000422,    loss=0.049124,    train_acc=0.982975,    eval_loss=4.348486,    eval_acc=0.495401\n",
      "epoch:  32,    lr=0.000400,    loss=0.044120,    train_acc=0.984418,    eval_loss=4.415212,    eval_acc=0.502685\n",
      "epoch:  33,    lr=0.000378,    loss=0.039249,    train_acc=0.986340,    eval_loss=4.456050,    eval_acc=0.502685\n",
      "epoch:  34,    lr=0.000356,    loss=0.034756,    train_acc=0.988042,    eval_loss=4.770016,    eval_acc=0.498644\n",
      "epoch:  35,    lr=0.000333,    loss=0.029956,    train_acc=0.989737,    eval_loss=4.744481,    eval_acc=0.504599\n",
      "Test accuray: 0.5657\n",
      "epoch:  36,    lr=0.000311,    loss=0.025582,    train_acc=0.991450,    eval_loss=4.914252,    eval_acc=0.491998\n",
      "epoch:  37,    lr=0.000289,    loss=0.022569,    train_acc=0.992513,    eval_loss=5.166309,    eval_acc=0.484715\n",
      "epoch:  38,    lr=0.000267,    loss=0.020904,    train_acc=0.992986,    eval_loss=5.220395,    eval_acc=0.485619\n",
      "epoch:  39,    lr=0.000244,    loss=0.017958,    train_acc=0.994018,    eval_loss=5.199823,    eval_acc=0.501887\n",
      "epoch:  40,    lr=0.000222,    loss=0.014707,    train_acc=0.995240,    eval_loss=5.395093,    eval_acc=0.489606\n",
      "Test accuray: 0.57461\n",
      "epoch:  41,    lr=0.000200,    loss=0.014233,    train_acc=0.995265,    eval_loss=5.395459,    eval_acc=0.495507\n",
      "epoch:  42,    lr=0.000178,    loss=0.010723,    train_acc=0.996493,    eval_loss=5.449131,    eval_acc=0.492849\n",
      "epoch:  43,    lr=0.000156,    loss=0.008952,    train_acc=0.997255,    eval_loss=5.670450,    eval_acc=0.504493\n",
      "epoch:  44,    lr=0.000133,    loss=0.007880,    train_acc=0.997617,    eval_loss=5.523621,    eval_acc=0.495720\n",
      "epoch:  45,    lr=0.000111,    loss=0.006362,    train_acc=0.998305,    eval_loss=5.891938,    eval_acc=0.493806\n",
      "Test accuray: 0.56793\n",
      "epoch:  46,    lr=0.000089,    loss=0.005558,    train_acc=0.998446,    eval_loss=5.737709,    eval_acc=0.509650\n",
      "epoch:  47,    lr=0.000067,    loss=0.004631,    train_acc=0.998630,    eval_loss=5.833349,    eval_acc=0.499814\n",
      "epoch:  48,    lr=0.000044,    loss=0.003735,    train_acc=0.998980,    eval_loss=6.031548,    eval_acc=0.497049\n",
      "epoch:  49,    lr=0.000022,    loss=0.002908,    train_acc=0.999208,    eval_loss=5.952449,    eval_acc=0.499016\n",
      "epoch:  50,    lr=0.000000,    loss=0.002476,    train_acc=0.999398,    eval_loss=5.934552,    eval_acc=0.498697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [00:00, 175.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuray: 0.57906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4041it [00:25, 159.59it/s]\n",
      "449it [00:02, 164.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "epoch:   1,    lr=0.000200,    loss=1.139794,    train_acc=0.492432,    eval_loss=1.157606,    eval_acc=0.474192\n",
      "epoch:   2,    lr=0.000400,    loss=0.997298,    train_acc=0.588071,    eval_loss=1.117960,    eval_acc=0.526088\n",
      "epoch:   3,    lr=0.000600,    loss=0.946873,    train_acc=0.614082,    eval_loss=1.132647,    eval_acc=0.518627\n",
      "epoch:   4,    lr=0.000800,    loss=0.919900,    train_acc=0.626565,    eval_loss=1.148605,    eval_acc=0.538095\n",
      "epoch:   5,    lr=0.001000,    loss=0.902107,    train_acc=0.635209,    eval_loss=1.183619,    eval_acc=0.519917\n",
      "Test accuray: 0.55679\n",
      "epoch:   6,    lr=0.000978,    loss=0.885648,    train_acc=0.641817,    eval_loss=1.236310,    eval_acc=0.528333\n",
      "epoch:   7,    lr=0.000956,    loss=0.870018,    train_acc=0.649098,    eval_loss=1.110236,    eval_acc=0.548193\n",
      "epoch:   8,    lr=0.000933,    loss=0.855397,    train_acc=0.656427,    eval_loss=1.119264,    eval_acc=0.562724\n",
      "epoch:   9,    lr=0.000911,    loss=0.841798,    train_acc=0.662406,    eval_loss=1.119232,    eval_acc=0.561097\n",
      "epoch:  10,    lr=0.000889,    loss=0.826230,    train_acc=0.668892,    eval_loss=1.188719,    eval_acc=0.544210\n",
      "Test accuray: 0.57238\n",
      "epoch:  11,    lr=0.000867,    loss=0.804170,    train_acc=0.677041,    eval_loss=1.233021,    eval_acc=0.546791\n",
      "epoch:  12,    lr=0.000844,    loss=0.775784,    train_acc=0.687109,    eval_loss=1.231506,    eval_acc=0.557058\n",
      "epoch:  13,    lr=0.000822,    loss=0.733024,    train_acc=0.704433,    eval_loss=1.251184,    eval_acc=0.551504\n",
      "epoch:  14,    lr=0.000800,    loss=0.677090,    train_acc=0.726593,    eval_loss=1.462014,    eval_acc=0.527098\n",
      "epoch:  15,    lr=0.000778,    loss=0.612576,    train_acc=0.753167,    eval_loss=1.533189,    eval_acc=0.526425\n",
      "Test accuray: 0.57906\n",
      "epoch:  16,    lr=0.000756,    loss=0.541850,    train_acc=0.782393,    eval_loss=1.682892,    eval_acc=0.529904\n",
      "epoch:  17,    lr=0.000733,    loss=0.474851,    train_acc=0.810055,    eval_loss=1.936072,    eval_acc=0.515092\n",
      "epoch:  18,    lr=0.000711,    loss=0.413194,    train_acc=0.836372,    eval_loss=2.188660,    eval_acc=0.508864\n",
      "epoch:  19,    lr=0.000689,    loss=0.355302,    train_acc=0.859962,    eval_loss=2.498549,    eval_acc=0.499663\n",
      "epoch:  20,    lr=0.000667,    loss=0.311059,    train_acc=0.877604,    eval_loss=2.477636,    eval_acc=0.502637\n",
      "Test accuray: 0.60134\n",
      "epoch:  21,    lr=0.000644,    loss=0.271538,    train_acc=0.893999,    eval_loss=2.842521,    eval_acc=0.507742\n",
      "epoch:  22,    lr=0.000622,    loss=0.232989,    train_acc=0.909435,    eval_loss=3.120247,    eval_acc=0.495848\n",
      "epoch:  23,    lr=0.000600,    loss=0.206499,    train_acc=0.920597,    eval_loss=3.167040,    eval_acc=0.481093\n",
      "epoch:  24,    lr=0.000578,    loss=0.173506,    train_acc=0.933306,    eval_loss=3.390394,    eval_acc=0.478007\n",
      "epoch:  25,    lr=0.000556,    loss=0.153949,    train_acc=0.941425,    eval_loss=3.665736,    eval_acc=0.492987\n",
      "Test accuray: 0.59465\n",
      "epoch:  26,    lr=0.000533,    loss=0.131692,    train_acc=0.950068,    eval_loss=3.680121,    eval_acc=0.490294\n",
      "epoch:  27,    lr=0.000511,    loss=0.118280,    train_acc=0.955393,    eval_loss=3.992579,    eval_acc=0.494951\n",
      "epoch:  28,    lr=0.000489,    loss=0.103504,    train_acc=0.962148,    eval_loss=4.086925,    eval_acc=0.498036\n",
      "epoch:  29,    lr=0.000467,    loss=0.085925,    train_acc=0.968004,    eval_loss=4.387236,    eval_acc=0.490855\n",
      "epoch:  30,    lr=0.000444,    loss=0.080862,    train_acc=0.970492,    eval_loss=4.382511,    eval_acc=0.492594\n",
      "Test accuray: 0.57684\n",
      "epoch:  31,    lr=0.000422,    loss=0.069382,    train_acc=0.975077,    eval_loss=4.537295,    eval_acc=0.491416\n",
      "epoch:  32,    lr=0.000400,    loss=0.061184,    train_acc=0.978097,    eval_loss=4.763203,    eval_acc=0.491921\n",
      "epoch:  33,    lr=0.000378,    loss=0.053403,    train_acc=0.981343,    eval_loss=4.862434,    eval_acc=0.495512\n",
      "epoch:  34,    lr=0.000356,    loss=0.043873,    train_acc=0.985011,    eval_loss=5.053376,    eval_acc=0.494165\n",
      "epoch:  35,    lr=0.000333,    loss=0.040068,    train_acc=0.986129,    eval_loss=4.909621,    eval_acc=0.504601\n",
      "Test accuray: 0.59688\n",
      "epoch:  36,    lr=0.000311,    loss=0.038440,    train_acc=0.986967,    eval_loss=5.153357,    eval_acc=0.488611\n",
      "epoch:  37,    lr=0.000289,    loss=0.030848,    train_acc=0.989638,    eval_loss=5.180157,    eval_acc=0.490126\n",
      "epoch:  38,    lr=0.000267,    loss=0.027123,    train_acc=0.990910,    eval_loss=5.331803,    eval_acc=0.503647\n",
      "epoch:  39,    lr=0.000244,    loss=0.024082,    train_acc=0.991961,    eval_loss=5.736695,    eval_acc=0.492650\n",
      "epoch:  40,    lr=0.000222,    loss=0.019740,    train_acc=0.993661,    eval_loss=5.781184,    eval_acc=0.495007\n",
      "Test accuray: 0.59465\n",
      "epoch:  41,    lr=0.000200,    loss=0.019613,    train_acc=0.993636,    eval_loss=5.805263,    eval_acc=0.501795\n",
      "epoch:  42,    lr=0.000178,    loss=0.016144,    train_acc=0.994877,    eval_loss=6.048453,    eval_acc=0.495736\n",
      "epoch:  43,    lr=0.000156,    loss=0.012217,    train_acc=0.996271,    eval_loss=6.179119,    eval_acc=0.500449\n",
      "epoch:  44,    lr=0.000133,    loss=0.011397,    train_acc=0.996687,    eval_loss=6.129762,    eval_acc=0.495343\n",
      "epoch:  45,    lr=0.000111,    loss=0.009051,    train_acc=0.997396,    eval_loss=6.413185,    eval_acc=0.494053\n",
      "Test accuray: 0.59243\n",
      "epoch:  46,    lr=0.000089,    loss=0.008024,    train_acc=0.997738,    eval_loss=6.220050,    eval_acc=0.500729\n",
      "epoch:  47,    lr=0.000067,    loss=0.006430,    train_acc=0.998270,    eval_loss=6.473756,    eval_acc=0.495343\n",
      "epoch:  48,    lr=0.000044,    loss=0.005302,    train_acc=0.998570,    eval_loss=6.524238,    eval_acc=0.497307\n",
      "epoch:  49,    lr=0.000022,    loss=0.004299,    train_acc=0.998863,    eval_loss=6.537619,    eval_acc=0.497588\n",
      "epoch:  50,    lr=0.000000,    loss=0.003707,    train_acc=0.999132,    eval_loss=6.564004,    eval_acc=0.496129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17it [00:00, 166.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuray: 0.60802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4041it [00:26, 153.26it/s]\n",
      "449it [00:02, 163.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "epoch:   1,    lr=0.000200,    loss=1.159949,    train_acc=0.483385,    eval_loss=1.060162,    eval_acc=0.543996\n",
      "epoch:   2,    lr=0.000400,    loss=1.010360,    train_acc=0.583969,    eval_loss=1.011778,    eval_acc=0.582567\n",
      "epoch:   3,    lr=0.000600,    loss=0.951393,    train_acc=0.617880,    eval_loss=0.995473,    eval_acc=0.598549\n",
      "epoch:   4,    lr=0.000800,    loss=0.917101,    train_acc=0.633560,    eval_loss=0.977945,    eval_acc=0.603385\n",
      "epoch:   5,    lr=0.001000,    loss=0.899108,    train_acc=0.640546,    eval_loss=0.957891,    eval_acc=0.615004\n",
      "Test accuray: 0.6392\n",
      "epoch:   6,    lr=0.000978,    loss=0.881572,    train_acc=0.646621,    eval_loss=1.005725,    eval_acc=0.597547\n",
      "epoch:   7,    lr=0.000956,    loss=0.868383,    train_acc=0.653073,    eval_loss=1.017196,    eval_acc=0.578379\n",
      "epoch:   8,    lr=0.000933,    loss=0.855703,    train_acc=0.656669,    eval_loss=1.028497,    eval_acc=0.577554\n",
      "epoch:   9,    lr=0.000911,    loss=0.841422,    train_acc=0.663400,    eval_loss=1.043890,    eval_acc=0.576256\n",
      "epoch:  10,    lr=0.000889,    loss=0.827430,    train_acc=0.667422,    eval_loss=1.087652,    eval_acc=0.578320\n",
      "Test accuray: 0.61024\n",
      "epoch:  11,    lr=0.000867,    loss=0.808508,    train_acc=0.674250,    eval_loss=1.146654,    eval_acc=0.566171\n",
      "epoch:  12,    lr=0.000844,    loss=0.781394,    train_acc=0.685477,    eval_loss=1.094998,    eval_acc=0.573956\n",
      "epoch:  13,    lr=0.000822,    loss=0.744614,    train_acc=0.699820,    eval_loss=1.134827,    eval_acc=0.572305\n",
      "epoch:  14,    lr=0.000800,    loss=0.696309,    train_acc=0.718568,    eval_loss=1.221663,    eval_acc=0.551486\n",
      "epoch:  15,    lr=0.000778,    loss=0.631176,    train_acc=0.746288,    eval_loss=1.358495,    eval_acc=0.542227\n",
      "Test accuray: 0.63029\n",
      "epoch:  16,    lr=0.000756,    loss=0.559743,    train_acc=0.776590,    eval_loss=1.475677,    eval_acc=0.541519\n",
      "epoch:  17,    lr=0.000733,    loss=0.489764,    train_acc=0.804044,    eval_loss=1.629627,    eval_acc=0.529252\n",
      "epoch:  18,    lr=0.000711,    loss=0.421294,    train_acc=0.832153,    eval_loss=1.811502,    eval_acc=0.534914\n",
      "epoch:  19,    lr=0.000689,    loss=0.356377,    train_acc=0.859539,    eval_loss=2.087978,    eval_acc=0.516100\n",
      "epoch:  20,    lr=0.000667,    loss=0.303105,    train_acc=0.881051,    eval_loss=2.215703,    eval_acc=0.514449\n",
      "Test accuray: 0.61915\n",
      "epoch:  21,    lr=0.000644,    loss=0.257449,    train_acc=0.899707,    eval_loss=2.451743,    eval_acc=0.518165\n",
      "epoch:  22,    lr=0.000622,    loss=0.211736,    train_acc=0.918309,    eval_loss=2.721328,    eval_acc=0.496343\n",
      "epoch:  23,    lr=0.000600,    loss=0.180156,    train_acc=0.931559,    eval_loss=2.775548,    eval_acc=0.520524\n",
      "epoch:  24,    lr=0.000578,    loss=0.153090,    train_acc=0.942482,    eval_loss=3.064134,    eval_acc=0.509908\n",
      "epoch:  25,    lr=0.000556,    loss=0.132371,    train_acc=0.950367,    eval_loss=3.233200,    eval_acc=0.505544\n",
      "Test accuray: 0.62138\n",
      "epoch:  26,    lr=0.000533,    loss=0.113280,    train_acc=0.958034,    eval_loss=3.293150,    eval_acc=0.518165\n",
      "epoch:  27,    lr=0.000511,    loss=0.094509,    train_acc=0.965226,    eval_loss=3.573573,    eval_acc=0.514803\n",
      "epoch:  28,    lr=0.000489,    loss=0.085388,    train_acc=0.968823,    eval_loss=3.708480,    eval_acc=0.519108\n",
      "epoch:  29,    lr=0.000467,    loss=0.072729,    train_acc=0.974011,    eval_loss=3.798955,    eval_acc=0.513034\n",
      "epoch:  30,    lr=0.000444,    loss=0.059150,    train_acc=0.978895,    eval_loss=4.019129,    eval_acc=0.516277\n",
      "Test accuray: 0.6147\n",
      "epoch:  31,    lr=0.000422,    loss=0.056774,    train_acc=0.980226,    eval_loss=4.054135,    eval_acc=0.496226\n",
      "epoch:  32,    lr=0.000400,    loss=0.050474,    train_acc=0.982364,    eval_loss=4.362815,    eval_acc=0.510439\n",
      "epoch:  33,    lr=0.000378,    loss=0.041502,    train_acc=0.985955,    eval_loss=4.293528,    eval_acc=0.521055\n",
      "epoch:  34,    lr=0.000356,    loss=0.039138,    train_acc=0.986319,    eval_loss=4.642807,    eval_acc=0.511559\n",
      "epoch:  35,    lr=0.000333,    loss=0.032275,    train_acc=0.988931,    eval_loss=4.625824,    eval_acc=0.514272\n",
      "Test accuray: 0.62138\n",
      "epoch:  36,    lr=0.000311,    loss=0.027755,    train_acc=0.990644,    eval_loss=4.817988,    eval_acc=0.519875\n",
      "epoch:  37,    lr=0.000289,    loss=0.026019,    train_acc=0.991428,    eval_loss=4.901170,    eval_acc=0.515452\n",
      "epoch:  38,    lr=0.000267,    loss=0.022815,    train_acc=0.992303,    eval_loss=5.050817,    eval_acc=0.509554\n",
      "epoch:  39,    lr=0.000244,    loss=0.020922,    train_acc=0.993396,    eval_loss=5.009689,    eval_acc=0.512385\n",
      "epoch:  40,    lr=0.000222,    loss=0.016173,    train_acc=0.994684,    eval_loss=5.195001,    eval_acc=0.502654\n",
      "Test accuray: 0.61247\n",
      "epoch:  41,    lr=0.000200,    loss=0.012640,    train_acc=0.996009,    eval_loss=5.379641,    eval_acc=0.518460\n",
      "epoch:  42,    lr=0.000178,    loss=0.012652,    train_acc=0.996009,    eval_loss=5.376877,    eval_acc=0.521349\n",
      "epoch:  43,    lr=0.000156,    loss=0.010757,    train_acc=0.996659,    eval_loss=5.535584,    eval_acc=0.512798\n",
      "epoch:  44,    lr=0.000133,    loss=0.008630,    train_acc=0.997455,    eval_loss=5.558921,    eval_acc=0.518224\n",
      "epoch:  45,    lr=0.000111,    loss=0.006816,    train_acc=0.998056,    eval_loss=5.669477,    eval_acc=0.513211\n",
      "Test accuray: 0.61693\n",
      "epoch:  46,    lr=0.000089,    loss=0.006194,    train_acc=0.998329,    eval_loss=5.702954,    eval_acc=0.514567\n",
      "epoch:  47,    lr=0.000067,    loss=0.004310,    train_acc=0.998894,    eval_loss=5.829424,    eval_acc=0.514980\n",
      "epoch:  48,    lr=0.000044,    loss=0.003545,    train_acc=0.999137,    eval_loss=5.895941,    eval_acc=0.518224\n",
      "epoch:  49,    lr=0.000022,    loss=0.003478,    train_acc=0.999034,    eval_loss=5.871598,    eval_acc=0.516631\n",
      "epoch:  50,    lr=0.000000,    loss=0.002958,    train_acc=0.999210,    eval_loss=5.876434,    eval_acc=0.518047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [00:00, 174.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuray: 0.61915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4041it [00:27, 147.67it/s]\n",
      "449it [00:02, 161.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "epoch:   1,    lr=0.000200,    loss=1.142504,    train_acc=0.496652,    eval_loss=1.110026,    eval_acc=0.549864\n",
      "epoch:   2,    lr=0.000400,    loss=0.985986,    train_acc=0.598447,    eval_loss=1.099890,    eval_acc=0.564802\n",
      "epoch:   3,    lr=0.000600,    loss=0.943775,    train_acc=0.618898,    eval_loss=1.116955,    eval_acc=0.542205\n",
      "epoch:   4,    lr=0.000800,    loss=0.918358,    train_acc=0.630887,    eval_loss=1.076565,    eval_acc=0.574525\n",
      "epoch:   5,    lr=0.001000,    loss=0.898630,    train_acc=0.640981,    eval_loss=1.078903,    eval_acc=0.561217\n",
      "Test accuray: 0.62361\n",
      "epoch:   6,    lr=0.000978,    loss=0.882110,    train_acc=0.647205,    eval_loss=1.077450,    eval_acc=0.564259\n",
      "epoch:   7,    lr=0.000956,    loss=0.866749,    train_acc=0.654907,    eval_loss=1.149569,    eval_acc=0.551928\n",
      "epoch:   8,    lr=0.000933,    loss=0.851252,    train_acc=0.662793,    eval_loss=1.166857,    eval_acc=0.553449\n",
      "epoch:   9,    lr=0.000911,    loss=0.837563,    train_acc=0.666411,    eval_loss=1.108980,    eval_acc=0.571863\n",
      "epoch:  10,    lr=0.000889,    loss=0.822503,    train_acc=0.674126,    eval_loss=1.162901,    eval_acc=0.542966\n",
      "Test accuray: 0.6392\n",
      "epoch:  11,    lr=0.000867,    loss=0.805019,    train_acc=0.680227,    eval_loss=1.113064,    eval_acc=0.549973\n",
      "epoch:  12,    lr=0.000844,    loss=0.781310,    train_acc=0.690002,    eval_loss=1.206323,    eval_acc=0.556763\n",
      "epoch:  13,    lr=0.000822,    loss=0.744458,    train_acc=0.702843,    eval_loss=1.279168,    eval_acc=0.534275\n",
      "epoch:  14,    lr=0.000800,    loss=0.696119,    train_acc=0.723778,    eval_loss=1.255498,    eval_acc=0.546822\n",
      "epoch:  15,    lr=0.000778,    loss=0.633982,    train_acc=0.747474,    eval_loss=1.436044,    eval_acc=0.531450\n",
      "Test accuray: 0.65924\n",
      "epoch:  16,    lr=0.000756,    loss=0.562665,    train_acc=0.775670,    eval_loss=1.615534,    eval_acc=0.534492\n",
      "epoch:  17,    lr=0.000733,    loss=0.487773,    train_acc=0.805626,    eval_loss=1.901493,    eval_acc=0.518305\n",
      "epoch:  18,    lr=0.000711,    loss=0.420740,    train_acc=0.833902,    eval_loss=2.015810,    eval_acc=0.530961\n",
      "epoch:  19,    lr=0.000689,    loss=0.358485,    train_acc=0.858480,    eval_loss=2.175724,    eval_acc=0.509614\n",
      "epoch:  20,    lr=0.000667,    loss=0.304450,    train_acc=0.880605,    eval_loss=2.641557,    eval_acc=0.505215\n",
      "Test accuray: 0.63029\n",
      "epoch:  21,    lr=0.000644,    loss=0.262967,    train_acc=0.898180,    eval_loss=2.851248,    eval_acc=0.501086\n",
      "epoch:  22,    lr=0.000622,    loss=0.224506,    train_acc=0.912450,    eval_loss=2.888044,    eval_acc=0.506953\n",
      "epoch:  23,    lr=0.000600,    loss=0.191898,    train_acc=0.926713,    eval_loss=3.261787,    eval_acc=0.515698\n",
      "epoch:  24,    lr=0.000578,    loss=0.164436,    train_acc=0.938236,    eval_loss=3.395402,    eval_acc=0.512330\n",
      "epoch:  25,    lr=0.000556,    loss=0.141618,    train_acc=0.946815,    eval_loss=3.592421,    eval_acc=0.487778\n",
      "Test accuray: 0.62806\n",
      "epoch:  26,    lr=0.000533,    loss=0.120425,    train_acc=0.954910,    eval_loss=3.680382,    eval_acc=0.502227\n",
      "epoch:  27,    lr=0.000511,    loss=0.105389,    train_acc=0.961171,    eval_loss=3.886125,    eval_acc=0.505323\n",
      "epoch:  28,    lr=0.000489,    loss=0.093030,    train_acc=0.965941,    eval_loss=4.207427,    eval_acc=0.508419\n",
      "epoch:  29,    lr=0.000467,    loss=0.079200,    train_acc=0.971154,    eval_loss=4.348189,    eval_acc=0.506898\n",
      "epoch:  30,    lr=0.000444,    loss=0.063980,    train_acc=0.976679,    eval_loss=4.416977,    eval_acc=0.504671\n",
      "Test accuray: 0.61915\n",
      "epoch:  31,    lr=0.000422,    loss=0.060277,    train_acc=0.978721,    eval_loss=4.757773,    eval_acc=0.501847\n",
      "epoch:  32,    lr=0.000400,    loss=0.052820,    train_acc=0.981340,    eval_loss=4.582014,    eval_acc=0.500326\n",
      "epoch:  33,    lr=0.000378,    loss=0.044572,    train_acc=0.984651,    eval_loss=5.133014,    eval_acc=0.495166\n",
      "epoch:  34,    lr=0.000356,    loss=0.039652,    train_acc=0.986448,    eval_loss=4.952092,    eval_acc=0.507876\n",
      "epoch:  35,    lr=0.000333,    loss=0.035963,    train_acc=0.988024,    eval_loss=5.089496,    eval_acc=0.503857\n",
      "Test accuray: 0.63474\n",
      "epoch:  36,    lr=0.000311,    loss=0.032207,    train_acc=0.989066,    eval_loss=5.314950,    eval_acc=0.508202\n",
      "epoch:  37,    lr=0.000289,    loss=0.027204,    train_acc=0.990452,    eval_loss=5.372890,    eval_acc=0.504237\n",
      "epoch:  38,    lr=0.000267,    loss=0.024397,    train_acc=0.991771,    eval_loss=5.580441,    eval_acc=0.512928\n",
      "epoch:  39,    lr=0.000244,    loss=0.019287,    train_acc=0.993573,    eval_loss=5.678858,    eval_acc=0.516241\n",
      "epoch:  40,    lr=0.000222,    loss=0.019413,    train_acc=0.993604,    eval_loss=5.727990,    eval_acc=0.502010\n",
      "Test accuray: 0.62584\n",
      "epoch:  41,    lr=0.000200,    loss=0.016478,    train_acc=0.994671,    eval_loss=6.003570,    eval_acc=0.505486\n",
      "epoch:  42,    lr=0.000178,    loss=0.012880,    train_acc=0.995904,    eval_loss=5.944655,    eval_acc=0.514612\n",
      "epoch:  43,    lr=0.000156,    loss=0.010360,    train_acc=0.996830,    eval_loss=6.247225,    eval_acc=0.509071\n",
      "epoch:  44,    lr=0.000133,    loss=0.009057,    train_acc=0.997418,    eval_loss=6.239147,    eval_acc=0.512004\n",
      "epoch:  45,    lr=0.000111,    loss=0.008222,    train_acc=0.997437,    eval_loss=6.193115,    eval_acc=0.510212\n",
      "Test accuray: 0.62361\n",
      "epoch:  46,    lr=0.000089,    loss=0.006568,    train_acc=0.998081,    eval_loss=6.231420,    eval_acc=0.513960\n",
      "epoch:  47,    lr=0.000067,    loss=0.005277,    train_acc=0.998516,    eval_loss=6.314289,    eval_acc=0.515209\n",
      "epoch:  48,    lr=0.000044,    loss=0.004170,    train_acc=0.998866,    eval_loss=6.393017,    eval_acc=0.512330\n",
      "epoch:  49,    lr=0.000022,    loss=0.003757,    train_acc=0.999105,    eval_loss=6.431212,    eval_acc=0.516621\n",
      "epoch:  50,    lr=0.000000,    loss=0.003398,    train_acc=0.999111,    eval_loss=6.453828,    eval_acc=0.512819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [00:00, 133.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuray: 0.61915\n",
      "conv_dim: 1d \twith_focus_attn: True\n",
      "Test accuray: [0.6146993318485523, 0.6035634743875279, 0.6169265033407573, 0.6948775055679287, 0.6169265033407573, 0.5991091314031181, 0.5946547884187082, 0.6080178173719376, 0.6391982182628062, 0.6592427616926503]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4041it [00:25, 157.29it/s]\n",
      "449it [00:03, 139.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "epoch:   1,    lr=0.000200,    loss=1.168723,    train_acc=0.481156,    eval_loss=0.992027,    eval_acc=0.552211\n",
      "epoch:   2,    lr=0.000400,    loss=1.038159,    train_acc=0.566903,    eval_loss=0.961758,    eval_acc=0.583397\n",
      "epoch:   3,    lr=0.000600,    loss=0.980404,    train_acc=0.601992,    eval_loss=0.950368,    eval_acc=0.600402\n",
      "epoch:   4,    lr=0.000800,    loss=0.945630,    train_acc=0.618800,    eval_loss=1.016733,    eval_acc=0.571390\n",
      "epoch:   5,    lr=0.001000,    loss=0.924133,    train_acc=0.628600,    eval_loss=0.968829,    eval_acc=0.596436\n",
      "Test accuray: 0.59465\n",
      "epoch:   6,    lr=0.000978,    loss=0.905988,    train_acc=0.637829,    eval_loss=0.945625,    eval_acc=0.596762\n",
      "epoch:   7,    lr=0.000956,    loss=0.888964,    train_acc=0.645568,    eval_loss=0.957549,    eval_acc=0.594317\n",
      "epoch:   8,    lr=0.000933,    loss=0.871451,    train_acc=0.653319,    eval_loss=0.904963,    eval_acc=0.610127\n",
      "epoch:   9,    lr=0.000911,    loss=0.853155,    train_acc=0.659604,    eval_loss=0.949548,    eval_acc=0.592144\n",
      "epoch:  10,    lr=0.000889,    loss=0.834245,    train_acc=0.667165,    eval_loss=0.942455,    eval_acc=0.596545\n",
      "Test accuray: 0.59688\n",
      "epoch:  11,    lr=0.000867,    loss=0.805980,    train_acc=0.678124,    eval_loss=0.951326,    eval_acc=0.604096\n",
      "epoch:  12,    lr=0.000844,    loss=0.766013,    train_acc=0.693951,    eval_loss=0.981780,    eval_acc=0.596653\n",
      "epoch:  13,    lr=0.000822,    loss=0.714724,    train_acc=0.715120,    eval_loss=1.128699,    eval_acc=0.579105\n",
      "epoch:  14,    lr=0.000800,    loss=0.648030,    train_acc=0.741985,    eval_loss=1.211462,    eval_acc=0.587580\n",
      "epoch:  15,    lr=0.000778,    loss=0.575257,    train_acc=0.771083,    eval_loss=1.395988,    eval_acc=0.563621\n",
      "Test accuray: 0.60802\n",
      "epoch:  16,    lr=0.000756,    loss=0.502797,    train_acc=0.800450,    eval_loss=1.466430,    eval_acc=0.560143\n",
      "epoch:  17,    lr=0.000733,    loss=0.433469,    train_acc=0.829296,    eval_loss=1.676699,    eval_acc=0.554058\n",
      "epoch:  18,    lr=0.000711,    loss=0.373553,    train_acc=0.852863,    eval_loss=1.822776,    eval_acc=0.560252\n",
      "epoch:  19,    lr=0.000689,    loss=0.323233,    train_acc=0.873908,    eval_loss=1.979236,    eval_acc=0.557481\n",
      "epoch:  20,    lr=0.000667,    loss=0.277185,    train_acc=0.892679,    eval_loss=2.246456,    eval_acc=0.551505\n",
      "Test accuray: 0.60579\n",
      "epoch:  21,    lr=0.000644,    loss=0.238313,    train_acc=0.908360,    eval_loss=2.326670,    eval_acc=0.546181\n",
      "epoch:  22,    lr=0.000622,    loss=0.204503,    train_acc=0.921464,    eval_loss=2.456936,    eval_acc=0.557862\n",
      "epoch:  23,    lr=0.000600,    loss=0.176114,    train_acc=0.933778,    eval_loss=2.717174,    eval_acc=0.548408\n",
      "epoch:  24,    lr=0.000578,    loss=0.154902,    train_acc=0.941529,    eval_loss=2.814841,    eval_acc=0.546941\n",
      "epoch:  25,    lr=0.000556,    loss=0.130792,    train_acc=0.951592,    eval_loss=2.982861,    eval_acc=0.551777\n",
      "Test accuray: 0.57906\n",
      "epoch:  26,    lr=0.000533,    loss=0.113105,    train_acc=0.957841,    eval_loss=3.203285,    eval_acc=0.548734\n",
      "epoch:  27,    lr=0.000511,    loss=0.101878,    train_acc=0.962434,    eval_loss=3.335159,    eval_acc=0.542595\n",
      "epoch:  28,    lr=0.000489,    loss=0.087028,    train_acc=0.968118,    eval_loss=3.329726,    eval_acc=0.555145\n",
      "epoch:  29,    lr=0.000467,    loss=0.072297,    train_acc=0.974422,    eval_loss=3.496805,    eval_acc=0.551994\n",
      "epoch:  30,    lr=0.000444,    loss=0.065042,    train_acc=0.976888,    eval_loss=3.696176,    eval_acc=0.547974\n",
      "Test accuray: 0.57906\n",
      "epoch:  31,    lr=0.000422,    loss=0.059302,    train_acc=0.979439,    eval_loss=3.785361,    eval_acc=0.563566\n",
      "epoch:  32,    lr=0.000400,    loss=0.051919,    train_acc=0.981922,    eval_loss=3.713185,    eval_acc=0.552374\n",
      "epoch:  33,    lr=0.000378,    loss=0.046680,    train_acc=0.984344,    eval_loss=3.895670,    eval_acc=0.555525\n",
      "epoch:  34,    lr=0.000356,    loss=0.040558,    train_acc=0.986110,    eval_loss=4.030259,    eval_acc=0.550527\n",
      "epoch:  35,    lr=0.000333,    loss=0.035353,    train_acc=0.987981,    eval_loss=4.044543,    eval_acc=0.559600\n",
      "Test accuray: 0.60134\n",
      "epoch:  36,    lr=0.000311,    loss=0.030943,    train_acc=0.989514,    eval_loss=4.099373,    eval_acc=0.561991\n",
      "epoch:  37,    lr=0.000289,    loss=0.027263,    train_acc=0.991010,    eval_loss=4.341706,    eval_acc=0.564707\n",
      "epoch:  38,    lr=0.000267,    loss=0.024587,    train_acc=0.991758,    eval_loss=4.304933,    eval_acc=0.555634\n",
      "epoch:  39,    lr=0.000244,    loss=0.019920,    train_acc=0.993414,    eval_loss=4.386622,    eval_acc=0.561991\n",
      "epoch:  40,    lr=0.000222,    loss=0.017660,    train_acc=0.994199,    eval_loss=4.449337,    eval_acc=0.561828\n",
      "Test accuray: 0.59465\n",
      "epoch:  41,    lr=0.000200,    loss=0.015681,    train_acc=0.995045,    eval_loss=4.666327,    eval_acc=0.559437\n",
      "epoch:  42,    lr=0.000178,    loss=0.012760,    train_acc=0.995922,    eval_loss=4.724267,    eval_acc=0.557427\n",
      "epoch:  43,    lr=0.000156,    loss=0.012217,    train_acc=0.996143,    eval_loss=4.722500,    eval_acc=0.561447\n",
      "epoch:  44,    lr=0.000133,    loss=0.009770,    train_acc=0.997136,    eval_loss=4.826900,    eval_acc=0.557264\n",
      "epoch:  45,    lr=0.000111,    loss=0.008372,    train_acc=0.997510,    eval_loss=4.817899,    eval_acc=0.559654\n",
      "Test accuray: 0.58129\n",
      "epoch:  46,    lr=0.000089,    loss=0.006497,    train_acc=0.998111,    eval_loss=4.985298,    eval_acc=0.557970\n",
      "epoch:  47,    lr=0.000067,    loss=0.005738,    train_acc=0.998265,    eval_loss=4.922348,    eval_acc=0.559111\n",
      "epoch:  48,    lr=0.000044,    loss=0.004131,    train_acc=0.998958,    eval_loss=5.039584,    eval_acc=0.557264\n",
      "epoch:  49,    lr=0.000022,    loss=0.003734,    train_acc=0.999031,    eval_loss=4.974716,    eval_acc=0.560795\n",
      "epoch:  50,    lr=0.000000,    loss=0.003356,    train_acc=0.999246,    eval_loss=4.991326,    eval_acc=0.560143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17it [00:00, 164.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuray: 0.5902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4041it [00:26, 154.11it/s]\n",
      "449it [00:03, 141.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "epoch:   1,    lr=0.000200,    loss=1.142324,    train_acc=0.494101,    eval_loss=1.089391,    eval_acc=0.554996\n",
      "epoch:   2,    lr=0.000400,    loss=1.011195,    train_acc=0.583525,    eval_loss=1.074711,    eval_acc=0.556229\n",
      "epoch:   3,    lr=0.000600,    loss=0.969473,    train_acc=0.608301,    eval_loss=1.026158,    eval_acc=0.579091\n",
      "epoch:   4,    lr=0.000800,    loss=0.941673,    train_acc=0.620810,    eval_loss=1.119833,    eval_acc=0.544310\n",
      "epoch:   5,    lr=0.001000,    loss=0.920474,    train_acc=0.630727,    eval_loss=1.039349,    eval_acc=0.550064\n",
      "Test accuray: 0.58129\n",
      "epoch:   6,    lr=0.000978,    loss=0.899064,    train_acc=0.639199,    eval_loss=1.206055,    eval_acc=0.506602\n",
      "epoch:   7,    lr=0.000956,    loss=0.879692,    train_acc=0.648425,    eval_loss=1.015419,    eval_acc=0.597020\n",
      "epoch:   8,    lr=0.000933,    loss=0.863778,    train_acc=0.655553,    eval_loss=1.037151,    eval_acc=0.589314\n",
      "epoch:   9,    lr=0.000911,    loss=0.847167,    train_acc=0.661255,    eval_loss=1.100986,    eval_acc=0.574210\n",
      "epoch:  10,    lr=0.000889,    loss=0.832130,    train_acc=0.667383,    eval_loss=1.099173,    eval_acc=0.580118\n",
      "Test accuray: 0.60579\n",
      "epoch:  11,    lr=0.000867,    loss=0.809073,    train_acc=0.676176,    eval_loss=1.096402,    eval_acc=0.588698\n",
      "epoch:  12,    lr=0.000844,    loss=0.778821,    train_acc=0.689185,    eval_loss=1.238571,    eval_acc=0.558079\n",
      "epoch:  13,    lr=0.000822,    loss=0.734066,    train_acc=0.707568,    eval_loss=1.161760,    eval_acc=0.585975\n",
      "epoch:  14,    lr=0.000800,    loss=0.683709,    train_acc=0.726779,    eval_loss=1.372969,    eval_acc=0.572926\n",
      "epoch:  15,    lr=0.000778,    loss=0.623607,    train_acc=0.751537,    eval_loss=1.483767,    eval_acc=0.559414\n",
      "Test accuray: 0.61915\n",
      "epoch:  16,    lr=0.000756,    loss=0.558055,    train_acc=0.778263,    eval_loss=1.592881,    eval_acc=0.561264\n",
      "epoch:  17,    lr=0.000733,    loss=0.491563,    train_acc=0.803898,    eval_loss=1.866576,    eval_acc=0.570203\n",
      "epoch:  18,    lr=0.000711,    loss=0.430457,    train_acc=0.829205,    eval_loss=2.126760,    eval_acc=0.529823\n",
      "epoch:  19,    lr=0.000689,    loss=0.374955,    train_acc=0.852932,    eval_loss=2.159325,    eval_acc=0.548626\n",
      "epoch:  20,    lr=0.000667,    loss=0.324941,    train_acc=0.873069,    eval_loss=2.342323,    eval_acc=0.560647\n",
      "Test accuray: 0.63474\n",
      "epoch:  21,    lr=0.000644,    loss=0.279711,    train_acc=0.891785,    eval_loss=2.402447,    eval_acc=0.545235\n",
      "epoch:  22,    lr=0.000622,    loss=0.246512,    train_acc=0.904979,    eval_loss=2.836277,    eval_acc=0.549037\n",
      "epoch:  23,    lr=0.000600,    loss=0.214415,    train_acc=0.917531,    eval_loss=2.956403,    eval_acc=0.557308\n",
      "epoch:  24,    lr=0.000578,    loss=0.184369,    train_acc=0.929731,    eval_loss=2.954850,    eval_acc=0.549859\n",
      "epoch:  25,    lr=0.000556,    loss=0.162208,    train_acc=0.938870,    eval_loss=3.102450,    eval_acc=0.550527\n",
      "Test accuray: 0.61247\n",
      "epoch:  26,    lr=0.000533,    loss=0.139876,    train_acc=0.947374,    eval_loss=3.303454,    eval_acc=0.551194\n",
      "epoch:  27,    lr=0.000511,    loss=0.124418,    train_acc=0.952971,    eval_loss=3.683584,    eval_acc=0.543591\n",
      "epoch:  28,    lr=0.000489,    loss=0.108718,    train_acc=0.959901,    eval_loss=3.622656,    eval_acc=0.549807\n",
      "epoch:  29,    lr=0.000467,    loss=0.090934,    train_acc=0.966936,    eval_loss=3.726609,    eval_acc=0.546519\n",
      "epoch:  30,    lr=0.000444,    loss=0.083031,    train_acc=0.970182,    eval_loss=4.050014,    eval_acc=0.545132\n",
      "Test accuray: 0.61693\n",
      "epoch:  31,    lr=0.000422,    loss=0.075557,    train_acc=0.972996,    eval_loss=4.161104,    eval_acc=0.548523\n",
      "epoch:  32,    lr=0.000400,    loss=0.063473,    train_acc=0.977328,    eval_loss=4.174500,    eval_acc=0.552684\n",
      "epoch:  33,    lr=0.000378,    loss=0.054767,    train_acc=0.980469,    eval_loss=4.283326,    eval_acc=0.551914\n",
      "epoch:  34,    lr=0.000356,    loss=0.051215,    train_acc=0.981919,    eval_loss=4.513633,    eval_acc=0.545749\n",
      "epoch:  35,    lr=0.000333,    loss=0.042911,    train_acc=0.985301,    eval_loss=4.748067,    eval_acc=0.538967\n",
      "Test accuray: 0.61247\n",
      "epoch:  36,    lr=0.000311,    loss=0.038287,    train_acc=0.987022,    eval_loss=4.563029,    eval_acc=0.554020\n",
      "epoch:  37,    lr=0.000289,    loss=0.035816,    train_acc=0.987633,    eval_loss=4.711942,    eval_acc=0.550167\n",
      "epoch:  38,    lr=0.000267,    loss=0.028709,    train_acc=0.990219,    eval_loss=4.940125,    eval_acc=0.553609\n",
      "epoch:  39,    lr=0.000244,    loss=0.025054,    train_acc=0.991564,    eval_loss=5.001604,    eval_acc=0.552171\n",
      "epoch:  40,    lr=0.000222,    loss=0.022578,    train_acc=0.992391,    eval_loss=5.207527,    eval_acc=0.555099\n",
      "Test accuray: 0.61693\n",
      "epoch:  41,    lr=0.000200,    loss=0.019742,    train_acc=0.993576,    eval_loss=5.078255,    eval_acc=0.557257\n",
      "epoch:  42,    lr=0.000178,    loss=0.016296,    train_acc=0.994711,    eval_loss=5.232107,    eval_acc=0.549653\n",
      "epoch:  43,    lr=0.000156,    loss=0.015711,    train_acc=0.994835,    eval_loss=5.301612,    eval_acc=0.557719\n",
      "epoch:  44,    lr=0.000133,    loss=0.011621,    train_acc=0.996267,    eval_loss=5.404313,    eval_acc=0.551246\n",
      "epoch:  45,    lr=0.000111,    loss=0.011499,    train_acc=0.996513,    eval_loss=5.491580,    eval_acc=0.550629\n",
      "Test accuray: 0.62138\n",
      "epoch:  46,    lr=0.000089,    loss=0.008364,    train_acc=0.997581,    eval_loss=5.495083,    eval_acc=0.558798\n",
      "epoch:  47,    lr=0.000067,    loss=0.006520,    train_acc=0.998173,    eval_loss=5.618014,    eval_acc=0.556846\n",
      "epoch:  48,    lr=0.000044,    loss=0.006467,    train_acc=0.998217,    eval_loss=5.699074,    eval_acc=0.554534\n",
      "epoch:  49,    lr=0.000022,    loss=0.005363,    train_acc=0.998556,    eval_loss=5.767871,    eval_acc=0.558798\n",
      "epoch:  50,    lr=0.000000,    loss=0.004508,    train_acc=0.998803,    eval_loss=5.765834,    eval_acc=0.557308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17it [00:00, 167.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuray: 0.62584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4041it [00:27, 147.17it/s]\n",
      "449it [00:02, 149.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "epoch:   1,    lr=0.000200,    loss=1.149656,    train_acc=0.483653,    eval_loss=1.124083,    eval_acc=0.506688\n",
      "epoch:   2,    lr=0.000400,    loss=1.011859,    train_acc=0.580032,    eval_loss=1.060868,    eval_acc=0.549491\n",
      "epoch:   3,    lr=0.000600,    loss=0.951655,    train_acc=0.616811,    eval_loss=1.045034,    eval_acc=0.567188\n",
      "epoch:   4,    lr=0.000800,    loss=0.919517,    train_acc=0.632899,    eval_loss=1.025058,    eval_acc=0.568731\n",
      "epoch:   5,    lr=0.001000,    loss=0.901172,    train_acc=0.640057,    eval_loss=1.039472,    eval_acc=0.580358\n",
      "Test accuray: 0.59688\n",
      "epoch:   6,    lr=0.000978,    loss=0.884608,    train_acc=0.648610,    eval_loss=1.262112,    eval_acc=0.532154\n",
      "epoch:   7,    lr=0.000956,    loss=0.868288,    train_acc=0.654553,    eval_loss=1.028189,    eval_acc=0.580873\n",
      "epoch:   8,    lr=0.000933,    loss=0.853653,    train_acc=0.659891,    eval_loss=1.048880,    eval_acc=0.573516\n",
      "epoch:   9,    lr=0.000911,    loss=0.839742,    train_acc=0.666056,    eval_loss=1.051961,    eval_acc=0.586480\n",
      "epoch:  10,    lr=0.000889,    loss=0.820972,    train_acc=0.673103,    eval_loss=1.091344,    eval_acc=0.571818\n",
      "Test accuray: 0.57461\n",
      "epoch:  11,    lr=0.000867,    loss=0.799267,    train_acc=0.681175,    eval_loss=1.106380,    eval_acc=0.569915\n",
      "epoch:  12,    lr=0.000844,    loss=0.768028,    train_acc=0.694010,    eval_loss=1.133392,    eval_acc=0.557825\n",
      "epoch:  13,    lr=0.000822,    loss=0.723055,    train_acc=0.712104,    eval_loss=1.211987,    eval_acc=0.554121\n",
      "epoch:  14,    lr=0.000800,    loss=0.665231,    train_acc=0.735319,    eval_loss=1.318537,    eval_acc=0.549799\n",
      "epoch:  15,    lr=0.000778,    loss=0.596669,    train_acc=0.763354,    eval_loss=1.544548,    eval_acc=0.520475\n",
      "Test accuray: 0.61915\n",
      "epoch:  16,    lr=0.000756,    loss=0.526051,    train_acc=0.792796,    eval_loss=1.646222,    eval_acc=0.534314\n",
      "epoch:  17,    lr=0.000733,    loss=0.456319,    train_acc=0.821028,    eval_loss=1.890585,    eval_acc=0.519086\n",
      "epoch:  18,    lr=0.000711,    loss=0.390688,    train_acc=0.847940,    eval_loss=2.090243,    eval_acc=0.525929\n",
      "epoch:  19,    lr=0.000689,    loss=0.331329,    train_acc=0.871902,    eval_loss=2.313885,    eval_acc=0.518675\n",
      "epoch:  20,    lr=0.000667,    loss=0.282315,    train_acc=0.890329,    eval_loss=2.480163,    eval_acc=0.502727\n",
      "Test accuray: 0.60802\n",
      "epoch:  21,    lr=0.000644,    loss=0.236955,    train_acc=0.909373,    eval_loss=2.742488,    eval_acc=0.512861\n",
      "epoch:  22,    lr=0.000622,    loss=0.202893,    train_acc=0.922579,    eval_loss=2.945477,    eval_acc=0.516000\n",
      "epoch:  23,    lr=0.000600,    loss=0.169322,    train_acc=0.936235,    eval_loss=3.212836,    eval_acc=0.496965\n",
      "epoch:  24,    lr=0.000578,    loss=0.149526,    train_acc=0.944202,    eval_loss=3.366923,    eval_acc=0.514971\n",
      "epoch:  25,    lr=0.000556,    loss=0.126757,    train_acc=0.953026,    eval_loss=3.395079,    eval_acc=0.520064\n",
      "Test accuray: 0.5902\n",
      "epoch:  26,    lr=0.000533,    loss=0.108711,    train_acc=0.960074,    eval_loss=3.625304,    eval_acc=0.509209\n",
      "epoch:  27,    lr=0.000511,    loss=0.092703,    train_acc=0.965893,    eval_loss=3.810864,    eval_acc=0.511987\n",
      "epoch:  28,    lr=0.000489,    loss=0.081243,    train_acc=0.970965,    eval_loss=3.895293,    eval_acc=0.498868\n",
      "epoch:  29,    lr=0.000467,    loss=0.070510,    train_acc=0.974748,    eval_loss=4.028187,    eval_acc=0.508437\n",
      "epoch:  30,    lr=0.000444,    loss=0.064956,    train_acc=0.976840,    eval_loss=4.242946,    eval_acc=0.506379\n",
      "Test accuray: 0.56793\n",
      "epoch:  31,    lr=0.000422,    loss=0.057593,    train_acc=0.979728,    eval_loss=4.235843,    eval_acc=0.517955\n",
      "epoch:  32,    lr=0.000400,    loss=0.047984,    train_acc=0.983406,    eval_loss=4.513838,    eval_acc=0.509209\n",
      "epoch:  33,    lr=0.000378,    loss=0.041577,    train_acc=0.985683,    eval_loss=4.641218,    eval_acc=0.511575\n",
      "epoch:  34,    lr=0.000356,    loss=0.037219,    train_acc=0.987238,    eval_loss=4.761612,    eval_acc=0.520733\n",
      "epoch:  35,    lr=0.000333,    loss=0.034523,    train_acc=0.987991,    eval_loss=4.954954,    eval_acc=0.507923\n",
      "Test accuray: 0.5902\n",
      "epoch:  36,    lr=0.000311,    loss=0.029264,    train_acc=0.990077,    eval_loss=4.791775,    eval_acc=0.518675\n",
      "epoch:  37,    lr=0.000289,    loss=0.025335,    train_acc=0.991811,    eval_loss=4.988985,    eval_acc=0.514559\n",
      "epoch:  38,    lr=0.000267,    loss=0.023926,    train_acc=0.991737,    eval_loss=5.056293,    eval_acc=0.509260\n",
      "epoch:  39,    lr=0.000244,    loss=0.019409,    train_acc=0.993854,    eval_loss=5.211493,    eval_acc=0.511061\n",
      "epoch:  40,    lr=0.000222,    loss=0.016432,    train_acc=0.994662,    eval_loss=5.489222,    eval_acc=0.515948\n",
      "Test accuray: 0.58575\n",
      "epoch:  41,    lr=0.000200,    loss=0.014518,    train_acc=0.995322,    eval_loss=5.577047,    eval_acc=0.511832\n",
      "epoch:  42,    lr=0.000178,    loss=0.013253,    train_acc=0.995736,    eval_loss=5.695056,    eval_acc=0.515897\n",
      "epoch:  43,    lr=0.000156,    loss=0.011413,    train_acc=0.996365,    eval_loss=5.717031,    eval_acc=0.517903\n",
      "epoch:  44,    lr=0.000133,    loss=0.009263,    train_acc=0.997069,    eval_loss=5.581619,    eval_acc=0.513170\n",
      "epoch:  45,    lr=0.000111,    loss=0.007455,    train_acc=0.997772,    eval_loss=5.776520,    eval_acc=0.523614\n",
      "Test accuray: 0.57906\n",
      "epoch:  46,    lr=0.000089,    loss=0.005851,    train_acc=0.998161,    eval_loss=5.906682,    eval_acc=0.515897\n",
      "epoch:  47,    lr=0.000067,    loss=0.005172,    train_acc=0.998476,    eval_loss=5.949136,    eval_acc=0.513633\n",
      "epoch:  48,    lr=0.000044,    loss=0.003471,    train_acc=0.999068,    eval_loss=6.061158,    eval_acc=0.512861\n",
      "epoch:  49,    lr=0.000022,    loss=0.003335,    train_acc=0.999222,    eval_loss=6.016772,    eval_acc=0.518057\n",
      "epoch:  50,    lr=0.000000,    loss=0.003130,    train_acc=0.999259,    eval_loss=6.024350,    eval_acc=0.516463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [00:00, 158.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuray: 0.56793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4041it [00:27, 145.83it/s]\n",
      "449it [00:02, 161.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "epoch:   1,    lr=0.000200,    loss=1.157935,    train_acc=0.480059,    eval_loss=1.076812,    eval_acc=0.567194\n",
      "epoch:   2,    lr=0.000400,    loss=1.042795,    train_acc=0.558190,    eval_loss=0.978691,    eval_acc=0.626699\n",
      "epoch:   3,    lr=0.000600,    loss=0.990339,    train_acc=0.588927,    eval_loss=0.957751,    eval_acc=0.635143\n",
      "epoch:   4,    lr=0.000800,    loss=0.963022,    train_acc=0.603384,    eval_loss=0.951694,    eval_acc=0.642693\n",
      "epoch:   5,    lr=0.001000,    loss=0.939227,    train_acc=0.614553,    eval_loss=0.948093,    eval_acc=0.640289\n",
      "Test accuray: 0.66592\n",
      "epoch:   6,    lr=0.000978,    loss=0.916642,    train_acc=0.627580,    eval_loss=1.073088,    eval_acc=0.578491\n",
      "epoch:   7,    lr=0.000956,    loss=0.899697,    train_acc=0.635582,    eval_loss=0.921415,    eval_acc=0.659024\n",
      "epoch:   8,    lr=0.000933,    loss=0.883640,    train_acc=0.642758,    eval_loss=0.917294,    eval_acc=0.657905\n",
      "epoch:   9,    lr=0.000911,    loss=0.868350,    train_acc=0.648224,    eval_loss=1.006640,    eval_acc=0.617974\n",
      "epoch:  10,    lr=0.000889,    loss=0.852742,    train_acc=0.655559,    eval_loss=0.934529,    eval_acc=0.644874\n",
      "Test accuray: 0.68151\n",
      "epoch:  11,    lr=0.000867,    loss=0.830610,    train_acc=0.665206,    eval_loss=0.959248,    eval_acc=0.645993\n",
      "epoch:  12,    lr=0.000844,    loss=0.800214,    train_acc=0.676717,    eval_loss=1.082581,    eval_acc=0.612270\n",
      "epoch:  13,    lr=0.000822,    loss=0.759457,    train_acc=0.693515,    eval_loss=1.073879,    eval_acc=0.620491\n",
      "epoch:  14,    lr=0.000800,    loss=0.701994,    train_acc=0.717344,    eval_loss=1.187753,    eval_acc=0.604552\n",
      "epoch:  15,    lr=0.000778,    loss=0.632155,    train_acc=0.744700,    eval_loss=1.234463,    eval_acc=0.602483\n",
      "Test accuray: 0.67483\n",
      "epoch:  16,    lr=0.000756,    loss=0.560815,    train_acc=0.775180,    eval_loss=1.405327,    eval_acc=0.561993\n",
      "epoch:  17,    lr=0.000733,    loss=0.492595,    train_acc=0.802664,    eval_loss=1.560675,    eval_acc=0.572339\n",
      "epoch:  18,    lr=0.000711,    loss=0.425384,    train_acc=0.830173,    eval_loss=1.746689,    eval_acc=0.559588\n",
      "epoch:  19,    lr=0.000689,    loss=0.366668,    train_acc=0.853782,    eval_loss=1.975817,    eval_acc=0.553269\n",
      "epoch:  20,    lr=0.000667,    loss=0.312224,    train_acc=0.876461,    eval_loss=2.030870,    eval_acc=0.567921\n",
      "Test accuray: 0.66815\n",
      "epoch:  21,    lr=0.000644,    loss=0.271045,    train_acc=0.893211,    eval_loss=2.268415,    eval_acc=0.562217\n",
      "epoch:  22,    lr=0.000622,    loss=0.236012,    train_acc=0.908011,    eval_loss=2.550261,    eval_acc=0.565349\n",
      "epoch:  23,    lr=0.000600,    loss=0.201443,    train_acc=0.922444,    eval_loss=2.492913,    eval_acc=0.557687\n",
      "epoch:  24,    lr=0.000578,    loss=0.172086,    train_acc=0.934358,    eval_loss=2.718547,    eval_acc=0.549746\n",
      "epoch:  25,    lr=0.000556,    loss=0.150311,    train_acc=0.942965,    eval_loss=2.826258,    eval_acc=0.552318\n",
      "Test accuray: 0.66147\n",
      "epoch:  26,    lr=0.000533,    loss=0.128876,    train_acc=0.951585,    eval_loss=2.955399,    eval_acc=0.531122\n",
      "epoch:  27,    lr=0.000511,    loss=0.113659,    train_acc=0.957398,    eval_loss=3.130312,    eval_acc=0.533919\n",
      "epoch:  28,    lr=0.000489,    loss=0.097198,    train_acc=0.964550,    eval_loss=3.270635,    eval_acc=0.546670\n",
      "epoch:  29,    lr=0.000467,    loss=0.083701,    train_acc=0.969227,    eval_loss=3.247946,    eval_acc=0.556624\n",
      "epoch:  30,    lr=0.000444,    loss=0.075019,    train_acc=0.972723,    eval_loss=3.429930,    eval_acc=0.556009\n",
      "Test accuray: 0.66592\n",
      "epoch:  31,    lr=0.000422,    loss=0.065900,    train_acc=0.976636,    eval_loss=3.665646,    eval_acc=0.554611\n",
      "epoch:  32,    lr=0.000400,    loss=0.055904,    train_acc=0.980126,    eval_loss=3.593886,    eval_acc=0.551927\n",
      "epoch:  33,    lr=0.000378,    loss=0.050053,    train_acc=0.982559,    eval_loss=3.903763,    eval_acc=0.534366\n",
      "epoch:  34,    lr=0.000356,    loss=0.044460,    train_acc=0.984595,    eval_loss=3.781125,    eval_acc=0.564286\n",
      "epoch:  35,    lr=0.000333,    loss=0.036493,    train_acc=0.987505,    eval_loss=3.823976,    eval_acc=0.553828\n",
      "Test accuray: 0.65033\n",
      "epoch:  36,    lr=0.000311,    loss=0.034351,    train_acc=0.988410,    eval_loss=4.019557,    eval_acc=0.554220\n",
      "epoch:  37,    lr=0.000289,    loss=0.031048,    train_acc=0.989516,    eval_loss=4.143028,    eval_acc=0.551088\n",
      "epoch:  38,    lr=0.000267,    loss=0.026974,    train_acc=0.991038,    eval_loss=4.262325,    eval_acc=0.559756\n",
      "epoch:  39,    lr=0.000244,    loss=0.021662,    train_acc=0.992842,    eval_loss=4.332783,    eval_acc=0.566915\n",
      "epoch:  40,    lr=0.000222,    loss=0.020098,    train_acc=0.993416,    eval_loss=4.503186,    eval_acc=0.561993\n",
      "Test accuray: 0.66815\n",
      "epoch:  41,    lr=0.000200,    loss=0.017295,    train_acc=0.994523,    eval_loss=4.549161,    eval_acc=0.557575\n",
      "epoch:  42,    lr=0.000178,    loss=0.015010,    train_acc=0.995189,    eval_loss=4.444229,    eval_acc=0.555841\n",
      "epoch:  43,    lr=0.000156,    loss=0.012490,    train_acc=0.995959,    eval_loss=4.462667,    eval_acc=0.567753\n",
      "epoch:  44,    lr=0.000133,    loss=0.010773,    train_acc=0.996638,    eval_loss=4.668693,    eval_acc=0.553660\n",
      "epoch:  45,    lr=0.000111,    loss=0.008131,    train_acc=0.997475,    eval_loss=4.763410,    eval_acc=0.560483\n",
      "Test accuray: 0.65924\n",
      "epoch:  46,    lr=0.000089,    loss=0.007337,    train_acc=0.997793,    eval_loss=4.827675,    eval_acc=0.555394\n",
      "epoch:  47,    lr=0.000067,    loss=0.006020,    train_acc=0.998282,    eval_loss=4.804616,    eval_acc=0.558917\n",
      "epoch:  48,    lr=0.000044,    loss=0.005156,    train_acc=0.998570,    eval_loss=4.806582,    eval_acc=0.566859\n",
      "epoch:  49,    lr=0.000022,    loss=0.004128,    train_acc=0.998912,    eval_loss=4.842777,    eval_acc=0.561602\n",
      "epoch:  50,    lr=0.000000,    loss=0.003897,    train_acc=0.999059,    eval_loss=4.822060,    eval_acc=0.564062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [00:00, 175.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuray: 0.65256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4041it [00:29, 138.04it/s]\n",
      "449it [00:02, 173.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "epoch:   1,    lr=0.000200,    loss=1.137316,    train_acc=0.489472,    eval_loss=1.098030,    eval_acc=0.508581\n",
      "epoch:   2,    lr=0.000400,    loss=1.004833,    train_acc=0.583599,    eval_loss=1.091668,    eval_acc=0.532503\n",
      "epoch:   3,    lr=0.000600,    loss=0.951532,    train_acc=0.613263,    eval_loss=1.055630,    eval_acc=0.561302\n",
      "epoch:   4,    lr=0.000800,    loss=0.915568,    train_acc=0.632053,    eval_loss=1.022553,    eval_acc=0.574880\n",
      "epoch:   5,    lr=0.001000,    loss=0.897633,    train_acc=0.640947,    eval_loss=1.070955,    eval_acc=0.561302\n",
      "Test accuray: 0.55234\n",
      "epoch:   6,    lr=0.000978,    loss=0.881006,    train_acc=0.649549,    eval_loss=1.061693,    eval_acc=0.568473\n",
      "epoch:   7,    lr=0.000956,    loss=0.866004,    train_acc=0.654737,    eval_loss=1.019504,    eval_acc=0.583813\n",
      "epoch:   8,    lr=0.000933,    loss=0.854926,    train_acc=0.659409,    eval_loss=1.040939,    eval_acc=0.587105\n",
      "epoch:   9,    lr=0.000911,    loss=0.838756,    train_acc=0.665921,    eval_loss=1.104726,    eval_acc=0.565534\n",
      "epoch:  10,    lr=0.000889,    loss=0.823036,    train_acc=0.671602,    eval_loss=1.067346,    eval_acc=0.577113\n",
      "Test accuray: 0.60356\n",
      "epoch:  11,    lr=0.000867,    loss=0.801077,    train_acc=0.679299,    eval_loss=1.094604,    eval_acc=0.569825\n",
      "epoch:  12,    lr=0.000844,    loss=0.769762,    train_acc=0.691722,    eval_loss=1.115627,    eval_acc=0.580346\n",
      "epoch:  13,    lr=0.000822,    loss=0.727143,    train_acc=0.707870,    eval_loss=1.226718,    eval_acc=0.543494\n",
      "epoch:  14,    lr=0.000800,    loss=0.670085,    train_acc=0.730754,    eval_loss=1.250443,    eval_acc=0.555778\n",
      "epoch:  15,    lr=0.000778,    loss=0.604252,    train_acc=0.757314,    eval_loss=1.388846,    eval_acc=0.536852\n",
      "Test accuray: 0.59243\n",
      "epoch:  16,    lr=0.000756,    loss=0.530289,    train_acc=0.787732,    eval_loss=1.485237,    eval_acc=0.551134\n",
      "epoch:  17,    lr=0.000733,    loss=0.460175,    train_acc=0.816868,    eval_loss=1.607931,    eval_acc=0.526037\n",
      "epoch:  18,    lr=0.000711,    loss=0.390744,    train_acc=0.845402,    eval_loss=1.901454,    eval_acc=0.516575\n",
      "epoch:  19,    lr=0.000689,    loss=0.334807,    train_acc=0.867303,    eval_loss=2.150431,    eval_acc=0.528506\n",
      "epoch:  20,    lr=0.000667,    loss=0.282720,    train_acc=0.889817,    eval_loss=2.242688,    eval_acc=0.508934\n",
      "Test accuray: 0.59911\n",
      "epoch:  21,    lr=0.000644,    loss=0.243798,    train_acc=0.905308,    eval_loss=2.471777,    eval_acc=0.504467\n",
      "epoch:  22,    lr=0.000622,    loss=0.205056,    train_acc=0.921310,    eval_loss=2.654616,    eval_acc=0.504114\n",
      "epoch:  23,    lr=0.000600,    loss=0.173505,    train_acc=0.934232,    eval_loss=2.908298,    eval_acc=0.514165\n",
      "epoch:  24,    lr=0.000578,    loss=0.147972,    train_acc=0.944091,    eval_loss=3.142883,    eval_acc=0.516339\n",
      "epoch:  25,    lr=0.000556,    loss=0.126406,    train_acc=0.953192,    eval_loss=3.243249,    eval_acc=0.505819\n",
      "Test accuray: 0.59243\n",
      "epoch:  26,    lr=0.000533,    loss=0.111383,    train_acc=0.959431,    eval_loss=3.265087,    eval_acc=0.512402\n",
      "epoch:  27,    lr=0.000511,    loss=0.096613,    train_acc=0.964923,    eval_loss=3.443599,    eval_acc=0.498472\n",
      "epoch:  28,    lr=0.000489,    loss=0.083519,    train_acc=0.970020,    eval_loss=3.740767,    eval_acc=0.495592\n",
      "epoch:  29,    lr=0.000467,    loss=0.073029,    train_acc=0.973756,    eval_loss=4.106080,    eval_acc=0.509580\n",
      "epoch:  30,    lr=0.000444,    loss=0.063429,    train_acc=0.977413,    eval_loss=4.348497,    eval_acc=0.496356\n",
      "Test accuray: 0.59465\n",
      "epoch:  31,    lr=0.000422,    loss=0.057269,    train_acc=0.979260,    eval_loss=4.212585,    eval_acc=0.496885\n",
      "epoch:  32,    lr=0.000400,    loss=0.052438,    train_acc=0.981775,    eval_loss=4.178246,    eval_acc=0.507229\n",
      "epoch:  33,    lr=0.000378,    loss=0.042832,    train_acc=0.985420,    eval_loss=4.462899,    eval_acc=0.511814\n",
      "epoch:  34,    lr=0.000356,    loss=0.037185,    train_acc=0.987394,    eval_loss=4.445236,    eval_acc=0.511990\n",
      "epoch:  35,    lr=0.000333,    loss=0.035200,    train_acc=0.988148,    eval_loss=4.474504,    eval_acc=0.498296\n",
      "Test accuray: 0.59688\n",
      "epoch:  36,    lr=0.000311,    loss=0.030593,    train_acc=0.989988,    eval_loss=4.745308,    eval_acc=0.514870\n",
      "epoch:  37,    lr=0.000289,    loss=0.027152,    train_acc=0.990948,    eval_loss=4.940195,    eval_acc=0.495180\n",
      "epoch:  38,    lr=0.000267,    loss=0.022894,    train_acc=0.992522,    eval_loss=5.146359,    eval_acc=0.509051\n",
      "epoch:  39,    lr=0.000244,    loss=0.020941,    train_acc=0.993056,    eval_loss=5.095664,    eval_acc=0.504349\n",
      "epoch:  40,    lr=0.000222,    loss=0.019862,    train_acc=0.993396,    eval_loss=5.173324,    eval_acc=0.506935\n",
      "Test accuray: 0.59688\n",
      "epoch:  41,    lr=0.000200,    loss=0.015703,    train_acc=0.994903,    eval_loss=5.249906,    eval_acc=0.507700\n",
      "epoch:  42,    lr=0.000178,    loss=0.012846,    train_acc=0.996100,    eval_loss=5.453979,    eval_acc=0.506289\n",
      "epoch:  43,    lr=0.000156,    loss=0.011196,    train_acc=0.996634,    eval_loss=5.397280,    eval_acc=0.508699\n",
      "epoch:  44,    lr=0.000133,    loss=0.009273,    train_acc=0.997114,    eval_loss=5.601128,    eval_acc=0.513871\n",
      "epoch:  45,    lr=0.000111,    loss=0.007566,    train_acc=0.997704,    eval_loss=5.651664,    eval_acc=0.509757\n",
      "Test accuray: 0.58129\n",
      "epoch:  46,    lr=0.000089,    loss=0.006373,    train_acc=0.998153,    eval_loss=5.770131,    eval_acc=0.503350\n",
      "epoch:  47,    lr=0.000067,    loss=0.005278,    train_acc=0.998530,    eval_loss=5.847553,    eval_acc=0.511696\n",
      "epoch:  48,    lr=0.000044,    loss=0.004768,    train_acc=0.998749,    eval_loss=5.873687,    eval_acc=0.510344\n",
      "epoch:  49,    lr=0.000022,    loss=0.003916,    train_acc=0.998961,    eval_loss=5.970321,    eval_acc=0.507053\n",
      "epoch:  50,    lr=0.000000,    loss=0.003355,    train_acc=0.999253,    eval_loss=5.979953,    eval_acc=0.509169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [00:00, 139.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuray: 0.58352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4041it [00:26, 152.15it/s]\n",
      "449it [00:03, 122.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "epoch:   1,    lr=0.000200,    loss=1.143331,    train_acc=0.488178,    eval_loss=1.091644,    eval_acc=0.535544\n",
      "epoch:   2,    lr=0.000400,    loss=0.985010,    train_acc=0.601148,    eval_loss=1.073958,    eval_acc=0.549923\n",
      "epoch:   3,    lr=0.000600,    loss=0.942775,    train_acc=0.622142,    eval_loss=1.041383,    eval_acc=0.576617\n",
      "epoch:   4,    lr=0.000800,    loss=0.919375,    train_acc=0.633026,    eval_loss=1.011310,    eval_acc=0.595463\n",
      "epoch:   5,    lr=0.001000,    loss=0.901536,    train_acc=0.641454,    eval_loss=1.053706,    eval_acc=0.565561\n",
      "Test accuray: 0.55679\n",
      "epoch:   6,    lr=0.000978,    loss=0.888453,    train_acc=0.646451,    eval_loss=1.040904,    eval_acc=0.571289\n",
      "epoch:   7,    lr=0.000956,    loss=0.873965,    train_acc=0.652898,    eval_loss=1.144777,    eval_acc=0.545340\n",
      "epoch:   8,    lr=0.000933,    loss=0.860449,    train_acc=0.659949,    eval_loss=1.080592,    eval_acc=0.553703\n",
      "epoch:   9,    lr=0.000911,    loss=0.846901,    train_acc=0.663575,    eval_loss=1.085532,    eval_acc=0.556739\n",
      "epoch:  10,    lr=0.000889,    loss=0.832981,    train_acc=0.668980,    eval_loss=1.057005,    eval_acc=0.570487\n",
      "Test accuray: 0.58352\n",
      "epoch:  11,    lr=0.000867,    loss=0.810686,    train_acc=0.677018,    eval_loss=1.122288,    eval_acc=0.555536\n",
      "epoch:  12,    lr=0.000844,    loss=0.780727,    train_acc=0.688335,    eval_loss=1.123534,    eval_acc=0.568483\n",
      "epoch:  13,    lr=0.000822,    loss=0.737288,    train_acc=0.705319,    eval_loss=1.173786,    eval_acc=0.556338\n",
      "epoch:  14,    lr=0.000800,    loss=0.682852,    train_acc=0.726739,    eval_loss=1.186903,    eval_acc=0.570144\n",
      "epoch:  15,    lr=0.000778,    loss=0.611339,    train_acc=0.755783,    eval_loss=1.363190,    eval_acc=0.538523\n",
      "Test accuray: 0.55902\n",
      "epoch:  16,    lr=0.000756,    loss=0.537297,    train_acc=0.787076,    eval_loss=1.440808,    eval_acc=0.559031\n",
      "epoch:  17,    lr=0.000733,    loss=0.463459,    train_acc=0.816522,    eval_loss=1.573662,    eval_acc=0.524145\n",
      "epoch:  18,    lr=0.000711,    loss=0.395637,    train_acc=0.843811,    eval_loss=1.805196,    eval_acc=0.536461\n",
      "epoch:  19,    lr=0.000689,    loss=0.335473,    train_acc=0.868869,    eval_loss=1.936430,    eval_acc=0.543220\n",
      "epoch:  20,    lr=0.000667,    loss=0.282529,    train_acc=0.890564,    eval_loss=2.252561,    eval_acc=0.520021\n",
      "Test accuray: 0.5657\n",
      "epoch:  21,    lr=0.000644,    loss=0.237564,    train_acc=0.908657,    eval_loss=2.416463,    eval_acc=0.510454\n",
      "epoch:  22,    lr=0.000622,    loss=0.202832,    train_acc=0.922515,    eval_loss=2.505868,    eval_acc=0.526952\n",
      "epoch:  23,    lr=0.000600,    loss=0.169794,    train_acc=0.935471,    eval_loss=2.901871,    eval_acc=0.521395\n",
      "epoch:  24,    lr=0.000578,    loss=0.140504,    train_acc=0.947701,    eval_loss=3.015417,    eval_acc=0.509652\n",
      "epoch:  25,    lr=0.000556,    loss=0.123413,    train_acc=0.954472,    eval_loss=3.177193,    eval_acc=0.532337\n",
      "Test accuray: 0.57461\n",
      "epoch:  26,    lr=0.000533,    loss=0.105264,    train_acc=0.961663,    eval_loss=3.417323,    eval_acc=0.515495\n",
      "epoch:  27,    lr=0.000511,    loss=0.091512,    train_acc=0.966721,    eval_loss=3.425503,    eval_acc=0.518474\n",
      "epoch:  28,    lr=0.000489,    loss=0.075917,    train_acc=0.972821,    eval_loss=3.628841,    eval_acc=0.524603\n",
      "epoch:  29,    lr=0.000467,    loss=0.067027,    train_acc=0.976014,    eval_loss=3.788717,    eval_acc=0.526837\n",
      "epoch:  30,    lr=0.000444,    loss=0.060565,    train_acc=0.978299,    eval_loss=3.664943,    eval_acc=0.520479\n",
      "Test accuray: 0.58129\n",
      "epoch:  31,    lr=0.000422,    loss=0.050618,    train_acc=0.982181,    eval_loss=4.213483,    eval_acc=0.519791\n",
      "epoch:  32,    lr=0.000400,    loss=0.046558,    train_acc=0.984082,    eval_loss=4.070940,    eval_acc=0.518646\n",
      "epoch:  33,    lr=0.000378,    loss=0.038149,    train_acc=0.987123,    eval_loss=4.373117,    eval_acc=0.514980\n",
      "epoch:  34,    lr=0.000356,    loss=0.037938,    train_acc=0.986953,    eval_loss=4.473611,    eval_acc=0.525520\n",
      "epoch:  35,    lr=0.000333,    loss=0.030379,    train_acc=0.990152,    eval_loss=4.704789,    eval_acc=0.517557\n",
      "Test accuray: 0.56347\n",
      "epoch:  36,    lr=0.000311,    loss=0.025686,    train_acc=0.991237,    eval_loss=4.710513,    eval_acc=0.520364\n",
      "epoch:  37,    lr=0.000289,    loss=0.023675,    train_acc=0.991999,    eval_loss=4.686815,    eval_acc=0.520422\n",
      "epoch:  38,    lr=0.000267,    loss=0.020426,    train_acc=0.993419,    eval_loss=5.048347,    eval_acc=0.518589\n",
      "epoch:  39,    lr=0.000244,    loss=0.018287,    train_acc=0.993796,    eval_loss=5.092797,    eval_acc=0.509309\n",
      "epoch:  40,    lr=0.000222,    loss=0.016311,    train_acc=0.994790,    eval_loss=5.305774,    eval_acc=0.518417\n",
      "Test accuray: 0.56347\n",
      "epoch:  41,    lr=0.000200,    loss=0.014388,    train_acc=0.995381,    eval_loss=5.139162,    eval_acc=0.520708\n",
      "epoch:  42,    lr=0.000178,    loss=0.010934,    train_acc=0.996581,    eval_loss=5.200572,    eval_acc=0.521682\n",
      "epoch:  43,    lr=0.000156,    loss=0.009178,    train_acc=0.997252,    eval_loss=5.329993,    eval_acc=0.519161\n",
      "epoch:  44,    lr=0.000133,    loss=0.007834,    train_acc=0.997709,    eval_loss=5.530686,    eval_acc=0.521281\n",
      "epoch:  45,    lr=0.000111,    loss=0.006578,    train_acc=0.998026,    eval_loss=5.516388,    eval_acc=0.521854\n",
      "Test accuray: 0.5657\n",
      "epoch:  46,    lr=0.000089,    loss=0.005658,    train_acc=0.998379,    eval_loss=5.618300,    eval_acc=0.522541\n",
      "epoch:  47,    lr=0.000067,    loss=0.004518,    train_acc=0.998708,    eval_loss=5.646046,    eval_acc=0.524202\n",
      "epoch:  48,    lr=0.000044,    loss=0.003582,    train_acc=0.999062,    eval_loss=5.772770,    eval_acc=0.521854\n",
      "epoch:  49,    lr=0.000022,    loss=0.003173,    train_acc=0.999165,    eval_loss=5.772120,    eval_acc=0.520708\n",
      "epoch:  50,    lr=0.000000,    loss=0.002404,    train_acc=0.999500,    eval_loss=5.809790,    eval_acc=0.522598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [00:00, 172.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuray: 0.55902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4041it [00:25, 157.93it/s]\n",
      "449it [00:03, 148.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "epoch:   1,    lr=0.000200,    loss=1.156815,    train_acc=0.475052,    eval_loss=1.178234,    eval_acc=0.471211\n",
      "epoch:   2,    lr=0.000400,    loss=1.012280,    train_acc=0.575693,    eval_loss=1.120200,    eval_acc=0.537774\n",
      "epoch:   3,    lr=0.000600,    loss=0.960375,    train_acc=0.606107,    eval_loss=1.054844,    eval_acc=0.588335\n",
      "epoch:   4,    lr=0.000800,    loss=0.928839,    train_acc=0.623280,    eval_loss=1.117287,    eval_acc=0.551385\n",
      "epoch:   5,    lr=0.001000,    loss=0.908326,    train_acc=0.631682,    eval_loss=1.076550,    eval_acc=0.577755\n",
      "Test accuray: 0.57238\n",
      "epoch:   6,    lr=0.000978,    loss=0.889369,    train_acc=0.641835,    eval_loss=1.106993,    eval_acc=0.541018\n",
      "epoch:   7,    lr=0.000956,    loss=0.869671,    train_acc=0.650876,    eval_loss=1.160951,    eval_acc=0.514275\n",
      "epoch:   8,    lr=0.000933,    loss=0.857213,    train_acc=0.656311,    eval_loss=1.080570,    eval_acc=0.560902\n",
      "epoch:   9,    lr=0.000911,    loss=0.842322,    train_acc=0.662318,    eval_loss=1.116186,    eval_acc=0.552289\n",
      "epoch:  10,    lr=0.000889,    loss=0.827486,    train_acc=0.669725,    eval_loss=1.131123,    eval_acc=0.550056\n",
      "Test accuray: 0.56347\n",
      "epoch:  11,    lr=0.000867,    loss=0.809599,    train_acc=0.676420,    eval_loss=1.143223,    eval_acc=0.558084\n",
      "epoch:  12,    lr=0.000844,    loss=0.784712,    train_acc=0.685780,    eval_loss=1.184973,    eval_acc=0.550481\n",
      "epoch:  13,    lr=0.000822,    loss=0.749656,    train_acc=0.699802,    eval_loss=1.235686,    eval_acc=0.528151\n",
      "epoch:  14,    lr=0.000800,    loss=0.699915,    train_acc=0.720212,    eval_loss=1.353984,    eval_acc=0.514275\n",
      "epoch:  15,    lr=0.000778,    loss=0.634747,    train_acc=0.747906,    eval_loss=1.411995,    eval_acc=0.497475\n",
      "Test accuray: 0.53898\n",
      "epoch:  16,    lr=0.000756,    loss=0.565192,    train_acc=0.775108,    eval_loss=1.584365,    eval_acc=0.520761\n",
      "epoch:  17,    lr=0.000733,    loss=0.494290,    train_acc=0.805025,    eval_loss=1.704926,    eval_acc=0.509862\n",
      "epoch:  18,    lr=0.000711,    loss=0.427839,    train_acc=0.831601,    eval_loss=1.842906,    eval_acc=0.497953\n",
      "epoch:  19,    lr=0.000689,    loss=0.364335,    train_acc=0.857023,    eval_loss=2.003615,    eval_acc=0.505715\n",
      "epoch:  20,    lr=0.000667,    loss=0.314638,    train_acc=0.877266,    eval_loss=2.405774,    eval_acc=0.493115\n",
      "Test accuray: 0.5657\n",
      "epoch:  21,    lr=0.000644,    loss=0.267970,    train_acc=0.896533,    eval_loss=2.351185,    eval_acc=0.499389\n",
      "epoch:  22,    lr=0.000622,    loss=0.231782,    train_acc=0.911133,    eval_loss=2.714405,    eval_acc=0.488809\n",
      "epoch:  23,    lr=0.000600,    loss=0.191962,    train_acc=0.927378,    eval_loss=2.880377,    eval_acc=0.486363\n",
      "epoch:  24,    lr=0.000578,    loss=0.169321,    train_acc=0.936880,    eval_loss=3.049745,    eval_acc=0.475411\n",
      "epoch:  25,    lr=0.000556,    loss=0.145065,    train_acc=0.945939,    eval_loss=3.033320,    eval_acc=0.487001\n",
      "Test accuray: 0.5902\n",
      "epoch:  26,    lr=0.000533,    loss=0.128483,    train_acc=0.952652,    eval_loss=3.225078,    eval_acc=0.478813\n",
      "epoch:  27,    lr=0.000511,    loss=0.106973,    train_acc=0.961005,    eval_loss=3.625353,    eval_acc=0.487320\n",
      "epoch:  28,    lr=0.000489,    loss=0.094985,    train_acc=0.965562,    eval_loss=3.782654,    eval_acc=0.480568\n",
      "epoch:  29,    lr=0.000467,    loss=0.083230,    train_acc=0.969978,    eval_loss=3.732013,    eval_acc=0.474773\n",
      "epoch:  30,    lr=0.000444,    loss=0.067491,    train_acc=0.975696,    eval_loss=3.793021,    eval_acc=0.486522\n",
      "Test accuray: 0.58797\n",
      "epoch:  31,    lr=0.000422,    loss=0.064567,    train_acc=0.976784,    eval_loss=3.975124,    eval_acc=0.470892\n",
      "epoch:  32,    lr=0.000400,    loss=0.056129,    train_acc=0.980272,    eval_loss=4.304498,    eval_acc=0.480302\n",
      "epoch:  33,    lr=0.000378,    loss=0.048831,    train_acc=0.983509,    eval_loss=4.310565,    eval_acc=0.490935\n",
      "epoch:  34,    lr=0.000356,    loss=0.042446,    train_acc=0.985143,    eval_loss=4.535900,    eval_acc=0.491095\n",
      "epoch:  35,    lr=0.000333,    loss=0.038044,    train_acc=0.986912,    eval_loss=4.469498,    eval_acc=0.484927\n",
      "Test accuray: 0.57238\n",
      "epoch:  36,    lr=0.000311,    loss=0.035118,    train_acc=0.987870,    eval_loss=4.750742,    eval_acc=0.484236\n",
      "epoch:  37,    lr=0.000289,    loss=0.028863,    train_acc=0.990554,    eval_loss=5.010465,    eval_acc=0.485406\n",
      "epoch:  38,    lr=0.000267,    loss=0.025566,    train_acc=0.991315,    eval_loss=4.976345,    eval_acc=0.494391\n",
      "epoch:  39,    lr=0.000244,    loss=0.022960,    train_acc=0.992304,    eval_loss=5.178671,    eval_acc=0.485406\n",
      "epoch:  40,    lr=0.000222,    loss=0.020786,    train_acc=0.993268,    eval_loss=5.085199,    eval_acc=0.492317\n",
      "Test accuray: 0.5657\n",
      "epoch:  41,    lr=0.000200,    loss=0.017182,    train_acc=0.994632,    eval_loss=5.291311,    eval_acc=0.488117\n",
      "epoch:  42,    lr=0.000178,    loss=0.013692,    train_acc=0.995787,    eval_loss=5.366885,    eval_acc=0.487054\n",
      "epoch:  43,    lr=0.000156,    loss=0.013169,    train_acc=0.995823,    eval_loss=5.448978,    eval_acc=0.491892\n",
      "epoch:  44,    lr=0.000133,    loss=0.010302,    train_acc=0.996880,    eval_loss=5.466342,    eval_acc=0.483598\n",
      "epoch:  45,    lr=0.000111,    loss=0.008804,    train_acc=0.997396,    eval_loss=5.501109,    eval_acc=0.491680\n",
      "Test accuray: 0.57238\n",
      "epoch:  46,    lr=0.000089,    loss=0.007580,    train_acc=0.997764,    eval_loss=5.576220,    eval_acc=0.487639\n",
      "epoch:  47,    lr=0.000067,    loss=0.006357,    train_acc=0.998145,    eval_loss=5.691298,    eval_acc=0.493540\n",
      "epoch:  48,    lr=0.000044,    loss=0.005092,    train_acc=0.998655,    eval_loss=5.704045,    eval_acc=0.488809\n",
      "epoch:  49,    lr=0.000022,    loss=0.004517,    train_acc=0.998827,    eval_loss=5.859011,    eval_acc=0.489872\n",
      "epoch:  50,    lr=0.000000,    loss=0.003436,    train_acc=0.999195,    eval_loss=5.784719,    eval_acc=0.491254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [00:00, 156.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuray: 0.58129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4041it [00:26, 153.51it/s]\n",
      "449it [00:02, 165.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "epoch:   1,    lr=0.000200,    loss=1.126528,    train_acc=0.502030,    eval_loss=1.159303,    eval_acc=0.508864\n",
      "epoch:   2,    lr=0.000400,    loss=0.991743,    train_acc=0.591005,    eval_loss=1.124793,    eval_acc=0.529230\n",
      "epoch:   3,    lr=0.000600,    loss=0.945133,    train_acc=0.618343,    eval_loss=1.087548,    eval_acc=0.550662\n",
      "epoch:   4,    lr=0.000800,    loss=0.922064,    train_acc=0.630055,    eval_loss=1.167849,    eval_acc=0.526088\n",
      "epoch:   5,    lr=0.001000,    loss=0.902826,    train_acc=0.638253,    eval_loss=1.166666,    eval_acc=0.526369\n",
      "Test accuray: 0.55234\n",
      "epoch:   6,    lr=0.000978,    loss=0.887495,    train_acc=0.644776,    eval_loss=1.108971,    eval_acc=0.543817\n",
      "epoch:   7,    lr=0.000956,    loss=0.873057,    train_acc=0.650278,    eval_loss=1.078665,    eval_acc=0.544715\n",
      "epoch:   8,    lr=0.000933,    loss=0.855330,    train_acc=0.657375,    eval_loss=1.098318,    eval_acc=0.554533\n",
      "epoch:   9,    lr=0.000911,    loss=0.843446,    train_acc=0.661550,    eval_loss=1.089842,    eval_acc=0.562893\n",
      "epoch:  10,    lr=0.000889,    loss=0.824530,    train_acc=0.669631,    eval_loss=1.171007,    eval_acc=0.519412\n",
      "Test accuray: 0.54343\n",
      "epoch:  11,    lr=0.000867,    loss=0.802851,    train_acc=0.677499,    eval_loss=1.178925,    eval_acc=0.539666\n",
      "epoch:  12,    lr=0.000844,    loss=0.775022,    train_acc=0.688466,    eval_loss=1.193188,    eval_acc=0.551728\n",
      "epoch:  13,    lr=0.000822,    loss=0.737547,    train_acc=0.703638,    eval_loss=1.257777,    eval_acc=0.535682\n",
      "epoch:  14,    lr=0.000800,    loss=0.685837,    train_acc=0.723072,    eval_loss=1.570825,    eval_acc=0.488106\n",
      "epoch:  15,    lr=0.000778,    loss=0.620087,    train_acc=0.750391,    eval_loss=1.569340,    eval_acc=0.519693\n",
      "Test accuray: 0.55234\n",
      "epoch:  16,    lr=0.000756,    loss=0.547913,    train_acc=0.780333,    eval_loss=1.689270,    eval_acc=0.504096\n",
      "epoch:  17,    lr=0.000733,    loss=0.474030,    train_acc=0.810905,    eval_loss=2.010366,    eval_acc=0.479073\n",
      "epoch:  18,    lr=0.000711,    loss=0.405511,    train_acc=0.838652,    eval_loss=2.133714,    eval_acc=0.482832\n",
      "epoch:  19,    lr=0.000689,    loss=0.346288,    train_acc=0.863715,    eval_loss=2.567865,    eval_acc=0.468526\n",
      "epoch:  20,    lr=0.000667,    loss=0.289411,    train_acc=0.887134,    eval_loss=2.753752,    eval_acc=0.476268\n",
      "Test accuray: 0.54788\n",
      "epoch:  21,    lr=0.000644,    loss=0.249782,    train_acc=0.903267,    eval_loss=2.827174,    eval_acc=0.476212\n",
      "epoch:  22,    lr=0.000622,    loss=0.209598,    train_acc=0.919503,    eval_loss=3.096464,    eval_acc=0.465777\n",
      "epoch:  23,    lr=0.000600,    loss=0.177252,    train_acc=0.933086,    eval_loss=3.262520,    eval_acc=0.482944\n",
      "epoch:  24,    lr=0.000578,    loss=0.155338,    train_acc=0.941247,    eval_loss=3.317325,    eval_acc=0.482776\n",
      "epoch:  25,    lr=0.000556,    loss=0.130566,    train_acc=0.951939,    eval_loss=3.711441,    eval_acc=0.489565\n",
      "Test accuray: 0.55679\n",
      "epoch:  26,    lr=0.000533,    loss=0.112312,    train_acc=0.958022,    eval_loss=4.035261,    eval_acc=0.464430\n",
      "epoch:  27,    lr=0.000511,    loss=0.100363,    train_acc=0.963572,    eval_loss=4.098820,    eval_acc=0.484010\n",
      "epoch:  28,    lr=0.000489,    loss=0.087614,    train_acc=0.968799,    eval_loss=4.295680,    eval_acc=0.468582\n",
      "epoch:  29,    lr=0.000467,    loss=0.074811,    train_acc=0.973188,    eval_loss=4.515354,    eval_acc=0.472846\n",
      "epoch:  30,    lr=0.000444,    loss=0.061669,    train_acc=0.977822,    eval_loss=4.530226,    eval_acc=0.484515\n",
      "Test accuray: 0.56347\n",
      "epoch:  31,    lr=0.000422,    loss=0.058669,    train_acc=0.979332,    eval_loss=4.577366,    eval_acc=0.472116\n",
      "epoch:  32,    lr=0.000400,    loss=0.051472,    train_acc=0.981789,    eval_loss=4.784826,    eval_acc=0.489621\n",
      "epoch:  33,    lr=0.000378,    loss=0.043889,    train_acc=0.984870,    eval_loss=5.098659,    eval_acc=0.480251\n",
      "epoch:  34,    lr=0.000356,    loss=0.040736,    train_acc=0.985653,    eval_loss=5.050720,    eval_acc=0.470545\n",
      "epoch:  35,    lr=0.000333,    loss=0.035122,    train_acc=0.988018,    eval_loss=5.416879,    eval_acc=0.479915\n",
      "Test accuray: 0.57016\n",
      "epoch:  36,    lr=0.000311,    loss=0.029428,    train_acc=0.989681,    eval_loss=5.454070,    eval_acc=0.467796\n",
      "epoch:  37,    lr=0.000289,    loss=0.027333,    train_acc=0.991014,    eval_loss=5.553371,    eval_acc=0.474473\n",
      "epoch:  38,    lr=0.000267,    loss=0.023732,    train_acc=0.992151,    eval_loss=5.485531,    eval_acc=0.485020\n",
      "epoch:  39,    lr=0.000244,    loss=0.019301,    train_acc=0.993649,    eval_loss=5.660133,    eval_acc=0.485020\n",
      "epoch:  40,    lr=0.000222,    loss=0.018108,    train_acc=0.994199,    eval_loss=5.980266,    eval_acc=0.483562\n",
      "Test accuray: 0.56125\n",
      "epoch:  41,    lr=0.000200,    loss=0.016704,    train_acc=0.994468,    eval_loss=5.903028,    eval_acc=0.473687\n",
      "epoch:  42,    lr=0.000178,    loss=0.012771,    train_acc=0.995764,    eval_loss=5.925663,    eval_acc=0.485974\n",
      "epoch:  43,    lr=0.000156,    loss=0.012137,    train_acc=0.995935,    eval_loss=5.975310,    eval_acc=0.479466\n",
      "epoch:  44,    lr=0.000133,    loss=0.009411,    train_acc=0.997060,    eval_loss=6.188796,    eval_acc=0.481149\n",
      "epoch:  45,    lr=0.000111,    loss=0.008381,    train_acc=0.997439,    eval_loss=6.288783,    eval_acc=0.483730\n",
      "Test accuray: 0.57238\n",
      "epoch:  46,    lr=0.000089,    loss=0.006601,    train_acc=0.998105,    eval_loss=6.284329,    eval_acc=0.486816\n",
      "epoch:  47,    lr=0.000067,    loss=0.005544,    train_acc=0.998368,    eval_loss=6.496351,    eval_acc=0.480588\n",
      "epoch:  48,    lr=0.000044,    loss=0.004474,    train_acc=0.998857,    eval_loss=6.413272,    eval_acc=0.482664\n",
      "epoch:  49,    lr=0.000022,    loss=0.003836,    train_acc=0.998967,    eval_loss=6.592639,    eval_acc=0.482271\n",
      "epoch:  50,    lr=0.000000,    loss=0.003388,    train_acc=0.999114,    eval_loss=6.680468,    eval_acc=0.480139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [00:00, 127.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuray: 0.57461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4041it [00:29, 137.44it/s]\n",
      "449it [00:02, 160.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "epoch:   1,    lr=0.000200,    loss=1.129147,    train_acc=0.500917,    eval_loss=1.048761,    eval_acc=0.542522\n",
      "epoch:   2,    lr=0.000400,    loss=0.990143,    train_acc=0.591836,    eval_loss=0.998643,    eval_acc=0.586577\n",
      "epoch:   3,    lr=0.000600,    loss=0.948823,    train_acc=0.612856,    eval_loss=1.007501,    eval_acc=0.586046\n",
      "epoch:   4,    lr=0.000800,    loss=0.919298,    train_acc=0.627770,    eval_loss=0.960853,    eval_acc=0.617363\n",
      "epoch:   5,    lr=0.001000,    loss=0.899950,    train_acc=0.636294,    eval_loss=0.987752,    eval_acc=0.598726\n",
      "Test accuray: 0.64588\n",
      "epoch:   6,    lr=0.000978,    loss=0.883561,    train_acc=0.645655,    eval_loss=0.972180,    eval_acc=0.604270\n",
      "epoch:   7,    lr=0.000956,    loss=0.869533,    train_acc=0.651250,    eval_loss=1.003222,    eval_acc=0.589290\n",
      "epoch:   8,    lr=0.000933,    loss=0.854317,    train_acc=0.657398,    eval_loss=1.054475,    eval_acc=0.581623\n",
      "epoch:   9,    lr=0.000911,    loss=0.842359,    train_acc=0.661590,    eval_loss=1.014132,    eval_acc=0.590057\n",
      "epoch:  10,    lr=0.000889,    loss=0.824777,    train_acc=0.669573,    eval_loss=1.013404,    eval_acc=0.586872\n",
      "Test accuray: 0.63474\n",
      "epoch:  11,    lr=0.000867,    loss=0.805611,    train_acc=0.676340,    eval_loss=1.043234,    eval_acc=0.594244\n",
      "epoch:  12,    lr=0.000844,    loss=0.778061,    train_acc=0.686577,    eval_loss=1.037324,    eval_acc=0.589231\n",
      "epoch:  13,    lr=0.000822,    loss=0.734746,    train_acc=0.705136,    eval_loss=1.099330,    eval_acc=0.571302\n",
      "epoch:  14,    lr=0.000800,    loss=0.679337,    train_acc=0.726799,    eval_loss=1.206311,    eval_acc=0.560510\n",
      "epoch:  15,    lr=0.000778,    loss=0.609732,    train_acc=0.756081,    eval_loss=1.268907,    eval_acc=0.560333\n",
      "Test accuray: 0.63474\n",
      "epoch:  16,    lr=0.000756,    loss=0.540499,    train_acc=0.784707,    eval_loss=1.410331,    eval_acc=0.544409\n",
      "epoch:  17,    lr=0.000733,    loss=0.468379,    train_acc=0.814511,    eval_loss=1.607234,    eval_acc=0.546827\n",
      "epoch:  18,    lr=0.000711,    loss=0.401290,    train_acc=0.841739,    eval_loss=1.706355,    eval_acc=0.536801\n",
      "epoch:  19,    lr=0.000689,    loss=0.343981,    train_acc=0.865614,    eval_loss=1.806963,    eval_acc=0.541283\n",
      "epoch:  20,    lr=0.000667,    loss=0.292441,    train_acc=0.885091,    eval_loss=2.187859,    eval_acc=0.508375\n",
      "Test accuray: 0.59243\n",
      "epoch:  21,    lr=0.000644,    loss=0.247441,    train_acc=0.904027,    eval_loss=2.386561,    eval_acc=0.530491\n",
      "epoch:  22,    lr=0.000622,    loss=0.211946,    train_acc=0.918661,    eval_loss=2.429248,    eval_acc=0.532142\n",
      "epoch:  23,    lr=0.000600,    loss=0.182832,    train_acc=0.930222,    eval_loss=2.772908,    eval_acc=0.526067\n",
      "epoch:  24,    lr=0.000578,    loss=0.155511,    train_acc=0.940689,    eval_loss=2.886943,    eval_acc=0.532968\n",
      "epoch:  25,    lr=0.000556,    loss=0.132669,    train_acc=0.950270,    eval_loss=2.927989,    eval_acc=0.520524\n",
      "Test accuray: 0.62361\n",
      "epoch:  26,    lr=0.000533,    loss=0.117152,    train_acc=0.956849,    eval_loss=3.253343,    eval_acc=0.530078\n",
      "epoch:  27,    lr=0.000511,    loss=0.102315,    train_acc=0.962638,    eval_loss=3.341328,    eval_acc=0.522352\n",
      "epoch:  28,    lr=0.000489,    loss=0.085953,    train_acc=0.968173,    eval_loss=3.617585,    eval_acc=0.516513\n",
      "epoch:  29,    lr=0.000467,    loss=0.077722,    train_acc=0.972553,    eval_loss=3.644995,    eval_acc=0.521998\n",
      "epoch:  30,    lr=0.000444,    loss=0.065971,    train_acc=0.976654,    eval_loss=3.867644,    eval_acc=0.525360\n",
      "Test accuray: 0.60802\n",
      "epoch:  31,    lr=0.000422,    loss=0.058726,    train_acc=0.979217,    eval_loss=3.853455,    eval_acc=0.526244\n",
      "epoch:  32,    lr=0.000400,    loss=0.050886,    train_acc=0.982237,    eval_loss=3.975243,    eval_acc=0.527247\n",
      "epoch:  33,    lr=0.000378,    loss=0.044767,    train_acc=0.983986,    eval_loss=3.999855,    eval_acc=0.534029\n",
      "epoch:  34,    lr=0.000356,    loss=0.041084,    train_acc=0.985967,    eval_loss=4.082426,    eval_acc=0.529370\n",
      "epoch:  35,    lr=0.000333,    loss=0.033008,    train_acc=0.988749,    eval_loss=4.390287,    eval_acc=0.519049\n",
      "Test accuray: 0.6147\n",
      "epoch:  36,    lr=0.000311,    loss=0.031528,    train_acc=0.989454,    eval_loss=4.437626,    eval_acc=0.521055\n",
      "epoch:  37,    lr=0.000289,    loss=0.028397,    train_acc=0.990310,    eval_loss=4.558421,    eval_acc=0.530137\n",
      "epoch:  38,    lr=0.000267,    loss=0.023558,    train_acc=0.992109,    eval_loss=4.672902,    eval_acc=0.527247\n",
      "epoch:  39,    lr=0.000244,    loss=0.021547,    train_acc=0.992971,    eval_loss=4.754159,    eval_acc=0.522942\n",
      "epoch:  40,    lr=0.000222,    loss=0.018092,    train_acc=0.994095,    eval_loss=5.023482,    eval_acc=0.528073\n",
      "Test accuray: 0.61915\n",
      "epoch:  41,    lr=0.000200,    loss=0.016069,    train_acc=0.994739,    eval_loss=5.005848,    eval_acc=0.539219\n",
      "epoch:  42,    lr=0.000178,    loss=0.014691,    train_acc=0.995164,    eval_loss=5.106787,    eval_acc=0.529724\n",
      "epoch:  43,    lr=0.000156,    loss=0.010588,    train_acc=0.996744,    eval_loss=5.217107,    eval_acc=0.530373\n",
      "epoch:  44,    lr=0.000133,    loss=0.010184,    train_acc=0.997060,    eval_loss=5.280457,    eval_acc=0.532968\n",
      "epoch:  45,    lr=0.000111,    loss=0.007513,    train_acc=0.997819,    eval_loss=5.399492,    eval_acc=0.528368\n",
      "Test accuray: 0.61693\n",
      "epoch:  46,    lr=0.000089,    loss=0.007018,    train_acc=0.997977,    eval_loss=5.353961,    eval_acc=0.530078\n",
      "epoch:  47,    lr=0.000067,    loss=0.005452,    train_acc=0.998481,    eval_loss=5.559249,    eval_acc=0.535150\n",
      "epoch:  48,    lr=0.000044,    loss=0.004485,    train_acc=0.998834,    eval_loss=5.545628,    eval_acc=0.533439\n",
      "epoch:  49,    lr=0.000022,    loss=0.003653,    train_acc=0.999071,    eval_loss=5.715155,    eval_acc=0.534029\n",
      "epoch:  50,    lr=0.000000,    loss=0.003376,    train_acc=0.999137,    eval_loss=5.623545,    eval_acc=0.534265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [00:00, 175.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuray: 0.61024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4041it [00:26, 152.21it/s]\n",
      "449it [00:02, 161.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "epoch:   1,    lr=0.000200,    loss=1.125520,    train_acc=0.500184,    eval_loss=1.126347,    eval_acc=0.528246\n",
      "epoch:   2,    lr=0.000400,    loss=0.989149,    train_acc=0.594161,    eval_loss=1.145453,    eval_acc=0.553721\n",
      "epoch:   3,    lr=0.000600,    loss=0.942636,    train_acc=0.618543,    eval_loss=1.076926,    eval_acc=0.560239\n",
      "epoch:   4,    lr=0.000800,    loss=0.914368,    train_acc=0.632996,    eval_loss=1.045484,    eval_acc=0.565345\n",
      "epoch:   5,    lr=0.001000,    loss=0.891412,    train_acc=0.645114,    eval_loss=1.101681,    eval_acc=0.555894\n",
      "Test accuray: 0.63697\n",
      "epoch:   6,    lr=0.000978,    loss=0.875303,    train_acc=0.652442,    eval_loss=1.284294,    eval_acc=0.504834\n",
      "epoch:   7,    lr=0.000956,    loss=0.859439,    train_acc=0.658648,    eval_loss=1.131919,    eval_acc=0.558501\n",
      "epoch:   8,    lr=0.000933,    loss=0.844609,    train_acc=0.665835,    eval_loss=1.104000,    eval_acc=0.566105\n",
      "epoch:   9,    lr=0.000911,    loss=0.831736,    train_acc=0.669845,    eval_loss=1.099026,    eval_acc=0.562955\n",
      "epoch:  10,    lr=0.000889,    loss=0.813466,    train_acc=0.678026,    eval_loss=1.214156,    eval_acc=0.543455\n",
      "Test accuray: 0.65033\n",
      "epoch:  11,    lr=0.000867,    loss=0.792504,    train_acc=0.685366,    eval_loss=1.236485,    eval_acc=0.541391\n",
      "epoch:  12,    lr=0.000844,    loss=0.760868,    train_acc=0.698734,    eval_loss=1.316275,    eval_acc=0.535144\n",
      "epoch:  13,    lr=0.000822,    loss=0.717861,    train_acc=0.715285,    eval_loss=1.280928,    eval_acc=0.539598\n",
      "epoch:  14,    lr=0.000800,    loss=0.659217,    train_acc=0.739054,    eval_loss=1.414021,    eval_acc=0.537534\n",
      "epoch:  15,    lr=0.000778,    loss=0.590508,    train_acc=0.766306,    eval_loss=1.610396,    eval_acc=0.519555\n",
      "Test accuray: 0.64365\n",
      "epoch:  16,    lr=0.000756,    loss=0.519630,    train_acc=0.794949,    eval_loss=1.745362,    eval_acc=0.534818\n",
      "epoch:  17,    lr=0.000733,    loss=0.456606,    train_acc=0.819571,    eval_loss=1.852815,    eval_acc=0.527159\n",
      "epoch:  18,    lr=0.000711,    loss=0.394458,    train_acc=0.843695,    eval_loss=2.062133,    eval_acc=0.521619\n",
      "epoch:  19,    lr=0.000689,    loss=0.339268,    train_acc=0.866899,    eval_loss=2.386708,    eval_acc=0.525312\n",
      "epoch:  20,    lr=0.000667,    loss=0.292922,    train_acc=0.885216,    eval_loss=2.616531,    eval_acc=0.521564\n",
      "Test accuray: 0.65033\n",
      "epoch:  21,    lr=0.000644,    loss=0.247888,    train_acc=0.903374,    eval_loss=2.794232,    eval_acc=0.498045\n",
      "epoch:  22,    lr=0.000622,    loss=0.215934,    train_acc=0.916374,    eval_loss=3.009795,    eval_acc=0.499511\n",
      "epoch:  23,    lr=0.000600,    loss=0.187118,    train_acc=0.928148,    eval_loss=3.158764,    eval_acc=0.508202\n",
      "epoch:  24,    lr=0.000578,    loss=0.163715,    train_acc=0.937206,    eval_loss=3.342313,    eval_acc=0.511896\n",
      "epoch:  25,    lr=0.000556,    loss=0.136756,    train_acc=0.948231,    eval_loss=3.617567,    eval_acc=0.499728\n",
      "Test accuray: 0.63252\n",
      "epoch:  26,    lr=0.000533,    loss=0.120095,    train_acc=0.955676,    eval_loss=3.745452,    eval_acc=0.504671\n",
      "epoch:  27,    lr=0.000511,    loss=0.101620,    train_acc=0.962655,    eval_loss=3.751959,    eval_acc=0.504400\n",
      "epoch:  28,    lr=0.000489,    loss=0.088385,    train_acc=0.967750,    eval_loss=4.012305,    eval_acc=0.514938\n",
      "epoch:  29,    lr=0.000467,    loss=0.077573,    train_acc=0.971779,    eval_loss=4.207428,    eval_acc=0.497610\n",
      "epoch:  30,    lr=0.000444,    loss=0.071342,    train_acc=0.974612,    eval_loss=4.161952,    eval_acc=0.501304\n",
      "Test accuray: 0.62584\n",
      "epoch:  31,    lr=0.000422,    loss=0.057368,    train_acc=0.979451,    eval_loss=4.523422,    eval_acc=0.508365\n",
      "epoch:  32,    lr=0.000400,    loss=0.053064,    train_acc=0.981413,    eval_loss=4.530381,    eval_acc=0.507279\n",
      "epoch:  33,    lr=0.000378,    loss=0.044338,    train_acc=0.984504,    eval_loss=4.853621,    eval_acc=0.502770\n",
      "epoch:  34,    lr=0.000356,    loss=0.042043,    train_acc=0.985467,    eval_loss=4.769717,    eval_acc=0.517002\n",
      "epoch:  35,    lr=0.000333,    loss=0.035750,    train_acc=0.987827,    eval_loss=4.952146,    eval_acc=0.505703\n",
      "Test accuray: 0.62806\n",
      "epoch:  36,    lr=0.000311,    loss=0.030106,    train_acc=0.989845,    eval_loss=5.080839,    eval_acc=0.506355\n",
      "epoch:  37,    lr=0.000289,    loss=0.027177,    train_acc=0.990912,    eval_loss=5.266298,    eval_acc=0.514231\n",
      "epoch:  38,    lr=0.000267,    loss=0.022717,    train_acc=0.992040,    eval_loss=5.358213,    eval_acc=0.512493\n",
      "epoch:  39,    lr=0.000244,    loss=0.021614,    train_acc=0.993021,    eval_loss=5.563715,    eval_acc=0.514938\n",
      "epoch:  40,    lr=0.000222,    loss=0.016909,    train_acc=0.994432,    eval_loss=5.650099,    eval_acc=0.504400\n",
      "Test accuray: 0.6392\n",
      "epoch:  41,    lr=0.000200,    loss=0.014673,    train_acc=0.995340,    eval_loss=5.649903,    eval_acc=0.514340\n",
      "epoch:  42,    lr=0.000178,    loss=0.013194,    train_acc=0.995842,    eval_loss=5.721357,    eval_acc=0.507985\n",
      "epoch:  43,    lr=0.000156,    loss=0.009903,    train_acc=0.996866,    eval_loss=5.757128,    eval_acc=0.512113\n",
      "epoch:  44,    lr=0.000133,    loss=0.010228,    train_acc=0.996873,    eval_loss=6.007143,    eval_acc=0.503476\n",
      "epoch:  45,    lr=0.000111,    loss=0.007739,    train_acc=0.997725,    eval_loss=6.078851,    eval_acc=0.508256\n",
      "Test accuray: 0.63697\n",
      "epoch:  46,    lr=0.000089,    loss=0.005852,    train_acc=0.998301,    eval_loss=6.158581,    eval_acc=0.513743\n",
      "epoch:  47,    lr=0.000067,    loss=0.005357,    train_acc=0.998430,    eval_loss=6.197421,    eval_acc=0.514775\n",
      "epoch:  48,    lr=0.000044,    loss=0.003622,    train_acc=0.999240,    eval_loss=6.247822,    eval_acc=0.514557\n",
      "epoch:  49,    lr=0.000022,    loss=0.003395,    train_acc=0.999154,    eval_loss=6.318490,    eval_acc=0.509397\n",
      "epoch:  50,    lr=0.000000,    loss=0.003091,    train_acc=0.999227,    eval_loss=6.356540,    eval_acc=0.511678\n",
      "Test accuray: 0.6392\n",
      "conv_dim: 1d \twith_focus_attn: False\n",
      "Test accuray: [0.6080178173719376, 0.6347438752783965, 0.6191536748329621, 0.6815144766146993, 0.6035634743875279, 0.5835189309576837, 0.5902004454342984, 0.5746102449888641, 0.6458797327394209, 0.6503340757238307]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for with_focus_attn in focus_attn_list:\n",
    "    cv_eval = []\n",
    "    #with_focus_attn = True if(with_focus_attn == 'true') else False\n",
    "    for train_index, eval_index in skf.split(df['sample_name'], df['sample_label']):\n",
    "        conv_dim = '1d'\n",
    "        checkpoint = ''\n",
    "        hidden_size = 128\n",
    "        num_layers = 2\n",
    "        bidirectional = 'true'\n",
    "\n",
    "        batch_size = 256\n",
    "        num_epochs = 50\n",
    "        learning_rate = 0.001\n",
    "\n",
    "        use_warmup = 'true'\n",
    "        data_dir = './wav_data/pretrain/IEMOCAP_sub/'\n",
    "        multi_task = 'false'\n",
    "        augmentation = 'false'\n",
    "        \n",
    "        save_checkpoint_steps = 5\n",
    "        output_dir = './model'\n",
    "\n",
    "        bidirectional = True if(bidirectional == 'true') else False   \n",
    "        n_mfcc = 40 if(conv_dim == '1d') else 128\n",
    "\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        train_samples, eval_samples = df['sample_name'][train_index], df['sample_name'][eval_index]\n",
    "        train_label, eval_label = df['sample_label'][train_index], df['sample_label'][eval_index]\n",
    "        \n",
    "        train_samples = [data_dir + train_sample + '.wav' for train_sample in train_samples]\n",
    "        eval_samples = [data_dir + eval_sample + '.wav' for eval_sample in eval_samples]\n",
    "\n",
    "        y_train = np.array(train_label)\n",
    "        y_eval = np.array(eval_label)\n",
    "\n",
    "        if(multi_task == 'true'):\n",
    "            speaker = np.array(list(map(lambda x: int(x.split('/')[-1].split('-')[-1].split('.')[0]), sample_datas)))\n",
    "            y_gender = np.array(list(map(lambda x: 1 if x % 2 ==0 else 0, speaker)))\n",
    "\n",
    "            y_g_train = y_gender[train_idx]\n",
    "            y_g_eval = y_gender[eval_idx]\n",
    "\n",
    "        X_train, y_train = convert_spectrograms(train_samples, conv_dim=conv_dim, sr=16000, labels=y_train)\n",
    "        X_eval, y_eval = convert_spectrograms(eval_samples, conv_dim=conv_dim, sr=16000, labels=y_eval)\n",
    "\n",
    "        if(augmentation == 'true'):\n",
    "            X_train_flip = X_train[:, :, :, ::-1]\n",
    "            y_train_flip = y_train.copy()\n",
    "\n",
    "            X_train = np.concatenate((X_train, X_train_flip), axis=0)\n",
    "            y_train = np.concatenate((y_train, y_train_flip), axis=0)\n",
    "\n",
    "        X_train, y_train = convert_tensor(X_train, y_train)\n",
    "        X_eval, y_eval = convert_tensor(X_eval, y_eval)\n",
    "\n",
    "        y_train = y_train.long()\n",
    "        y_eval = y_eval.long()\n",
    "\n",
    "        if(multi_task == 'true'):\n",
    "            _, y_g_train = convert_spectrograms(train_samples, conv_dim=conv_dim, sr=16000, labels=y_g_train)\n",
    "            _, y_g_eval = convert_spectrograms(eval_samples, conv_dim=conv_dim, sr=16000, labels=y_g_eval)\n",
    "\n",
    "            if(augmentation == 'true'):\n",
    "                y_g_train_flip = y_g_train.copy()\n",
    "                y_g_train = np.concatenate((y_g_train, y_g_train_flip))\n",
    "\n",
    "            y_g_train = torch.tensor(y_g_train).float()\n",
    "            y_g_eval = torch.tensor(y_g_eval).float()\n",
    "\n",
    "            y_g_train = y_g_train.unsqueeze(-1)\n",
    "            y_g_eval = y_g_eval.unsqueeze(-1)\n",
    "\n",
    "        if(multi_task == 'true'):\n",
    "            train_ds = TensorDataset(X_train, y_train, y_g_train)\n",
    "            eval_ds = TensorDataset(X_eval, y_eval, y_g_eval)\n",
    "        else:\n",
    "            train_ds = TensorDataset(X_train, y_train)\n",
    "            eval_ds = TensorDataset(X_eval, y_eval)\n",
    "\n",
    "        train_dataloader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=0, drop_last=True)\n",
    "        eval_dataloader = DataLoader(eval_ds, batch_size=batch_size, num_workers=0)\n",
    "\n",
    "        model = CLDNN(conv_dim=conv_dim, checkpoint=checkpoint, hidden_size=hidden_size,\n",
    "                      num_layers=num_layers, bidirectional=bidirectional,\n",
    "                      with_focus_attn=with_focus_attn).to(device)\n",
    "\n",
    "        if(multi_task == 'true'):\n",
    "            model_g = CLDNN_G(conv_dim=conv_dim, checkpoint=checkpoint, hidden_size=hidden_size,\n",
    "                                num_layers=num_layers, bidirectional=bidirectional,\n",
    "                                with_focus_attn=with_focus_attn).to(device)\n",
    "\n",
    "        if(multi_task == 'true'):\n",
    "            loss_func = nn.CrossEntropyLoss()\n",
    "            loss_func_g = nn.BCELoss()\n",
    "            optimizer = optim.Adam(list(model.parameters()) + list(model_g.parameters()), lr=learning_rate)\n",
    "        else:\n",
    "            loss_func = nn.CrossEntropyLoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        if(use_warmup == 'true'):\n",
    "            t_total = len(train_dataloader) // 1 * num_epochs\n",
    "            opt_scheduler = WarmupLinearSchedule(optimizer, warmup_steps=t_total * 0.1, t_total=t_total)\n",
    "\n",
    "        eval_acc = train(train_dataloader, eval_dataloader, num_epochs)\n",
    "        cv_eval.append(eval_acc)\n",
    "\n",
    "    print('conv_dim:', conv_dim, '\\twith_focus_attn:', with_focus_attn)\n",
    "    print('Test accuray:', cv_eval)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_focus_attn = [0.6146993318485523, 0.6035634743875279, 0.6169265033407573, \n",
    "                   0.6948775055679287, 0.6169265033407573, 0.5991091314031181, \n",
    "                   0.5946547884187082, 0.6080178173719376, 0.6391982182628062, 0.6592427616926503]\n",
    "without_focus_attn = [0.6080178173719376, 0.6347438752783965, 0.6191536748329621, \n",
    "                      0.6815144766146993, 0.6035634743875279, 0.5835189309576837, \n",
    "                      0.5902004454342984, 0.5746102449888641, 0.6458797327394209, 0.6503340757238307]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with_focus_attn: 0.6247216035634744\n",
      "without_focus_attn: 0.6191536748329621\n"
     ]
    }
   ],
   "source": [
    "print('with_focus_attn:', sum(with_focus_attn) / 10)\n",
    "print('without_focus_attn:', sum(without_focus_attn) / 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.70824"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_focus_attn = [0.6414253897550112, 0.6280623608017817, 0.6169265033407573, \n",
    "                   0.6904231625835189, 0.6325167037861915, 0.6458797327394209, \n",
    "                   0.6035634743875279, 0.5991091314031181, 0.6614699331848553, 0.6503340757238307]\n",
    "\n",
    "without_focus_attn = [0.6191536748329621, 0.6080178173719376, 0.6347438752783965, \n",
    "                      0.6859688195991092, 0.6302895322939867, 0.6057906458797327, \n",
    "                      0.6035634743875279, 0.6102449888641426, 0.6592427616926503, 0.6525612472160356]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with_focus_attn: 0.6369710467706013\n",
      "without_focus_attn: 0.6309576837416481\n"
     ]
    }
   ],
   "source": [
    "print('with_focus_attn:', sum(with_focus_attn) / 10)\n",
    "print('without_focus_attn:', sum(without_focus_attn) / 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4041it [00:25, 158.41it/s]\n",
      "449it [00:03, 146.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n",
      "glo torch.Size([256, 1, 8])\n",
      "c_1 torch.Size([256, 50, 8])\n",
      "c_2 torch.Size([256, 4, 50, 2])\n",
      "up torch.Size([4, 1, 2])\n",
      "p torch.Size([256, 4, 50, 2])\n",
      "uz torch.Size([4, 1, 2])\n",
      "z torch.Size([256, 4, 50, 2])\n",
      "P torch.Size([256, 4, 50])\n",
      "Z torch.Size([256, 4, 50])\n",
      "j torch.Size([1, 1, 1, 50])\n",
      "G torch.Size([256, 4, 50, 50])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-10218bca7db8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mopt_scheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWarmupLinearSchedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarmup_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt_total\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_total\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt_total\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0meval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0mcv_eval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-5cc40949aeb3>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_dataloader, eval_dataloader, epochs)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for with_focus_attn in focus_attn_list:\n",
    "    cv_eval = []\n",
    "    #with_focus_attn = True if(with_focus_attn == 'true') else False\n",
    "    for train_index, eval_index in skf.split(df['sample_name'], df['sample_label']):\n",
    "        conv_dim = '1d'\n",
    "        checkpoint = ''\n",
    "        hidden_size = 128\n",
    "        num_layers = 2\n",
    "        bidirectional = 'true'\n",
    "\n",
    "        batch_size = 256\n",
    "        num_epochs = 50\n",
    "        learning_rate = 0.001\n",
    "\n",
    "        use_warmup = 'true'\n",
    "        data_dir = './wav_data/pretrain/IEMOCAP_sub/'\n",
    "        multi_task = 'false'\n",
    "        augmentation = 'false'\n",
    "        \n",
    "        save_checkpoint_steps = 5\n",
    "        output_dir = './model'\n",
    "        \n",
    "        bidirectional = True if(bidirectional == 'true') else False\n",
    "        n_mfcc = 40 if(conv_dim == '1d') else 128\n",
    "\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        train_samples, eval_samples = df['sample_name'][train_index], df['sample_name'][eval_index]\n",
    "        train_label, eval_label = df['sample_label'][train_index], df['sample_label'][eval_index]\n",
    "        \n",
    "        train_samples = [data_dir + train_sample + '.wav' for train_sample in train_samples]\n",
    "        eval_samples = [data_dir + eval_sample + '.wav' for eval_sample in eval_samples]\n",
    "\n",
    "        y_train = np.array(train_label)\n",
    "        y_eval = np.array(eval_label)\n",
    "\n",
    "        if(multi_task == 'true'):\n",
    "            speaker = np.array(list(map(lambda x: int(x.split('/')[-1].split('-')[-1].split('.')[0]), sample_datas)))\n",
    "            y_gender = np.array(list(map(lambda x: 1 if x % 2 ==0 else 0, speaker)))\n",
    "\n",
    "            y_g_train = y_gender[train_idx]\n",
    "            y_g_eval = y_gender[eval_idx]\n",
    "\n",
    "        X_train, y_train = convert_spectrograms(train_samples, conv_dim=conv_dim, sr=16000, labels=y_train)\n",
    "        X_eval, y_eval = convert_spectrograms(eval_samples, conv_dim=conv_dim, sr=16000, labels=y_eval)\n",
    "\n",
    "        if(augmentation == 'true'):\n",
    "            X_train_flip = X_train[:, :, :, ::-1]\n",
    "            y_train_flip = y_train.copy()\n",
    "\n",
    "            X_train = np.concatenate((X_train, X_train_flip), axis=0)\n",
    "            y_train = np.concatenate((y_train, y_train_flip), axis=0)\n",
    "\n",
    "        X_train, y_train = convert_tensor(X_train, y_train)\n",
    "        X_eval, y_eval = convert_tensor(X_eval, y_eval)\n",
    "\n",
    "        y_train = y_train.long()\n",
    "        y_eval = y_eval.long()\n",
    "\n",
    "        if(multi_task == 'true'):\n",
    "            _, y_g_train = convert_spectrograms(train_samples, conv_dim=conv_dim, sr=16000, labels=y_g_train)\n",
    "            _, y_g_eval = convert_spectrograms(eval_samples, conv_dim=conv_dim, sr=16000, labels=y_g_eval)\n",
    "\n",
    "            if(augmentation == 'true'):\n",
    "                y_g_train_flip = y_g_train.copy()\n",
    "                y_g_train = np.concatenate((y_g_train, y_g_train_flip))\n",
    "\n",
    "            y_g_train = torch.tensor(y_g_train).float()\n",
    "            y_g_eval = torch.tensor(y_g_eval).float()\n",
    "\n",
    "            y_g_train = y_g_train.unsqueeze(-1)\n",
    "            y_g_eval = y_g_eval.unsqueeze(-1)\n",
    "\n",
    "        if(multi_task == 'true'):\n",
    "            train_ds = TensorDataset(X_train, y_train, y_g_train)\n",
    "            eval_ds = TensorDataset(X_eval, y_eval, y_g_eval)\n",
    "        else:\n",
    "            train_ds = TensorDataset(X_train, y_train)\n",
    "            eval_ds = TensorDataset(X_eval, y_eval)\n",
    "\n",
    "        train_dataloader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=0, drop_last=True)\n",
    "        eval_dataloader = DataLoader(eval_ds, batch_size=batch_size, num_workers=0)\n",
    "\n",
    "        model = CLDNN(conv_dim=conv_dim, checkpoint=checkpoint, hidden_size=hidden_size,\n",
    "                      num_layers=num_layers, bidirectional=bidirectional,\n",
    "                      with_focus_attn=with_focus_attn).to(device)\n",
    "\n",
    "        if(multi_task == 'true'):\n",
    "            model_g = CLDNN_G(conv_dim=conv_dim, checkpoint=checkpoint, hidden_size=hidden_size,\n",
    "                                num_layers=num_layers, bidirectional=bidirectional,\n",
    "                                with_focus_attn=with_focus_attn).to(device)\n",
    "\n",
    "        if(multi_task == 'true'):\n",
    "            loss_func = nn.CrossEntropyLoss()\n",
    "            loss_func_g = nn.BCELoss()\n",
    "            optimizer = optim.Adam(list(model.parameters()) + list(model_g.parameters()), lr=learning_rate)\n",
    "        else:\n",
    "            loss_func = nn.CrossEntropyLoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        if(use_warmup == 'true'):\n",
    "            t_total = len(train_dataloader) // 1 * num_epochs\n",
    "            opt_scheduler = WarmupLinearSchedule(optimizer, warmup_steps=t_total * 0.1, t_total=t_total)\n",
    "\n",
    "        eval_acc = train(train_dataloader, eval_dataloader, num_epochs)\n",
    "        cv_eval.append(eval_acc)\n",
    "\n",
    "    print('conv_dim:', conv_dim, '\\twith_focus_attn:', with_focus_attn)\n",
    "    print('Test accuray:', cv_eval)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_focus_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for with_focus_attn in focus_attn_list:\n",
    "    print(with_focus_attn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# window_size 25ms, hop_size 10ms\n",
    "for conv_dim in conv_dim_list:\n",
    "    for augmentation in augmentation_list:\n",
    "        for with_focus_attn in focus_attn_list:\n",
    "            for multi_task in multi_task_list:\n",
    "                #conv_dim = '1d'\n",
    "                checkpoint = './output/aae_' + conv_dim + '_step_500.pt'\n",
    "                hidden_size = 128\n",
    "                num_layers = 2\n",
    "                bidirectional = 'true'\n",
    "                #with_focus_attn = 'false'\n",
    "\n",
    "                batch_size = 128\n",
    "                num_epochs = 300\n",
    "                learning_rate = 0.0001\n",
    "\n",
    "                use_warmup = 'true'\n",
    "                data_dir = './wav_data/pretrain/RAVDESS_resample/'\n",
    "                #multi_task = 'false'\n",
    "                #augmentation = 'true'\n",
    "\n",
    "                bidirectional = True if(bidirectional == 'true') else False\n",
    "                #with_focus_attn = True if(with_focus_attn == 'true') else False\n",
    "                n_mfcc = 40 if(conv_dim == '1d') else 128\n",
    "\n",
    "                device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "                sample_datas = glob.glob(os.path.join(data_dir, '**', '*wav'), recursive=True)\n",
    "                sample_datas = sorted(sample_datas)\n",
    "\n",
    "                acc_list = []\n",
    "                for i in range(5):\n",
    "                    np.random.seed(10 * i + 3)\n",
    "                    idx = np.random.permutation(len(sample_datas))\n",
    "                    train_idx = idx[:int(len(sample_datas)*0.75)]\n",
    "                    eval_idx = idx[int(len(sample_datas)*0.75):]\n",
    "\n",
    "                    train_samples = list(np.array(sample_datas)[train_idx])\n",
    "                    eval_samples = list(np.array(sample_datas)[eval_idx])\n",
    "\n",
    "                    y = np.array(list(map(lambda x: int(x.split('/')[-1].split('-')[2]) - 1, sample_datas)))\n",
    "                    y_train = y[train_idx]\n",
    "                    y_eval = y[eval_idx]\n",
    "\n",
    "                    if(multi_task == 'true'):\n",
    "                        speaker = np.array(list(map(lambda x: int(x.split('/')[-1].split('-')[-1].split('.')[0]), sample_datas)))\n",
    "                        y_gender = np.array(list(map(lambda x: 1 if x % 2 ==0 else 0, speaker)))\n",
    "\n",
    "                        y_g_train = y_gender[train_idx]\n",
    "                        y_g_eval = y_gender[eval_idx]\n",
    "\n",
    "                    X_train, y_train = convert_spectrograms(train_samples, conv_dim=conv_dim, sr=16000, labels=y_train)\n",
    "                    X_eval, y_eval = convert_spectrograms(eval_samples, conv_dim=conv_dim, sr=16000, labels=y_eval)\n",
    "\n",
    "                    if(augmentation == 'true'):\n",
    "                        X_train_flip = X_train[:, :, :, ::-1]\n",
    "                        y_train_flip = y_train.copy()\n",
    "\n",
    "                        X_train = np.concatenate((X_train, X_train_flip), axis=0)\n",
    "                        y_train = np.concatenate((y_train, y_train_flip), axis=0)\n",
    "                    \n",
    "                    X_train, y_train = convert_tensor(X_train, y_train)\n",
    "                    X_eval, y_eval = convert_tensor(X_eval, y_eval)\n",
    "\n",
    "                    y_train = y_train.long()\n",
    "                    y_eval = y_eval.long()\n",
    "\n",
    "                    if(multi_task == 'true'):\n",
    "                        _, y_g_train = convert_spectrograms(train_samples, conv_dim=conv_dim, sr=16000, labels=y_g_train)\n",
    "                        _, y_g_eval = convert_spectrograms(eval_samples, conv_dim=conv_dim, sr=16000, labels=y_g_eval)\n",
    "\n",
    "                        if(augmentation == 'true'):\n",
    "                            y_g_train_flip = y_g_train.copy()\n",
    "                            y_g_train = np.concatenate((y_g_train, y_g_train_flip))\n",
    "                        \n",
    "                        y_g_train = torch.tensor(y_g_train).float()\n",
    "                        y_g_eval = torch.tensor(y_g_eval).float()\n",
    "\n",
    "                        y_g_train = y_g_train.unsqueeze(-1)\n",
    "                        y_g_eval = y_g_eval.unsqueeze(-1)\n",
    "\n",
    "                    if(multi_task == 'true'):\n",
    "                        train_ds = TensorDataset(X_train, y_train, y_g_train)\n",
    "                        eval_ds = TensorDataset(X_eval, y_eval, y_g_eval)\n",
    "                    else:\n",
    "                        train_ds = TensorDataset(X_train, y_train)\n",
    "                        eval_ds = TensorDataset(X_eval, y_eval)\n",
    "\n",
    "                    train_dataloader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=0, drop_last=True)\n",
    "                    eval_dataloader = DataLoader(eval_ds, batch_size=batch_size, num_workers=0, drop_last=True)\n",
    "\n",
    "                    model = CLDNN(conv_dim=conv_dim, checkpoint=checkpoint, hidden_size=hidden_size,\n",
    "                                  num_layers=num_layers, bidirectional=bidirectional,\n",
    "                                  with_focus_attn=with_focus_attn).to(device)\n",
    "\n",
    "                    if(multi_task == 'true'):\n",
    "                        model_g = CLDNN_G(conv_dim=conv_dim, checkpoint=checkpoint, hidden_size=hidden_size,\n",
    "                                            num_layers=num_layers, bidirectional=bidirectional,\n",
    "                                            with_focus_attn=with_focus_attn).to(device)\n",
    "\n",
    "                    if(multi_task == 'true'):\n",
    "                        loss_func = nn.CrossEntropyLoss()\n",
    "                        loss_func_g = nn.BCELoss()\n",
    "                        optimizer = optim.Adam(list(model.parameters()) + list(model_g.parameters()), lr=learning_rate)\n",
    "                    else:\n",
    "                        loss_func = nn.CrossEntropyLoss()\n",
    "                        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "                    if(use_warmup == 'true'):\n",
    "                        t_total = len(train_dataloader) // 1 * num_epochs\n",
    "                        opt_scheduler = WarmupLinearSchedule(optimizer, warmup_steps=t_total * 0.1, t_total=t_total)\n",
    "\n",
    "                    train(train_dataloader, eval_dataloader, num_epochs)\n",
    "\n",
    "                    model.eval()\n",
    "                    if(multi_task == 'true'):\n",
    "                        model_g.eval()\n",
    "\n",
    "                    correct = 0\n",
    "                    n = 0\n",
    "                    for i in range(len(eval_samples)):\n",
    "                        try:\n",
    "                            X_new = preprocessing(eval_samples[i], method='mfcc', sr=16000, n_mfcc=n_mfcc)\n",
    "                            X_new = convert_tensor(X_new).to(device)\n",
    "                            y_new = model(X_new)\n",
    "                            y_new = torch.argmax(nn.Softmax(dim=-1)(torch.mean(y_new, dim=0)))\n",
    "                            #y_new = sorted(dict(collections.Counter(torch.argmax(nn.Softmax(dim=-1)(y_new), dim=1).cpu().numpy()))\n",
    "                            #               .items(), key=(lambda x: x[1]), reverse=True)[0][0]\n",
    "                            y_new = 1 if (y_new.item() == y[eval_idx][i].item()) else 0\n",
    "                            correct += y_new\n",
    "                            n += 1\n",
    "                        except:\n",
    "                            pass\n",
    "\n",
    "                    acc = correct / n\n",
    "                    acc_list.append(acc)\n",
    "\n",
    "                acc_mean = sum(acc_list) / 5\n",
    "                print('conv_dim:', conv_dim, '\\taugmentation', augmentation, \n",
    "                      '\\twith_focus_attn:', with_focus_attn, '\\tmulti_task:', multi_task)\n",
    "                print('Test accuray:', round(acc_mean, 5))\n",
    "                print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for conv_dim in conv_dim_list:\n",
    "    for augmentation in augmentation_list:\n",
    "        for with_focus_attn in focus_attn_list:\n",
    "            for multi_task in multi_task_list:\n",
    "                #conv_dim = '1d'\n",
    "                checkpoint = './output/aae_' + conv_dim + '_step_300.pt'\n",
    "                hidden_size = 128\n",
    "                num_layers = 2\n",
    "                bidirectional = 'true'\n",
    "                #with_focus_attn = 'false'\n",
    "\n",
    "                batch_size = 128\n",
    "                num_epochs = 300\n",
    "                learning_rate = 0.0001\n",
    "\n",
    "                use_warmup = 'true'\n",
    "                data_dir = './wav_data/pretrain/RAVDESS_resample/'\n",
    "                #multi_task = 'false'\n",
    "                #augmentation = 'true'\n",
    "\n",
    "                bidirectional = True if(bidirectional == 'true') else False\n",
    "                #with_focus_attn = True if(with_focus_attn == 'true') else False\n",
    "                n_mfcc = 40 if(conv_dim == '1d') else 128\n",
    "\n",
    "                device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "                sample_datas = glob.glob(os.path.join(data_dir, '**', '*wav'), recursive=True)\n",
    "                sample_datas = sorted(sample_datas)\n",
    "\n",
    "                acc_list = []\n",
    "                for i in range(5):\n",
    "                    np.random.seed(10 * i + 3)\n",
    "                    idx = np.random.permutation(len(sample_datas))\n",
    "                    train_idx = idx[:int(len(sample_datas)*0.75)]\n",
    "                    eval_idx = idx[int(len(sample_datas)*0.75):]\n",
    "\n",
    "                    train_samples = list(np.array(sample_datas)[train_idx])\n",
    "                    eval_samples = list(np.array(sample_datas)[eval_idx])\n",
    "\n",
    "                    y = np.array(list(map(lambda x: int(x.split('/')[-1].split('-')[2]) - 1, sample_datas)))\n",
    "                    y_train = y[train_idx]\n",
    "                    y_eval = y[eval_idx]\n",
    "\n",
    "                    if(multi_task == 'true'):\n",
    "                        speaker = np.array(list(map(lambda x: int(x.split('/')[-1].split('-')[-1].split('.')[0]), sample_datas)))\n",
    "                        y_gender = np.array(list(map(lambda x: 1 if x % 2 ==0 else 0, speaker)))\n",
    "\n",
    "                        y_g_train = y_gender[train_idx]\n",
    "                        y_g_eval = y_gender[eval_idx]\n",
    "\n",
    "                    X_train, y_train = convert_spectrograms(train_samples, conv_dim=conv_dim, sr=16000, labels=y_train)\n",
    "                    X_eval, y_eval = convert_spectrograms(eval_samples, conv_dim=conv_dim, sr=16000, labels=y_eval)\n",
    "\n",
    "                    if(augmentation == 'true'):\n",
    "                        X_train_flip = X_train[:, :, :, ::-1]\n",
    "                        y_train_flip = y_train.copy()\n",
    "\n",
    "                        X_train = np.concatenate((X_train, X_train_flip), axis=0)\n",
    "                        y_train = np.concatenate((y_train, y_train_flip), axis=0)\n",
    "                    \n",
    "                    X_train, y_train = convert_tensor(X_train, y_train)\n",
    "                    X_eval, y_eval = convert_tensor(X_eval, y_eval)\n",
    "\n",
    "                    y_train = y_train.long()\n",
    "                    y_eval = y_eval.long()\n",
    "\n",
    "                    if(multi_task == 'true'):\n",
    "                        _, y_g_train = convert_spectrograms(train_samples, conv_dim=conv_dim, sr=16000, labels=y_g_train)\n",
    "                        _, y_g_eval = convert_spectrograms(eval_samples, conv_dim=conv_dim, sr=16000, labels=y_g_eval)\n",
    "\n",
    "                        if(augmentation == 'true'):\n",
    "                            y_g_train_flip = y_g_train.copy()\n",
    "                            y_g_train = np.concatenate((y_g_train, y_g_train_flip))\n",
    "                        \n",
    "                        y_g_train = torch.tensor(y_g_train).float()\n",
    "                        y_g_eval = torch.tensor(y_g_eval).float()\n",
    "\n",
    "                        y_g_train = y_g_train.unsqueeze(-1)\n",
    "                        y_g_eval = y_g_eval.unsqueeze(-1)\n",
    "\n",
    "                    if(multi_task == 'true'):\n",
    "                        train_ds = TensorDataset(X_train, y_train, y_g_train)\n",
    "                        eval_ds = TensorDataset(X_eval, y_eval, y_g_eval)\n",
    "                    else:\n",
    "                        train_ds = TensorDataset(X_train, y_train)\n",
    "                        eval_ds = TensorDataset(X_eval, y_eval)\n",
    "\n",
    "                    train_dataloader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=0, drop_last=True)\n",
    "                    eval_dataloader = DataLoader(eval_ds, batch_size=batch_size, num_workers=0, drop_last=True)\n",
    "\n",
    "                    model = CLDNN(conv_dim=conv_dim, checkpoint=checkpoint, hidden_size=hidden_size,\n",
    "                                  num_layers=num_layers, bidirectional=bidirectional,\n",
    "                                  with_focus_attn=with_focus_attn).to(device)\n",
    "\n",
    "                    if(multi_task == 'true'):\n",
    "                        model_g = CLDNN_G(conv_dim=conv_dim, checkpoint=checkpoint, hidden_size=hidden_size,\n",
    "                                            num_layers=num_layers, bidirectional=bidirectional,\n",
    "                                            with_focus_attn=with_focus_attn).to(device)\n",
    "\n",
    "                    if(multi_task == 'true'):\n",
    "                        loss_func = nn.CrossEntropyLoss()\n",
    "                        loss_func_g = nn.BCELoss()\n",
    "                        optimizer = optim.Adam(list(model.parameters()) + list(model_g.parameters()), lr=learning_rate)\n",
    "                    else:\n",
    "                        loss_func = nn.CrossEntropyLoss()\n",
    "                        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "                    if(use_warmup == 'true'):\n",
    "                        t_total = len(train_dataloader) // 1 * num_epochs\n",
    "                        opt_scheduler = WarmupLinearSchedule(optimizer, warmup_steps=t_total * 0.1, t_total=t_total)\n",
    "\n",
    "                    train(train_dataloader, eval_dataloader, num_epochs)\n",
    "\n",
    "                    model.eval()\n",
    "                    if(multi_task == 'true'):\n",
    "                        model_g.eval()\n",
    "\n",
    "                    correct = 0\n",
    "                    n = 0\n",
    "                    for i in range(len(eval_samples)):\n",
    "                        try:\n",
    "                            X_new = preprocessing(eval_samples[i], method='mfcc', sr=16000, n_mfcc=n_mfcc)\n",
    "                            X_new = convert_tensor(X_new).to(device)\n",
    "                            y_new = model(X_new)\n",
    "                            y_new = torch.argmax(nn.Softmax(dim=-1)(torch.mean(y_new, dim=0)))\n",
    "                            #y_new = sorted(dict(collections.Counter(torch.argmax(nn.Softmax(dim=-1)(y_new), dim=1).cpu().numpy()))\n",
    "                            #               .items(), key=(lambda x: x[1]), reverse=True)[0][0]\n",
    "                            y_new = 1 if (y_new.item() == y[eval_idx][i].item()) else 0\n",
    "                            correct += y_new\n",
    "                            n += 1\n",
    "                        except:\n",
    "                            pass\n",
    "\n",
    "                    acc = correct / n\n",
    "                    acc_list.append(acc)\n",
    "\n",
    "                acc_mean = sum(acc_list) / 5\n",
    "                print('conv_dim:', conv_dim, '\\taugmentation', augmentation, \n",
    "                      '\\twith_focus_attn:', with_focus_attn, '\\tmulti_task:', multi_task)\n",
    "                print('Test accuray:', round(acc_mean, 5))\n",
    "                print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
